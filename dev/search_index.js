var documenterSearchIndex = {"docs":
[{"location":"advanced_usage/#advanced-usage-1","page":"Advanced Usage","title":"Advanced Usage","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"CurrentModule = DSGE","category":"page"},{"location":"advanced_usage/#Package-Directory-Structure-1","page":"Advanced Usage","title":"Package Directory Structure","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The package directory structure follows Julia module conventions. Directories in square brackets indicate future additions. Note that this directory tree is not linked, although it appears to be.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Pages = [\"pkg_structure.md\"]\nDepth = 5","category":"page"},{"location":"advanced_usage/#working-with-settings-1","page":"Advanced Usage","title":"Working with Settings","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"There are many computational settings that affect how the code runs without affecting the mathematical definition of the model. While the default settings loaded are intended to be comprehensive rather than the minimal number of settings, users will generally want to check that these three settings are properly chosen:","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"saveroot::String: The root directory for model output.\ndataroot::String: The root directory for model input data.\ndata_vintage::String: Data vintage, formatted yymmdd. By default, data_vintage is set to today's date. It is (currently) the only setting printed to output filenames by default.\ncond_vintage::String: Conditional data vintage, formatted yymmdd. By default, cond_vintage is set to today's date.\ndata_id::Int64: ID number to append to a created data set's name and to identify which saved data set to load\ncond_id::Int64: ID number to identify which conditional data set should be loaded","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Many functions in DSGE.jl will either require input data or create output data, so it is important to check that the saveroot and dataroot are set as the user intends. Setting the data vintage is also useful for reproducibility. Economic data like GDP are frequently revised, which can pose issues for reproducing results. Setting the data vintage allows users to guarantee the correct vintage of data is used when generating results. By default, the data vintage is set to the current date, so a user will need to manually set the data vintage to the desired date.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Below, we describe several important settings for package usage.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"For more details on implementation and usage of settings, see ModelConstructors.jl.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"See defaults.jl for the complete description of default settings.","category":"page"},{"location":"advanced_usage/#General-1","page":"Advanced Usage","title":"General","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"saveroot::String: The root directory for model output.\nuse_parallel_workers::Bool: Use available parallel workers in computations.\nnominal_rate_observable: Name (as a Symbol) of the observable used to measure the nominal interest rate used to implement monetary policy.\nmonetary_policy_shock: Name (as a Symbol) of the exogenous monetary policy shock in a concrete subtype of AbstractDSGEModel.\nn_mon_anticipated_shocks::Int: Number of anticipated policy shocks.\nantshocks::Dict{Symbol, Int}: a dictionary mapping the name of an anticipated shock to the number of periods of anticipation, e.g. :b => 2 adds anticipated b shocks up to two periods ahead.\nant_eq_mapping::Dict{Symbol, Symbol}: a dictionary mapping the name of an anticipated shock to the name of the state variable in the equation defining the shock's exogenous process, e.g. :b => :b maps an anticipated b shock to the equation eq_b.\nant_eq_E_mapping::Dict{Symbol, Symbol}: a dictionary mapping the name of an anticipated shock to the name of the state variable in the equation defining the shock's one-period ahead expectation e.g. :b => :Eb  maps an anticipated b shock to the equation eq_Eb, where Eb is E_tb_t + 1.\nproportional_antshocks::Vector{Symbol}: a vector of the names of one-period ahead anticipated shocks which are specified as directly proportional to the realizations of the current period's unanticipated shocks. For a shock b, the automatically generated parameter Ïƒ_b_prop defines the proportionality to the current period shock, e.g. a value of 1 indicates an anticipated shock in the next period of the same size as the current period's unanticipated shock.","category":"page"},{"location":"advanced_usage/#Data-and-I/O-1","page":"Advanced Usage","title":"Data and I/O","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"dataroot::String: The root directory for model input data.\ndata_vintage::String: Data vintage, formatted yymmdd. By default, data_vintage is set to today's date. It is (currently) the only setting printed to output filenames by default.\ndataset_id::Int: Dataset identifier. There should be a unique dataset ID for each set of observables.\ncond_vintage::String: Conditional data vintage, formatted yymmdd.\ncond_id::Int: Conditional dataset identifier. There should be a unique conditional dataset ID for each set of input, raw data mnemonics (not observables!).\ncond_semi_names::Vector{Symbol} and cond_full_names::Vector{Symbol}: names of observables for which we want to use semi- and full conditional data. All other observables are NaNed out in the conditional data periods.\npopulation_mnemonic::Nullable{Symbol}: population series mnemonic in form Nullable(:<mnemonic>__<source>) (for example, Nullable(:CNP16OV__FRED)), or Nullable{Symbol}() if the model doesn't use population data","category":"page"},{"location":"advanced_usage/#Dates-1","page":"Advanced Usage","title":"Dates","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"date_presample_start::Date: Start date of pre-sample.\ndate_mainsample_start::Date: Start date of main sample.\ndate_zlb_start::Date: Start date of zero lower bound regime.\ndate_zlb_end::Date: End date of zero lower bound regime.\ndate_forecast_start::Date: Start date of forecast period (or the period after the last period for which we have GDP data).\ndate_forecast_end::Date: End date of forecast, i.e. how far into the future to forecast.\ndate_conditional_end::Date: Last date for which we have conditional data. This is typically the same as date_forecast_start when we condition on nowcasts and current quarter financial data.","category":"page"},{"location":"advanced_usage/#Estimation-1","page":"Advanced Usage","title":"Estimation","text":"","category":"section"},{"location":"advanced_usage/#Metropolis-Hastings-Settings-1","page":"Advanced Usage","title":"Metropolis-Hastings Settings","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"reoptimize::Bool: Whether to reoptimize the posterior mode. If true (the   default), estimate begins reoptimizing from the model object's parameter   vector.  See Optimizing or Reoptimizing for   more details.\ncalculate_hessian::Bool: Whether to compute the Hessian. If true (the   default), estimate calculates the Hessian at the posterior mode.\nn_mh_simulations::Int: Number of draws from the posterior distribution per block.\nn_mh_blocks::Int: Number of blocks to run Metropolis-Hastings.\nn_mh_burn::Int: Number of blocks to discard as burn-in for Metropolis-Hastings.\nmh_thin::Int: Metropolis-Hastings thinning step.\nparallel::Bool: Flag for running algorithm in parallel.\nmh_adaptive_accept::Bool: if true, then the proposal distribution is adapted to achieve a target accept rate.\nmh_target_accept::Bool: target accept rate when adaptively adjusting acceptance probability.\nmh_c::S = 0.5: Initial scaling factor for covariance of the particles when using an adaptive proposal distribution. Controls size of steps in mutation step.\nmh_Î±::S = 1.0: The mixture proportion for the mutation step's proposal distribution when using an adaptive proposal distribution. See ?mvnormal_mixture_draw for details. Note that a value of 0.9 has commonly been used in applications to DSGE models (see citations below).","category":"page"},{"location":"advanced_usage/#Sequential-Monte-Carlo-Settings-1","page":"Advanced Usage","title":"Sequential Monte Carlo Settings","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"n_particles::Int: Number of particles.\nn_smc_blocks::Int: Number of parameter blocks in mutation step.\nn_mh_steps_smc::Int: Number of Metropolis Hastings steps to attempt during the mutation step.\nÎ»::S: The 'bending coefficient' Î» in Î¦(n) = (n/N(Î¦))^Î»\nn_Î¦::Int: Number of stages in the tempering schedule.\nresampling_method::Symbol: Which resampling method to use.\n:systematic: Will use sytematic resampling.\n:multinomial: Will use multinomial resampling.\n:polyalgo: Samples using a polyalgorithm.\nthreshold_ratio::S: Threshold s.t. particles will be resampled when the population   drops below threshold * N\nstep_size_smc::S: Scaling factor for covariance of the particles. Controls size of steps in mutation step.\nmixture_proportion::S: The mixture proportion for the mutation step's proposal distribution.\ntarget_accept::S: The initial target acceptance rate for new particles during mutation.\nuse_fixed_schedule::Bool: Flag for whether or not to use a fixed tempering (Ï•) schedule.\nadaptive_tempering_target_smc::S: Coefficient of the sample size metric to be targeted when solving   for an endogenous Ï• or 0.0 if using a fixed schedule.\ntempered_update_prior_weight::S: when bridging from old estimation, i.e. a tempered update, the user   can create a bridge distribution as a convex combination of the prior and a   previously ran estimation. This setting is the relative weight on the prior   in the convex combination.\nsmc_iteration::Int: The iteration index for the number of times SMC has been run on the    same data vintage. Primarily for numerical accuracy/testing purposes.\nprevious_data_vintage::String: the old data vintage from which to start SMC when using a tempered update\ndebug_assertion::Bool: print output (if applicable) when encountering an assertion error during SMC to help with debugging.","category":"page"},{"location":"advanced_usage/#Miscellaneous-1","page":"Advanced Usage","title":"Miscellaneous","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"use_chand_recursion::Bool: Flag for using Chandrasekhar Recursions in Kalman filter.","category":"page"},{"location":"advanced_usage/#Forecasting-1","page":"Advanced Usage","title":"Forecasting","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"forecast_jstep::Int: Forecast thinning step.\nforecast_block_size::Int: Number of draws in each forecast block before thinning by forecast_jstep.\nforecast_input_file_overrides::Dict{Symbol, String}: Maps input_type(s) to the file name containing input draws for that type of forecast. See Forecasting.\nforecast_horizons::Int: Number of periods to forecast.\nimpulse_response_horizons::Int: Number of periods for which to calculate IRFs.\nn_periods_no_shocks::Int: Number of periods for which no shocks are drawn (e.g. a full-distribution forecast draws shocks, but if n_periods_no_shocks = 3, then for 3 periods in the forecast horizon, no shocks will be drawn)","category":"page"},{"location":"advanced_usage/#Alternative-Policy-1","page":"Advanced Usage","title":"Alternative Policy","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"alternative_policy::AltPolicy: See Alternative Policies.","category":"page"},{"location":"advanced_usage/#Accessing-Settings-1","page":"Advanced Usage","title":"Accessing Settings","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The function get_setting(m::AbstractModel, s::Symbol) returns the value of the setting s in m.settings. Some settings also have explicit getter methods that take only the model object m as an argument. Note that not all are exported.","category":"page"},{"location":"advanced_usage/#Overwriting-Default-Settings-1","page":"Advanced Usage","title":"Overwriting Default Settings","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"To overwrite default settings added during model construction, a user must create a Dict{Symbol, Setting} and pass that into the model constructor as the keyword argument custom_settings. If the print, code, and description fields of the new Setting object are not provided, the fields of the existing setting will be maintained. If new values for print, code, and description are specified, and if these new values are distinct from the defaults for those fields, the fields of the existing setting will be updated.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"For example, overwriting use_parallel_workers should look like this:","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"custom_settings = Dict{Symbol, Setting}(\n    :use_parallel_workers => Setting(:use_parallel_workers, true))\nm = Model990(custom_settings = custom_settings)","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Or like this:","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"m = Model990()\nm <= Setting(:use_parallel_workers, true)","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Note that using this second method will not work for all settings, e.g. n_anticipated_shocks is a setting that must be passed into the model during construction, as in the first example.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"By default, passing in custom_settings overwrites the entries in the model object's settings field. However, with the additional keyword argument testing = true, it will overwrite the entries in test_settings:","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"m = Model990(custom_settings = custom_settings, testing = true)","category":"page"},{"location":"advanced_usage/#accel-regime-switch-statespace-comp-1","page":"Advanced Usage","title":"Accelerating Computation of Regime-Switching System","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Regime-switching state space systems take more time to compute, which can severely slow down estimation and forecasting time. The interface for computing regime-switching systems is written to be easy to use and generic, but, as a result, its default behavior ignores information that could be used to accelerate computation time. We provide some settings that allow the user to specify such information about the state space system.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"perfect_credibility_identical_transitions::Dict{Int, Int}: different regimes may have the same transition equations (TTT, RRR, and CCC matrices, also see Solving the Model). This setting tells the code to use another regime's transition equation rather than recalculate the equation. The keys of this Dict are regime numbers, and the values specify the regime to which the keys' regimes are identical. For example, if the setting was Dict(2 => 1, 3 => 1), then we are saying that regimes 2 and 3 have the same transition equations as regime 1. Note that if you are using gensys2, then you cannot say that gensys regimes have the same transition equations as any regime on which gensys2 is called, including the terminal period of gensys2, even though the transition equations may indeed be the same. The reason is that the gensys regimes are computed before the gensys2 regimes, and to avoid extra calculations, the terminal period is computed during the gensys2 step. Therefore, trying to copy a gensys2 regime for a gensys regime will cause an error (an attempt to access an undefined reference).","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"identical_eqcond_regimes::Dict{Int, Int}: different regimes may have the same equilibrium conditions (see Solving the Model). This setting tells the code to copy another regime's equilibrium conditions rather than recompute the gensys matrices. The keys of this Dict are regime numbers, and the values specify the regime to which the keys' regimes are identical. For example, if the setting was Dict(2 => 1, 3 => 1), then we are saying that regimes 2 and 3 have the same equilibrium conditions as regime 1.\nempty_measurement_equation::Vector{Bool}: when using time-varying information sets and forward-looking observables, you may need to calculate the transition equations beyond the last period of available data. By default, compute_system will also compute the measurement equation for these regimes in the future, which is unnecessary if you are trying to estimate the model. This setting specifies which regimes can have an empty measurement equation (set to be a Measurement type with undefined matrices for its fields). A false element in the vector means that the measurement equation is nonempty, while a true element means an empty measurement equation. The length of the vector should be the same length as the number of regimes, and the indices of the vector corresponding to the regime number.\nempty_pseudo_measurement_equation::Vector{Bool}: same as empty_measurement_equation but for the pseudo-measurement equation. For estimations, you can omit all the pseudo-measurement equations since they are unnecessary.","category":"page"},{"location":"advanced_usage/#regime-switch-forecast-1","page":"Advanced Usage","title":"Regime-Switching Forecasts","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Forecasts can involve state-space systems with exogenous and unanticipated regime-switching in the history periods and forecast horizon. Anticipated temporary alternative policies can also occur in both the history and the forecast horizon. Historical regime switching may occur to reflect structural breaks or to allow a DSGE to handle special circumstances, such as the COVID-19 pandemic. Regime switches in the forecast horizon may occur because agents expect a ZLB until some date in the future. In a rational expectations equilibrium, agents will behave differently if they know a forecasted policy is temporary rather than permanent. Using exogenous regime-switching along with a modified gensys solution algorithm is one way of implementing this expectation. See Regime-Switching for more details on the solution algorithm.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"In this section, we will go over the interface for running regime-switching forecasts and discuss some details of the implementation. It is useful to also look at the posted example script for regime-switching. To understand how to implement your own regime-switching model, we recommend examining the implementation of regime-switching equilibrium conditions for Model1002 and how it is integrated with our solvers. For a guide to running permanent and/or temporary alternative policies, please see Alternative Policies.","category":"page"},{"location":"advanced_usage/#Preparing-a-Model's-Settings-for-Regime-Switching-1","page":"Advanced Usage","title":"Preparing a Model's Settings for Regime-Switching","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Suppose we wanted to run a regime-switching forecast, where where the regimes are 1959:Q3-1989:Q4, 1990:Q1-2019:Q3, and 2019:Q4 to the end of the forecast horizon. The following lines are required:","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"m <= Setting(:regime_switching, true)\nm <= Setting(:regime_dates, Dict{Int, Date}(1 => Date(1959, 9, 30), 2 => Date(1990, 3, 31),\n                                            3 => Date(2019, 12, 31))","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The first setting turns on regime switching. Internally, functions like forecast_one will decide whether to use regime switching or not depending on whether get_setting(m, :regime_switching) is true and whether there are actually multiple regimes specified by :regime_dates. The second setting is a Dict mapping the regime number to the first date (inclusive) of that regime.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Before running a forecast, we must also run","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"setup_regime_switching_inds!(m; cond_type = cond_type)","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"which will automatically compute the (required) settings","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":":reg_forecast_start: Regime of the first forecast start period\n:reg_post_conditional_end: Regime of the period after the last conditional forecast period\n:n_regimes: Number of total regimes. If this is 1, then regime switching will not occur.\n:n_hist_regimes: Number of regimes in the history\n:n_fcast_regimes: Number of regimes in the forecast horizon (including the conditional forecast)\n:n_cond_regimes: Number of regimes in the conditional forecast","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"These settings will generally depend on whether the forecast is conditional or not, so the user needs to pass in cond_type = :full or cond_type = :semi to setup_regime_switching_inds! if the user wants a forecast with correct regime-switching.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Finally, to run a full-distribution forecast with regime-switching using forecast_one or usual_model_forecast, it is necessary to manually construct the matrix of parameter draws and pass them as an input with the keyword params. Currently, we have not fully implemented loading parameters from a saved estimation file. For an example about how to do this, see this example script.","category":"page"},{"location":"advanced_usage/#tvis-1","page":"Advanced Usage","title":"Time-Varying Information Sets","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"In many applications with regime-switching, changes in information sets may occur. For example, say in 1959:Q1 - 2007:Q3, people expected the Federal Reserve to always use a Taylor-style monetary policy rule. But in 2007:Q4, people realize that the Federal Reserve will implement a zero lower bound for N periods before switching back to the Taylor-style rule. The measurement equation used in 2007:Q4 and subsequent periods need to account for this change in the information set. In particular, quantities like anticipated nominal rates and 10Y inflation rates involve forecasting the expected state of the economy. If the transition matrices (e.g. TTT) are time-varying, and agents' information set includes knowledge that the matrices are time-varying, then the measurement equation should account for it. Explicitly, assume the state space evolves according to","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"beginaligned\ns_t = T_t s_t - 1 + R_t varepsilon_t + C_t\nendaligned","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"If in period t, the measurement equation includes the anticipated nominal rate in k periods, and agents know that the transition equations are time-varying over some horizon H, then we need to calculate that expectation taking into account that agents know about the time variation in the matrices, e.g. T_t + 1 dots T_t + H. This approach allows for varying degrees of myopia, e.g. H = 0 implies that agents do not know about any time variation while H  k captures the case that agents only know about the time variation up to a certain horizon forward.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"To help the user write the correct measurement equation with time-varying transition equations, we have implemented the following two functions:","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"DSGE.k_periods_ahead_expectations\nDSGE.k_periods_ahead_expected_sums","category":"page"},{"location":"advanced_usage/#DSGE.k_periods_ahead_expectations","page":"Advanced Usage","title":"DSGE.k_periods_ahead_expectations","text":"k_periods_ahead_expectations(TTT, CCC, TTTs, CCCs, t, k; permanent_t = length(TTTs),\n                             integ_series = false, memo = nothing)\n\ncalculates the matrices associated with the expected state k periods ahead from t. This function should NOT be used with linear state space system matrices with any unit roots.\n\nThe TTT and CCC inputs are the transition matrix and constant vector associated with the current period t, while the TTTs and CCCs are vectors containing the time-varying transition matrices and constant vectors, such that TTTs[t] retrieves the time-varying transition matrix associated with period t and TTTs[t + k] retrieves the time-varying transition matrix associated with period t + k. The optional argument permanent_t indicates the period for which the matrices/vectors are no longer time-varying, i.e. if t >= permanent_t, then TTTs[permanent_t] is the transition matrix.\n\nThe formula implemented by this function is\n\nð”¼â‚œ[sâ‚œâ‚Šâ‚–] = (âˆâ±¼=â‚áµ Tâ‚œâ‚Šâ±¼) sâ‚œ + (âˆ‘â‚˜â‚Œâ‚áµâ»Â¹ (âˆâ±¼â‚Œâ‚˜â‚Šâ‚áµ Tâ‚œâ‚Šâ±¼) Câ‚œâ‚Šâ‚˜) + Câ‚œâ‚Šâ‚–.\n\nAdditional simplifications are made if it is known that t + k > permanent_t since this implies some matrices are the same. This recognition reduces unnecessary computations.\n\nKeyword Arguments\n\ninteg_series::Bool: set to true if there are some transition matries in TTT   that result in integrated series, in which case we cannot speed up   computations by using left-divides.\nmemo::Union{ForwardExpectationsMemo, Nothing}: pass a properly formed   ForwardExpectationsMemo to avoid calculating unnecessary products and powers of   the matrices in TTTs. Typically, the memo you want to compute is\n\n# min_t is minimum t you will use, maximum_t is maximum t you will use, and\n# max_k is the maximum window for forward expectations.\nmemo = ForwardExpectationsMemo(TTTs, min_t, length(TTTs), length(TTTs), min_t + max_k - length(TTTs),\n                               max_t + max_k + 1 - length(TTTs))\n\n\n\n\n\n","category":"function"},{"location":"advanced_usage/#DSGE.k_periods_ahead_expected_sums","page":"Advanced Usage","title":"DSGE.k_periods_ahead_expected_sums","text":"k_periods_ahead_expected_sums(TTT, CCC, TTTs, CCCs, t, k; permanent_t = length(TTTs),\n                              integ_series = false, memo = nothing)\n\ncalculates the matrices associated with the sum of the expected states between periods t + 1 and  t + k. This function should NOT be used with linear state space system matrices with any unit roots.\n\nThe TTT and CCC inputs are the transition matrix and constant vector associated with the current period t, while the TTTs and CCCs are vectors containing the time-varying transition matrices and constant vectors, such that TTTs[t] retrieves the time-varying transition matrix associated with period t and TTTs[t + k] retrieves the time-varying transition matrix associated with period t + k. The optional argument permanent_t indicates the period for which the matrices/vectors are no longer time-varying, i.e. if t >= permanent_t, then TTTs[permanent_t] is the transition matrix.\n\nThe formula implemented by this function is\n\nâˆ‘â±¼â‚Œâ‚áµ ð”¼â‚œ[sâ‚œâ‚Šâ±¼] = âˆ‘â±¼â‚Œâ‚áµ(âˆâ±¼=â‚áµ Tâ‚œâ‚Šâ±¼) sâ‚œ + âˆ‘áµ£â‚Œâ‚áµâ»Â¹(I + âˆ‘â±¼â‚Œáµ£â‚Šâ‚áµ (âˆâ‚˜â‚Œáµ£â‚Šâ‚Ê² Tâ‚œâ‚Šâ‚˜))Câ‚œâ‚Šáµ£ + Câ‚œâ‚Šâ‚–.\n\nAdditional simplifications are made if it is known that t + k > permanent_t since this implies some matrices are the same. This recognition reduces unnecessary computations.\n\nKeyword Arguments\n\ninteg_series::Bool: set to true if there are some transition matries in TTT   that result in integrated series, in which case we cannot speed up   computations by using left-divides.\nmemo::Union{ForwardMultipleExpectationsMemo, Nothing}: pass a properly formed   ForwardExpectationsMemo to avoid calculating unnecessary products and powers of   the matrices in TTTs. Typically, the memo you want to compute is\n\n# min_t is minimum t you will use, maximum_t is maximum t you will use, and\n# max_k is the maximum window for forward expectations.\nmemo = ForwardMultipleExpectationsMemo(TTTs, min_t, length(TTTs), length(TTTs), min_t + max_k - length(TTTs),\n                               max_t + max_k + 1 - length(TTTs))\n\n\n\n\n\n","category":"function"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"See the measurement equation for Model 1002 for an example of how these functions are used.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"To accelerate the computation time for these functions, we have also implemented types that create memos of the products and powers of the T_t + k_t = 1^k matrices which are needed. See","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"DSGE.ForwardExpectationsMemo\nDSGE.ForwardMultipleExpectationsMemo","category":"page"},{"location":"advanced_usage/#DSGE.ForwardExpectationsMemo","page":"Advanced Usage","title":"DSGE.ForwardExpectationsMemo","text":"ForwardExpectationsMemo(TTTs::Vector{<: AbstractMatrix{S}},\n                        current_regime::Int64, last_tv_period::Int64,\n                        first_perm_period::Int64, min_perm_power::Int64 = 0,\n                        max_perm_power::Int64 = 0) where {S <: Real}\n\ncomputes the memo dictionaries of the necessary products/powers of TTTs for computing forward expectations of states and sums of states.\n\nInputs\n\nTTTs: complete sequence of time-varying transition matrices from regime 1 to the final regime\ncurrent_regime: the current period's regime\nlast_tv_period: the last period in which the transition matrix is believed to have changed relative to the previous period.\nfirst_perm_period: the first period in which the transition matrix in TTTs is permanently imposed. This period   should be from the perspective of an omniscient econometrician rather than the agents' perspective.\nmin_perm_power: minimum power of the permanent matrix to be calculated, i.e. we calculate at least TTTs[first_perm_period] ^ min_perm_power\nmax_perm_power: maximum power of the permanent matrix to be calculated, i.e. we calculate at most TTTs[first_perm_period] ^ max_perm_power\n\nNotes\n\nTo clarify what last_tv_period should be, note that\n\nif every matrix in TTTs is time-varying, AND agents believe every matrix is time-varying, then last_tv_period = length(TTTs). However, if agents are myopic and believe that the last time-varying matrix is the second to last one, then last_tv_period = length(TTTs) - 1. This flexibility allows the user to specify different degrees of awareness about TTTs.\n\nNote that when last_tv_period == first_perm_period, we do not calculate\n\ntime_varying_memo[last_tv_period] = TTTs[first_perm_period] * TTTs[first_perm_period - 1] * ... TTTs[t + 1]\n\nInstead, we calculate\n\ntime_varying_memo[last_tv_period] = TTTs[first_perm_period - 1] * ... TTTs[t + 1]\n\nThe reason is that it is more efficient to include that first TTTs[first_perm_period] in the powers of TTT[first_perm_period] computed for permanent_memo. So if length(TTTs) == 7, to get the correct k-periods ahead forward expectations from some period t < 7, you need to run\n\nmemo = ForwardExpectationsMemo(TTTs, t, 7, 7, 1, t + k + 1 - 7)\n# or equivalently . . .\n# memo = ForwardExpectationsMemo(TTTs, t, length(TTTs), length(TTTs), 1, t + k + 1 - length(TTTs))\n\n\n\n\n\n","category":"type"},{"location":"advanced_usage/#DSGE.ForwardMultipleExpectationsMemo","page":"Advanced Usage","title":"DSGE.ForwardMultipleExpectationsMemo","text":"ForwardMultipleExpectationsMemo(TTTs::Vector{<: AbstractMatrix{S}},\n                                current_regime::Int64, min_last_tv_period::Int64, max_last_tv_period::Int64,\n                                first_perm_period::Int64, min_perm_power::Int64 = 0,\n                                max_perm_power::Int64 = 0) where {S <: Real}\n\ncomputes the memo dictionaries of the necessary products/powers of TTTs for computing forward expectations of states and sums of states for multiple different horizon lengths for the \"forward-looking\" window, i.e. variation in how many periods ahead for which expectations are taken. This approach avoids repeating computations that would be incurred if the user instead repeatedly created ForwardExpectationsMemo for each horizon length.\n\nInputs\n\nTTTs: complete sequence of time-varying transition matrices from regime 1 to the final regime\ncurrent_regime: the current period's regime\nmin_last_tv_period: the minimum last period in which the transition matrix is believed to have changed relative to the previous period.\nmax_last_tv_period: the maximum last period in which the transition matrix is believed to have changed relative to the previous period.\nfirst_perm_period: the first period in which the transition matrix in TTTs is permanently imposed. This period   should be from the perspective of an omniscient econometrician rather than the agents' perspective.\nmin_perm_power: minimum power of the permanent matrix to be calculated, i.e. we calculate at least TTTs[first_perm_period] ^ min_perm_power\nmax_perm_power: maximum power of the permanent matrix to be calculated, i.e. we calculate at most TTTs[first_perm_period] ^ max_perm_power\n\nNotes\n\nTo clarify what min_last_tv_period and max_last_tv_period should be, first consider the meaning of input argument\n\nlast_tv_period for ForwardExpectationsMemo. If every matrix in TTTs is time-varying, AND agents believe every matrix is time-varying, then last_tv_period = length(TTTs). However, if agents are myopic and believe that the last time-varying matrix is the second to last one, then last_tv_period = length(TTTs) - 1. This flexibility allows the user to specify different degrees of awareness about TTTs.\n\nThe argument min_last_tv_period and max_last_tv_period allow the user to construct one memo object for computing varying lengths of forward expectations. For example, suppose we want expectations of the nominal rate from 1 to 6 periods ahead in the measurement equation in the regime t. Then you should run\n\nForwardExpectationsMemo(TTTs, t, t + 1, t + 6, ...) # ellipsis omits the remaining input args\n\nNote that when max_last_tv_period == first_perm_period,\n\ntime_varying_memo[max_last_tv_period] = TTTs[first_perm_period] * TTTs[first_perm_period - 1] * ... TTTs[t + 1]\n\nInstead, we calculate\n\ntime_varying_memo[max_last_tv_period] = TTTs[first_perm_period - 1] * ... TTTs[t + 1]\n\nThe reason is that it is more efficient to include that first TTTs[first_perm_period] in the powers of TTT[first_perm_period] computed for permanent_memo.\n\n\n\n\n\n","category":"type"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The first type is mainly an \"under the hood\" type for k_periods_ahead_expectations. The second type is a wrapper type that constructs all the memos needed to implement forward expectations of levels and sums in an efficient manner. We have automated the construction of memos with the Boolean Settings use_forward_expectations_memo and use_forward_expected_sum_memo. The first Setting indicates that a memo type will be used for calls to k_periods_ahead_expectations and the second indicates a memo type will be used for calls to k_periods_ahead_expected_sums. It is assumed by default that the last matrix in the sequence TTTs in a RegimeSwitchingSystem is the first period in which a TTT matrix permanently applies (hence we may assume that in all future periods the TTT is the same), but if this is not the case, then the user needs to specify the correct regime with the Setting memo_permanent_policy_regime::Int.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"For details on how we implement a state space system with time-varying information sets, see The TimeVaryingInformationSetSystem Type. For guidance on how to use this type, e.g. calculating forecats, see this example script.","category":"page"},{"location":"advanced_usage/#Available-Types-of-Regime-Switching-1","page":"Advanced Usage","title":"Available Types of Regime Switching","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"There are three cases involving regime switching that are implemented in DSGE.jl","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Exogenous and unanticipated regime switching (e.g. unanticipated regime-switching parameters)\nAlternative policies (temporary and permanent)\nTime-varying information sets","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"To implement regime-switching parameters or use temporary alternative policies, see this example script on regime-switching forecasts. This documentation on temporary alternative policies will also be helpful. For further details on regime-switching parameters, see the documentation for ModelConstructors.jl. To implement time-varying information sets, see this example script.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"If the user wants to combine exogenous regime switching in both parameters and policies, then the user may find it useful to distinguish between model and parameter regimes. For example, when implementing a temporary alternative policy, we typically treat each period of the temporary policy as a distinct regime, but the parameters of the model may remain constant across these regimes of the temporary policy. To distinguish the two, we implement in ModelConstructors.jl a second interface for changing parameter regimes. Aside from","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"toggle_regime!(p::Parameter, regime::Int)","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"for example, we also have the syntax","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"toggle_regime!(p::Parameter, model_regime::Int, d::AbstractDict{Int, Int})","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The latter syntax uses a dictionary to map a model regime to the correct parameter regime. As an example, suppose across 2020:Q1-Q4, I implement a temporary ZLB, and I assume that some parameters also regime switching during this period. Then I may want to write","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"d = Dict(1 => 1, # First model and parameter regime coincide (history until 2019:Q4).\n         2 => 2, # Regimes 2-5 represent 2020:Q1-Q4 andmap to the second regime\n         3 => 2,\n         4 => 2,\n         5 => 2,\n         6 => 1) # Starting in regime 6 (2021:Q1), the parameters switch back to the same values from before 2020.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"For more details, see the regime toggling in Model 1002's eqcond and the documentation for ModelConstructors.jl.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Once the regime-switching settings are properly created, the syntax for running a forecast is the same as when there is no regime-switching. See Forecasting.","category":"page"},{"location":"advanced_usage/#Handling-of-the-Zero-Lower-Bound-(ZLB)-1","page":"Advanced Usage","title":"Handling of the Zero Lower Bound (ZLB)","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The New York Fed DSGE model can handle the ZLB in two ways.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"In the first way, the New York Fed DSGE model treats the ZLB as a temporary alternative policy over a pre-specified horizon. In the second way, the New York Fed DSGE model treats the ZLB as a separate regime in which anticipated monetary policy shocks become \"alive\" and have positive standard deviations. However, this second form of the ZLB is not implemented as a separate regime. The reason is the only difference in the \"pre-ZLB\" and \"post-ZLB\" regimes is whether or not anticipated monetary policy shocks are non-zero. For an example, see the smoothing code as well as the auxiliary functions zlb_regime_matrices and zlb_regime_indices in this file.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"This approach saves computational time. Rather than creating redundant matrices, we directly zero/un-zero the appropriate entries in the pre- and post-ZLB QQ matrices. This approach also economizes on unnecessary switching, For instance, during the calculation of shock decompositions and trends, it is unnecessary to distinguish between the pre- and post-ZLB regimes.","category":"page"},{"location":"advanced_usage/#uncertainaltpol-1","page":"Advanced Usage","title":"Alternative Policy Uncertainty and Imperfect Awareness","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The standard alternative policy code assumes that people completely believe the change in policy. However, in many cases, the more realistic modeling choice is assuming some uncertainty or imperfect awareness/credibility about the policy change. This approach can also partially address the concern that expectations have counterfactually strong effects in standard DSGEs (e.g. the forward guidance puzzle).","category":"page"},{"location":"advanced_usage/#Theory-1","page":"Advanced Usage","title":"Theory","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"We model imperfect awareness by assuming there are n possible alternative policies that may occur tomorrow and n probability weights assigned to each policy. Further, it is believed that the alternative policy which occurs tomorrow will be permanent. One of the policies is the alternative policy which is actually implemented. The function gensys_uncertain_altpol calculates the state space transition equation implied by these beliefs. A typical application is assuming that with probability p some alternative policy occurs tomorrow and with probability 1-p the historical policy occurs tomorrow.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Imperfect awareness can occur in multiple periods and feature time-varying credibility by assuming myopia. For example, say agents in period t believe the central bank will implement AIT in t + 1 and all subsequent periods with probability p_t and the historical rule otherwise. After period t + 1 occurs and the central bank actually implements AIT, agents again believe that in period t + 2 and all subsequent periods, the central bank will implement AIT with probability p_t + 1 and the historical rule otherwise.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Imperfect awareness is robust to temporary alternative policies but requires the algorithm to account for time variation in the transition equation. In particular, we need to first compute the entire sequence of transition equations under the temporary alternative policy with perfect credibility. Once this sequence is available, we can then treat the temporary alternative policy as the alternative policy which is actually implemented and apply the same calculations described in the previous paragraph to each period of the temporary alternative policy.","category":"page"},{"location":"advanced_usage/#Implementation-1","page":"Advanced Usage","title":"Implementation","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"To apply imperfect awareness, the user needs to specify the possible alternative policies and the probability weights on these policies.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The alternative policy which is actually implemented should be added to the :regime_eqcond_info dictionary as an EqcondEntry, e.g.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"get_setting(m, :regime_eqcond_info)[2] = DSGE.EqcondEntry(DSGE.ngdp())","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The other alternative policies that agents believe may occur are then added as follows:","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"m <= Setting(:alternative_policies, [altpolicy1, altpolicy2]) # altpolicy1 and altpolicy2 are AltPolicy instances","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The user specifies the probability weights when creating the EqcondEntry instance for the :regime_eqcond_info dictionary, e.g.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"DSGE.EqcondEntry(DSGE.ngdp(), [p_t, 1 - p_t])","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"This approach permits time-variation in the probability weight because the user can use different p_t for each regime, e.g.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"get_setting(m, :regime_eqcond_info)[2] = DSGE.EqcondEntry(DSGE.ngdp(), [.5, .5])\nget_setting(m, :regime_eqcond_info)[3] = DSGE.EqcondEntry(DSGE.ngdp(), [1., 0.])","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Finally, before solving for the state space system or running forecasts, the user needs to add the line","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"m <= Seting(:uncertain_altpolicy, true)","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"To use imperfect awareness with a temporary altpolicy (eg. ZLB), the user needs to also add the following lines to the model's setup:","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"m <= Setting(:uncertain_temporary_altpolicy, true)\nm <= Setting(:temporary_altpolicy_names, keys_of_temp_altpols) # e.g. keys_of_temp_altpols = [:zlb_rule] or [:zero_rate]\nm <= Setting(:temporary_altpolicy_length, n_zlb_regs)","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The first line tells that a temporary altpolicy with imperfect awareness should apply. The second line tells which alternative policies (based on their keys) should be recognized as temporary policies and is used to infer on which regimes gensys2 should be called. The third line indicates the number of regimes for which the temporary altpolicy occurs. If the third line is not specified, then it is assumed that all regimes in get_setting(m, :regime_eqcond_info) except the last one are temporary altpolicy regimes. This assumption can be wrong, for example, if credibility changes after the temporary altpolicy ends.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"For further guidance on adding imperfect awareness, please see the script uncertainaltpolicyzlb.jl.","category":"page"},{"location":"advanced_usage/#Forward-Looking-Variables-in-the-Measurement-and-Pseudo-Measurement-Equations-1","page":"Advanced Usage","title":"Forward-Looking Variables in the Measurement and Pseudo-Measurement Equations","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The measurement and pseudo-measurement equations often include \"forward-looking\" observables, such as the anticipated nominal interest rate and the expected average inflation rate over the next ten years. The measurement equations for these observables are therefore affected when imperfect awareness is assumed. Say ZZ_1 and ZZ_2 are the measurement equation matrices mapping states to observables under two different monetary policy rules which may occur and that all the observables are forward-looking. For simplicity, additionally assume that the associated DD_1 and DD_2 are both zero. Because agents at the end of period t believe that either policy 1 or policy 2 occurs permanently in period t + 1, the measurement equation agents use to map states to data is just the weighted average of the measurement matrices, i.e.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"beginaligned\nZZ = p ZZ_1 + (1 - p) ZZ_2\nendaligned","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The reason is that, conditional on alternative policy 1 occurring, the observables in t + 1 should be","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"beginaligned\nmathbbE_ty_t + 1 mid textpolicy 1  = ZZ_1 mathbbE_ts_t + 1 mid textpolicy 1\nendaligned","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Similarly, if policy 2 occurs, then","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"beginaligned\nmathbbE_ty_t + 1 mid textpolicy 2  = ZZ_2 mathbbE_ts_t + 1 mid textpolicy 2\nendaligned","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The law of iterated expectations gives us the desired result.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The user does not need to worry about coding their measurement equations to account for this, as long as the measurement equation will properly compute ZZ_i, given the policies specified in the settings :regime_eqcond_info and :alternative_policies. DSGE.jl will handle the calculation of the convex combinations under the hood. The only setting which users are advised to add is one that indicates which rows of ZZ are associated with forward-looking observables, e.g.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"m <= Setting(:forward_looking_observables, [:obs_longinflation, :obs_nominalrate1])\nm <= Setting(:forward_looking_pseudo_observables, [:Expected10YearNaturalRate])","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"If such a setting exists, then DSGE.jl will only calculate the weighted average for the rows associated with these observables/pseudo-observables. Otherwise, we compute the weighted average of the different measurement matrices. This latter approach will always work, but it comes at the cost of unnecessary operations.","category":"page"},{"location":"advanced_usage/#[Imperfect-Awareness-with-Temporary-Policies-as-Alternative-Policies]-1","page":"Advanced Usage","title":"[Imperfect Awareness with Temporary Policies as Alternative Policies]","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The previous documentation generally assumes that the alternative policies which people believe may occur are one-regime and permanent policies. However, it is possible that agents are imperfectly aware over alternative policies that involve temporary policies and thus require the use of gensys2. The only difference the user needs to do is use a MultiPeriodAltPolicy type rather than an AltPolicy type when populating the Setting alternative_policies. See Types for documentation on the fields of a MultiPeriodAltPolicy. As an example, the code snippet below implements a temporary ZLB as the alternative policy, assuming the existence of a regime-switching model instance m.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"# Alternative Policy 1: default/historical rule\naltpol1 = default_policy()\n\n# Alernative Policy 2: ZLB starting in regime 3 and ending in regime 5, and flexible AIT starting in regime 6\nnew_reg_eqcond_info = Dict(3 => EqcondEntry(zlb_rule(), reg3_weights), # reg3_weights specifies whatever weights\n                           4 => EqcondEntry(zlb_rule(), reg4_weights), # the user wants in regime 3, etc.\n                           5 => EqcondEntry(zlb_rule(), reg5_weights),\n                           6 => EqcondEntry(flexible_ait(), reg6_weights))\nnew_infoset         = [1:1, 2:2, [i:6 for i in 3:6]..., [i:i for i in 7:get_setting(m, :n_regimes)]...]\n\ndelete!(m.settings, :alternative_policies) # if :alternative_policies already exists, then a type error may occur\n\naltpol2 = MultiPeriodAltPolicy(:temporary_zlb, get_setting(m, :n_regimes),\n                               reg_eqcond_info, gensys2 = true,\n                               temporary_altpolicy_names = [:zlb_rule],\n                               temporary_altpolicy_length = 3,\n                               infoset = new_infoset)\n\n# Both AltPolicy and MultiPeriodAltPolicy are subtypes of AbstractAltPolicy\nm <= Setting(:alternative_policies, DSGE.AbstractAltPolicy[altpol1, altpol2])","category":"page"},{"location":"advanced_usage/#Automatically-Generating-Anticipated-Shocks-1","page":"Advanced Usage","title":"Automatically Generating Anticipated Shocks","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"We have implemented some functionality for automatically adding anticipated shocks for Model1002. To add these shocks, the user must pass custom settings into the constructor using the custom_settings keyword. The available settings for defining these shocks are:","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"antshocks::Dict{Symbol, Int}: a dictionary mapping the name of an anticipated shock to the number of periods of anticipation, e.g. :b => 2 adds anticipated b shocks up to two periods ahead.\nant_eq_mapping::Dict{Symbol, Symbol}: a dictionary mapping the name of an anticipated shock to the name of the state variable in the equation defining the shock's exogenous process, e.g. :b => :b maps an anticipated b shock to the equation eq_b.\nant_eq_E_mapping::Dict{Symbol, Symbol}: a dictionary mapping the name of an anticipated shock to the name of the state variable in the equation defining the shock's one-period ahead expectation e.g. :b => :Eb  maps an anticipated b shock to the equation eq_Eb, where Eb is E_tb_t + 1.\nproportional_antshocks::Vector{Symbol}: a vector of the names of one-period ahead anticipated shocks which are specified as directly proportional to the realizations of the current period's unanticipated shocks. For a shock b, the automatically generated parameter Ïƒ_b_prop defines the proportionality to the current period shock, e.g. a value of 1 indicates an anticipated shock in the next period of the same size as the current period's unanticipated shock.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"As an example, the following code creates an instance of Model1002 with anticipation of b shocks up to two periods ahead.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"custom_settings = Dict{Symbol, Setting}(:antshocks => Setting(:antshocks, Dict{Symbol, Int}(:b => 2)),\n                :ant_eq_mapping => Setting(:ant_eq_mapping, Dict{Symbol, Symbol}(:b => :b)))\nm = Model1002(\"ss10\"; custom_settings = custom_settings)","category":"page"},{"location":"advanced_usage/#auto-endo-zlb-1","page":"Advanced Usage","title":"Automatic Endogenous ZLB Enforcement as Temporary Rule","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The user can enforce the ZLB during the forecast horizon in two ways. The default approach uses unanticipated monetary policy shocks. Instead, the user can also use the temporary ZLB machinery to enforce the ZLB. This enforcement is endogenous in the sense that, conditional on a draw of shocks, we want to figure out the required length of a temporary ZLB that will deliver non-negative interest rates throughout the horizon.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The enforcement is automated by trading off two objectives. First, we want the length of the ZLB to be minimal so that the ZLB is not unnecessarily accommodative, unless it is specifically desired for the ZLB to extend to at least some date. Second, we want to maintain a reasonable computational time. Finding a minimal ZLB length when there are multiple disconnected periods of negative interest rates would be prohibitively expensive because expecting more periods of temporary ZLB in the future affects agents' expectations today, and changing the number of periods of temporary ZLB in the past affects the future evolution of states.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Instead, we endogenously enforce the ZLB only for the first connected sequence of periods with negative interest rates and use unanticipated monetary policy shocks for future sequences of periods with negative rates. Our algorithm proceeds as follows.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Forecast without any periods of temporary ZLBs (unless a minimum length is specified) and find the first connected sequence of periods with negative interest rates.\nGuess a sequence of temporary ZLB regimes that cover this first sequence of periods with negative interest rates.\nIf the forecast under the temporary policy from 2 successfully enforces the ZLB over that first sequence and does not introduce negative rates after liftoff from the ZLB, then test whether shorter ZLBs will also enforce it. Otherwise, extend the sequence of temporary ZLBs using the same approch as 2.\nOnce we have successfully found a minimum length that guarantees non-negative rates for the first sequence of periods, re-run the forecast using unanticipated monetary policy shocks to enforce any other sequences of periods with negative rates.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Note that sometimes extending the sequence of temporary ZLB regimes will cause two disjoint sequences of periods with negative rates to become contiguous, in which case we treat the two disjoint sequences as one connected sequences therafter.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"To use this method, the user runs a forecast as follows","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"# (optional) maximum permitted length for temporary ZLB regimes in the forecast\nm <= Setting(:max_temporary_altpol_length, max_zlb_length)\n\n# (optional) minimum permitted length for temporary ZLB regimes and the\n# ZLB regimes are assumed to start in the first period of the forecast\nm <= Setting(:min_temporary_altpol_length, min_zlb_length)\n\n# (optional) length of the contiguous ZLB prior to the first period of the\n# forecast, ending in the regime prior to the start of the forecast\nm <= Setting(:historical_temporary_altpolicy_lengh, hist_zlb_length)\n\nforecast_one(m, input_type, cond_type, output_vars; rerun_smoother = true,\n             zlb_method = :temporary_altpolicy,\n             set_regime_vals_altpolicy = my_set_regime_vals_altpolicy_fnct,\n             set_info_sets_altpolicy = my_set_info_sets_altpolicy_fnct,\n             update_regime_eqcond_info! = my_update_regime_econd_info_fnct!,\n             nan_endozlb_failures = false)","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The keyword arguments are briefly described below. For more details, see the docstring for forecast_one.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"rerun_smoother::Bool: needs to be true if the current sequence of temporary ZLB regimes start during the history or conditional horizon because changing the length of the temporary ZLB affects the smoothed estimate of the state at the start of the forecast.\nzlb_method::Symbol: set to :temporary_altpolicy to enforce the ZLB as a temporary policy. Otherwise, unanticipated monetary policy shocks will be used.\nset_regime_vals_altpolicy::Function: if there are regime-switching parameters, this function is needed to figure out what parameters should be assigned to the new model regimes added when extending the temporary ZLB length.\nset_info_sets_altpolicy::Function: if the Setting tvis_information_set is used, then we need to specify how to update tvis_information_set as new model regimes are added to extend the temporary ZLB length.\nupdate_regime_eqcond_info!::Function: specifies how to update regime_eqcond_info to include more or fewer regimes of temporary ZLB.\nnan_endozlb_failures::Bool: sometimes the ZLB cannot be enforced because rates are negative even when the ZLB extends throughout the entire forecast horizon or because the max ZLB length is reached. By default, we enforce the remainder of the forecast horizon with unanticipated monetary policy shocks. If this kwarg is true, we return NaNs rather than use unanticipated shocks.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"For further guidance on forecasting with an endogenously enforced ZLB, please see the script imperfectawarenesstempzlb_ait.jl with the keyword endozlb set to true.","category":"page"},{"location":"advanced_usage/#editing-extending-model-1","page":"Advanced Usage","title":"Editing or Extending a Model","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Users may want to extend or edit Model990 in a number of different ways.  The most common changes are listed below, in decreasing order of complexity:","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Add new parameters\nModify equilibrium conditions or measurement equations\nChange the values of various parameter fields (i.e. initial value, prior, transform, etc.)\nChange the values of various computational settings (i.e. reoptimize, n_mh_blocks)","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Points 1 and 2 often go together (adding a new parameter guarantees a change in equilibrium conditions), and are such fundamental changes that they increment the model specification number and require the definition of a new subtype of AbstractModel (for instance, Model991).  See Model specification for more details.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Any changes to the initialization of preexisting parameters are defined as a new model sub-specification, or subspec. While less significant than a change to the model's equilibrium conditions, changing the values of some parameter fields (especially priors) can have economic significance over and above settings we use for computational purposes. Parameter definitions should not be modified in the model object's constructor. First, incrementing the model's sub-specification number when parameters are changed improves model-level (as opposed to code-level) version control. Second, it avoids potential output filename collisions, preventing the user from overwriting output from previous estimations with the original parameters. The protocol for defining new sub-specifications is described in Model sub-specifications.","category":"page"},{"location":"advanced_usage/#model-specification-mspec-1","page":"Advanced Usage","title":"Model specification (m.spec)","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"A particular model, which corresponds to a subtype of AbstractModel, is defined as a set of parameters, equilibrium conditions (defined by the eqcond function) and measurement equations (defined by the measurement function).  Therefore, the addition of new parameters, states, or observables, or any changes to the equilibrium conditions or measurement equations necessitate the creation of a new subtype of AbstractModel.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"To create a new model object, we recommend doing the following:","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Duplicate the m990 directory within the models directory. Name the new directory mXXX.jl, where XXX is your chosen model specification number or string. Rename m990.jl in this directory to mXXX.jl.\nIn the mXXX/ directory, change all references to Model990 to ModelXXX.\nEdit the m990.jl, eqcond.jl, and measurement.jl files as you see fit.  If adding new states, equilibrium conditions, shocks, or observables, be sure to add them to the appropriate list in init_model_indices.\nOpen the module file, src/DSGE.jl. Add ModelXXX to the list of functions to export, and include each of the files in src/model/mXXX.","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"It is very important that you include the default settings by adding the line default_settings!(m) inside the function that creates a new instance of your model. Otherwise, many methods in DSGE.jl will fail because they assume many settings have default values that are set by default_settings!.","category":"page"},{"location":"advanced_usage/#model-sub-specifications-msubspec-1","page":"Advanced Usage","title":"Model sub-specifications (m.subspec)","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Model990 sub-specifications are initialized by overwriting initial parameter definitions before the model object is fully constructed. This happens via a call to init_subspec in the Model990 constructor. (Clearly, an identical protocol should be followed for new model types as well.)","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"To create a new sub-specification (e.g., subspec 1) of Model990, edit the file src/models/subspecs.jl as follows (note that this example is not actually sub-specification 1 of Model990. In the source code, our sub-specification 5 is provided as additional example.):","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Step 1. Define a new function, ss1, that takes an object of type Model990 (not    AbstractModel!) as an argument. In this function, construct new parameter objects and    overwrite existing model parameters using the <= syntax. For example,","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"function ss1(m::Model990)\n    m <= parameter(:Î¹_w, 0.000, (0.0, .9999), (0.0,0.9999), DSGE.Untransformed(), Normal(0.0,1.0), fixed=false,\n                   description=\"Î¹_w: Some description.\",\n                   tex_label=\"\\\\iota_w\")\n    m <= parameter(:Î¹_p, 0.0, fixed=true,\n                   description= \"Î¹_p: Some description\"\n                   tex_label=\"\\\\iota_p\")\nend","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"Step 2. Add an elseif condition to init_subspec:","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"    ...\n    elseif subspec(m) == \"ss1\"\n        return ss1(m)\n    ...","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"To construct an instance of Model990, ss1, call the constructor for Model990 with ss1 as an argument. For example,","category":"page"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"m = Model990(\"ss1\")","category":"page"},{"location":"advanced_usage/#Additional-Tips-1","page":"Advanced Usage","title":"Additional Tips","text":"","category":"section"},{"location":"advanced_usage/#","page":"Advanced Usage","title":"Advanced Usage","text":"The file abstractdsgemodel.jl defines numerous auxiliary functions, which allow the user to more easily call standard settings or count the number of dimensions for important variables. For example, data_vintage(m) returns the vintage of the data specified by the model object m. Additionally see abstractmodel.jl in ModelConstructors.jl for more functions like n_observables(m), which returns the number of observables in m.","category":"page"},{"location":"model_implementation_details/#Model-Implementation-Details-1","page":"Model Implementation Details","title":"Model Implementation Details","text":"","category":"section"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"CurrentModule = DSGE","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"This section describes important functions and implementation features in greater detail. If the user is interested only in running the default model and reproducing the estimation results, this section can be ignored. Additional documentation can also be found in function documentation or in-line.","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"This section focuses on what the code does and why. Docstrings and the code itself (including comments) provide detailed information regarding how these basic procedures are implemented.","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"As of DSGE.jl v0.7.3, many types housed in the DSGE.jl package have been moved to ModelConstructors.jl. The following types now belong in ModelConstructors.jl:","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"AbstractModel\nAbstractParameter\nParameter{T<:Number, U<:Transform}: The abstract supertype for parameters that are directly estimated.\nUnscaledParameter{T<:Number, U:<Transform}: Concrete type for parameters that do not need to be scaled for equilibrium conditions.\nScaledParameter{T<:Number, U:<Transform}: Concrete type for parameters that are scaled for equilibrium conditions.\nSteadyStateParameter{T<:Number}: Concrete type for steady-state parameters.\nSetting\nObservable\nPseudoObservable\nTypes and functions used to define and work with priors","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"We refer users to the documentation provided for ModelConstructors.jl for information about the implementation of these types. Below, we document the implementation of DSGE.jl specific types.","category":"page"},{"location":"model_implementation_details/#The-AbstractDSGEModel-Type-1","page":"Model Implementation Details","title":"The AbstractDSGEModel Type","text":"","category":"section"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"The AbstractModel type has been rewritten to be an abstract type for any model with parameters. We have replaced the AbstractModel type in DSGE.jl with the AbstractDSGEModel type, which is a subtype of AbstractModel and includes various methods that standard DSGE models need.","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"The AbstractDSGEModel type provides a common interface for all DSGE model objects, which greatly facilitates the implementation of new model specifications. Any concrete subtype of AbstractDSGEModel can be passed to any function defined for AbstractDSGEModel, provided that the concrete type has the fields that the function expects to be available.","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"Model990 is one example of a concrete subtype of AbstractDSGEModel that implements a single specification of the New York Fed DSGE model. All model objects must have these fields so that the interface for AbstractDSGEModel objects works correctly.  See Editing or Extending a Model for more detail.","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"Model990","category":"page"},{"location":"model_implementation_details/#DSGE.Model990","page":"Model Implementation Details","title":"DSGE.Model990","text":"Model990{T} <: AbstractRepModel{T}\n\nThe Model990 type defines the structure of the New York Fed DSGE model.\n\nFields\n\nParameters and Steady-States\n\nparameters::Vector{AbstractParameter}: Vector of all time-invariant model parameters.\nsteady_state::Vector{AbstractParameter}: Model steady-state values, computed as a function of elements of parameters.\nkeys::OrderedDict{Symbol,Int}: Maps human-readable names for all model parameters and steady-states to their indices in parameters and steady_state.\n\nInputs to Measurement and Equilibrium Condition Equations\n\nThe following fields are dictionaries that map human-readable names to row and column indices in the matrix representations of of the measurement equation and equilibrium conditions.\n\nendogenous_states::OrderedDict{Symbol,Int}: Maps each state to a column in the measurement and equilibrium condition matrices.\nexogenous_shocks::OrderedDict{Symbol,Int}: Maps each shock to a column in the measurement and equilibrium condition matrices.\nexpected_shocks::OrderedDict{Symbol,Int}: Maps each expected shock to a column in the measurement and equilibrium condition matrices.\nequilibrium_conditions::OrderedDict{Symbol,Int}: Maps each equlibrium condition to a row in the model's equilibrium condition matrices.\nendogenous_states_augmented::OrderedDict{Symbol,Int}: Maps lagged states to their columns in the measurement and equilibrium condition equations. These are added after gensys solves the model.\nobservables::OrderedDict{Symbol,Int}: Maps each observable to a row in the model's measurement equation matrices.\npseudo_observables::OrderedDict{Symbol,Int}: Maps each pseudo-observable to a row in the model's pseudo-measurement equation matrices.\n\nModel Specifications and Settings\n\nspec::String: The model specification identifier, \"m990\", cached here for filepath computation.\nsubspec::String: The model subspecification number, indicating that some parameters from the original model spec (\"ss3\") are initialized differently. Cached here for filepath computation.\nsettings::Dict{Symbol,Setting}: Settings/flags that affect computation without changing the economic or mathematical setup of the model.\ntest_settings::Dict{Symbol,Setting}: Settings/flags for testing mode\n\nOther Fields\n\nrng::MersenneTwister: Random number generator. Can be is seeded to ensure reproducibility in algorithms that involve randomness (such as Metropolis-Hastings).\ntesting::Bool: Indicates whether the model is in testing mode. If true, settings from m.test_settings are used in place of those in m.settings.\nobservable_mappings::OrderedDict{Symbol,Observable}: A dictionary that stores data sources, series mnemonics, and transformations to/from model units. DSGE.jl will fetch data from the Federal Reserve Bank of St. Louis's FRED database; all other data must be downloaded by the user. See load_data and Observable for further details.\npseudo_observable_mappings::OrderedDict{Symbol,PseudoObservable}: A dictionary that stores names and transformations to/from model units. See PseudoObservable for further details.\n\n\n\n\n\n","category":"type"},{"location":"model_implementation_details/#Defining-Indices-1","page":"Model Implementation Details","title":"Defining Indices","text":"","category":"section"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"The model's equilibrium conditions and observables are represented as fairly large matrices, and keeping track of which rows and columns correspond to which states, shocks, equations, etc. can be confusing. To improve clarity, we define several dictionaries that map variable names to indices in these matrices:","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"endogenous_states: Indices of endogenous model states\nexogenous_shocks: Indices of exogenous shocks\nexpected_shocks: Indices of expectation shocks\nequilibrium_conditions: Indices of equilibrium condition equations\nendogenous_states_augmented: Indices of model states, after model solution and system augmentation\nobservables:  Indices of named observables","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"This approach has a number of advantages. Most importantly, it is robust to inadvertent typos or indexing errors. Since the actual index number doesn't matter to us, the user only needs to define the names of their equilibrium conditions, states, and other variables. Adding states is easy - we have only to add them to the appropriate list in the model constructor, and they will be assigned an index.","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"As an example, consider the model's equilibrium conditions. The canonical representation of the equilibrium conditions is","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"Î“0 s_t = Î“1 s_{t-1} + C + Î¨ Îµ_t + Î  Î·_t","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"where Î“0, Î“1, C, Î¨, and Î  are matrices of coefficients for s_t (states at time t), s_{t-1} (lagged states), Îµ_t (exogenous shocks) and Î·_t (expectational shocks). Each row of these matrices corresponds to an equilibrium condition, which we define using a descriptive name (for example, we name the consumption Euler equation :euler). States (columns of Î“0 and Î“1), exogenous shocks (columns of Î¨), and expectational shocks (columns Î ) also have names.","category":"page"},{"location":"model_implementation_details/#Type-Interfaces-1","page":"Model Implementation Details","title":"Type Interfaces","text":"","category":"section"},{"location":"model_implementation_details/#AbstractDSGEModel-Interface-1","page":"Model Implementation Details","title":"AbstractDSGEModel Interface","text":"","category":"section"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"DSGE.update!\nDSGE.transform_to_model_space!\nDSGE.load_parameters_from_file\nDSGE.specify_mode!\nDSGE.specify_hessian!","category":"page"},{"location":"model_implementation_details/#DSGE.update!","page":"Model Implementation Details","title":"DSGE.update!","text":"update!(m::AbstractDSGEModel, values::Vector{T}) where T<:AbstractFloat\n\nUpdate m.parameters with values, recomputing the steady-state parameter values.\n\nArguments:\n\nm: the model object\nvalues: the new values to assign to non-steady-state parameters.\n\n\n\n\n\nupdate!(m::AbstractDSGEModel, values::ParameterVector{T};\n    regime_switching::Bool = false, toggle::Bool = true) where T\n\nUpdate m.parameters with values, recomputing the steady-state parameter values.\n\nArguments\n\nm: the model object\nvalues: the new values to assign to non-steady-state parameters.\n\nKeyword\n\nregime_switching: if true, then we assume the parameters are regime-switching,   in which case update! assumes the value field   of each parameter in valuesholds the parameter value in the first regime, and   then we update the fieldregimes` for each parameter\ntoggle: if true, we call ModelConstructors.toggle_regime!(values) before   updating any values to ensure the value field of the parameters in values   correspond to regime 1 values.\n\n\n\n\n\n","category":"function"},{"location":"model_implementation_details/#DSGE.transform_to_model_space!","page":"Model Implementation Details","title":"DSGE.transform_to_model_space!","text":"transform_to_model_space!(m::AbstractDSGEModel, values::Vector{T}; regime_switching::Bool = false) where T<:AbstractFloat\n\nTransforms values from the real line to the model space, and assigns values[i] to m.parameters[i].value for non-steady-state parameters. Recomputes the steady-state parameter values.\n\nArguments\n\nm: the model object\nvalues: the new values to assign to non-steady-state parameters.\nregime_switching: set to true if the model's parameters are regime-switching\n\n\n\n\n\ntransform_to_model_space!(m::AbstractDSGEVARModel, values::Vector{T}) where T<:AbstractFloat\n\nTransforms values from the real line to the model space, and assigns values[i] to m.parameters[i].value for non-steady-state parameters. Recomputes the steady-state paramter values.\n\nArguments\n\nm: the model object\nvalues: the new values to assign to non-steady-state parameters.\n\n\n\n\n\n","category":"function"},{"location":"model_implementation_details/#DSGE.load_parameters_from_file","page":"Model Implementation Details","title":"DSGE.load_parameters_from_file","text":"load_parameters_from_file(m::AbstractDSGEModel,path::String)\n\nReturns a vector of parameters, read from a file, suitable for updating m.\n\n\n\n\n\n","category":"function"},{"location":"model_implementation_details/#DSGE.specify_mode!","page":"Model Implementation Details","title":"DSGE.specify_mode!","text":"specify_mode!(m::AbstractDSGEModel, mode_file::String=\"\"; verbose=:low)\n\nUpdates the values of m.parameters with the values from mode_file. Sets reoptimize setting to false.\n\nUsage: should be run before calling estimate(m), e.g.:\n\nm = Model990()\nspecify_mode!(m, modefile)\nestimate(m)\n\n\n\n\n\n","category":"function"},{"location":"model_implementation_details/#DSGE.specify_hessian!","page":"Model Implementation Details","title":"DSGE.specify_hessian!","text":"specify_hessian!(m::AbstractDSGEModel, path::String=\"\"; verbose=:low)\n\nSpecify a Hessian matrix calculated at the posterior mode to use in the model estimation. If no path is provided, will attempt to detect location.\n\n\n\n\n\n","category":"function"},{"location":"model_implementation_details/#Parameter-and-Setting-Interface-1","page":"Model Implementation Details","title":"Parameter and Setting Interface","text":"","category":"section"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"See ModelConstructors.jl.","category":"page"},{"location":"model_implementation_details/#The-PoolModel-Type-1","page":"Model Implementation Details","title":"The PoolModel Type","text":"","category":"section"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"A PoolModel has a very similar structure to concrete subtypes of AbstractDSGEModel, but certain fields have been removed because they are not necessary for a PoolModel, such as exogenous_shocks. We chose to define PoolModel as a concrete subtype of AbstractDSGEModel because, for the foreseeable future, we have no plans to implement a more complex type hierarchy for types that perform model averaging. By defining PoolModel as a subtype of a AbstractDSGEModel and taking advantage of multiple dispatch, less refactoring was required to make PoolModel compatible with DSGE.jl functions like estimate.","category":"page"},{"location":"model_implementation_details/#The-DSGEVAR-Type-1","page":"Model Implementation Details","title":"The DSGEVAR Type","text":"","category":"section"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"Like the PoolModel type, the DSGEVAR is not a DSGE model, but unlike the PoolModel, which is still a subtype of AbstractDSGEModel, DSGEVAR has the following type hierarchy:","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"DSGEVAR <: AbstractDSGEVARModel <: AbstractVARModel <: AbstractModel","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"The behavior of DSGEVAR is sufficiently distinct from AbstractDSGEModel and requires enough specialized functions that simply using multiple dispatch did not seem an effective way to implement DSGEVAR. Moreover, several functions, like the impulse_responses code, apply to generic VARs. Restricting these functions to DSGEVAR did not seem like the best idea.","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"In the near term, there are no plans to further flesh out the VAR capabilities of DSGE.jl, but in the longer term, we may add VAR routines to DSGE.jl or implement them in a separate package. If we do create a separate package, then DSGEVAR will be refactored to be compatible with this new package.","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"Features that have not been fully implemented for DSGEVAR include","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"Loading data directly from the DSGEVAR\nCalling forecast_one on a DSGEVAR\nCalling compute_meansbands on a DSGEVAR\nPlotting with a DSGEVAR\nAlternative policy","category":"page"},{"location":"model_implementation_details/#The-DSGEVECM-Type-1","page":"Model Implementation Details","title":"The DSGEVECM Type","text":"","category":"section"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"The DSGEVECM extends the DSGEVAR to accommodate DSGE-VECM methods. It has the following type hierarchy:","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"DSGEVECM <: AbstractDSGEVECMModel <: AbstractDSGEVARModel <: AbstractVARModel <: AbstractModel","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"In the near term, there are no plans to further flesh out the VECM capabilities of DSGE.jl, but in the longer term, we may add VECM routines to DSGE.jl or implement them in a separate package. If we do create a separate package, then DSGEVECM will be refactored to be compatible with this new package.","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"Features that have not been fully implemented for DSGEVECM include","category":"page"},{"location":"model_implementation_details/#","page":"Model Implementation Details","title":"Model Implementation Details","text":"Testing the creation of a DSGEVECM from a DSGE\nTests that a DSGEVECM can be estimated properly\nLoading data directly from the DSGEVECM\nCalling forecast_one on a DSGEVECM\nCalling compute_meansbands on a DSGEVECM\nPlotting with a DSGEVECM\nAlternative policy","category":"page"},{"location":"contributing/#contributing-1","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"","category":"section"},{"location":"contributing/#Notes-for-DSGE.jl-Contributors-1","page":"Contributing to DSGE.jl","title":"Notes for DSGE.jl Contributors","text":"","category":"section"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"We are continuing to add more features to this package. Please see the README for details.","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"As these steps are under development, we would welcome improvements to the existing code from the community. Some examples could be:","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"Performance improvements\nAlternatives to algorithms used here (optimization, hessian, etc.)\nExtension of the DSGE-VAR, DSGE-VECM, and VAR code a. Allowing measurement error uncorrelated with the exogenous structural shocks. b. Implementing a test DSGE model with cointegrating relationships in the    measurement equation so that the DSGEVECM object and functions defined    for it can be tested, e.g. impulse_responses. Currently, most of the tested    DSGE-VECM code are internal functions which are not intended to be the    user-level interface. For example, the impulse responses of a DSGE-VECM    can be calculated if the state space system matrices are given as inputs, but we do    not have tests for the wrapper impulse_responses(m, . . .), where    `m <: AbstractDSGEVECMModel'.\nExtension of regime-switching code to include regime-switching beyond changes in parameter values and in policy rules a. Example \"toy\" extension: A second sector is introduced at some point in the history, so the final consumption good is now an aggregate of intermediate goods from two sectors. This example would require extending solution functions (e.g. solve and compute_system) to be robust to regime switches in the equilibrium conditions of a DSGE model.\nExtension of model averaging techniques beyond PoolModel\nOther general improvements a. Adding documentation/test coverage b. Adding existing notable DSGE models into the models/ directory","category":"page"},{"location":"contributing/#Git-Recommendations-For-Pull-Requests-1","page":"Contributing to DSGE.jl","title":"Git Recommendations For Pull Requests","text":"","category":"section"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"These are adapted from JuliaLang.","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"Avoid working from the main branch of your fork, creating a new branch will make it easier if DSGE's main changes and you need to update your pull request.\nTry to squash together small commits that make repeated changes to the same section of code so your pull request is easier to review, and Julia's history won't have any broken intermediate commits. A reasonable number of separate well-factored commits is fine, especially for larger changes.\nIf any conflicts arise due to changes in DSGE's main, prefer updating your pull request branch with git rebase versus git merge or git pull, since the latter will introduce merge commits that clutter the git history with noise that makes your changes more difficult to review.\nDescriptive commit messages are good.\nUsing git add -p or git add -i can be useful to avoid accidentally committing unrelated changes.\nGitHub does not send notifications when you push a new commit to a pull request, so please add a comment to the pull request thread to let reviewers know when you've made changes.\nWhen linking to specific lines of code in discussion of an issue or pull request, hit the y key while viewing code on GitHub to reload the page with a URL that includes the specific version that you're viewing. That way any lines of code that you refer to will still make sense in the future, even if the content of the file changes.\nWhitespace can be automatically removed from existing commits with git rebase.\nTo remove whitespace for the previous commit, run git rebase --whitespace=fix HEAD~1.\nTo remove whitespace relative to the main branch, run git rebase --whitespace=fix main.","category":"page"},{"location":"contributing/#DSGE-Julia-Style-Guide-1","page":"Contributing to DSGE.jl","title":"DSGE Julia Style Guide","text":"","category":"section"},{"location":"contributing/#Intro-1","page":"Contributing to DSGE.jl","title":"Intro","text":"","category":"section"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"This document lists Julia coding recommendations consistent with best practices in the software development community. The recommendations are based on guidelines for other languages collected from a number of sources and on personal experience. These guidelines are written with the New York Fed DSGE code in mind. All pull requests submitted should follow these general style guidelines.","category":"page"},{"location":"contributing/#Naming-conventions-1","page":"Contributing to DSGE.jl","title":"Naming conventions","text":"","category":"section"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"Emphasize readability! Our goal is for the code to mimic the mathematical notation used in New York Fed DSGE papers as closely as possible.","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"The names of variables should document their meaning or","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"use. Variables with a large scope should have especially meaningful names. Variables with a small scope can have short names.","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"Exhibit consistency with the existing codebase.\nModules and type names in UpperCamelCase\nVariable names in snake_case.","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"Variable names should be in lower case, using underscores to separate parts of a compound variable name. For example, steady_state and equilibrium_conditions are two fields in the Model990() object that follow this convention. Also notice that, though the words could be shortened, they are spelled out for maximum clarity.","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"The prefix n_ should be used for variables representing the","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"number of objects (e.g. n_parameters or n_anticipated_shocks) use the suffix s as is natural in spoken language.","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"Negative Boolean variable names should be avoided. A problem arises","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"when such a name is used in conjunction with the logical negation operator as this results in a double negative. It is not immediately apparent what !isNotFound means.  Use isFound. Avoid isNotFound.","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"Named constants can be all uppercase using underscore to separate words:","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"MAX_ITERATIONS","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"Naming mathematical objects","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"Variables with mathematical significance should use unicode characters and imitate LaTeX syntax.  For example, Ï should be used to name the autocorrelation coefficient in an AR(1) process, and Ïƒ should be used to name standard deviation. Parameters in the text should keep the same symbol in the code (e.g. Î± in the code is the same Î± as in this paper, and takes on it usual significance as the capital share in a Cobb-Douglas output function.","category":"page"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"General conventions\nUnderscores can and should be used when the variable refers to a mathematical object that has a subscript. (In this case, we are imitating LaTeX syntax.) For example, r_m in LaTeX should be represented by the variable r_m.\nIf the mathematical object has multiple subscripts, for example x_ij, simply concatenate the subscripts: x_ij.\nIf the object has superscripts as well as subscripts, for example y^f_t, separate the superscripts with an underscore and place them first: y_f_t.\nFor compatibility with existing code, variables with numeric subscripts should exclude the underscore: G0, Ïˆ1.\nMatrices that have mathematical significance (e.g. the matrices of the transition and measurement equations) should be upper case, as they are in mathematical notation, and can repeat the letter to avoid collisions: TTT or QQ.\nSymbols such as overbars (which indicate mean values) and  tildes (which indicate log-deviations from the steady state) are written using a 3- or 4-letter abbreviation immediately after the variable they modify: kbar_t, ztil (z tilde).\nStars indicating steady-state variables are included as subscripts: Ï€_star_t\nSuffixes\nTime: Consistent with the previous bullet points, the suffix _t as in x_t signifies the value of x at time t. The suffix _t1 signifies the value of x at time t-1.\nShocks: The suffix _sh refers to a model shock.\nPrefixes\nThe prefix eq_ refers to an equilibrium condition.\nThe prefix obs_ refers to an observable.\nThe prefix E refers to the expectation operator.\nThe prefix I refers to the indicator operator.\nObservables with the prefix g refer to growth rates.","category":"page"},{"location":"contributing/#Code-Formatting-Guidelines-1","page":"Contributing to DSGE.jl","title":"Code Formatting Guidelines","text":"","category":"section"},{"location":"contributing/#","page":"Contributing to DSGE.jl","title":"Contributing to DSGE.jl","text":"Indent 4 spaces\nWrap lines at 92 characters\nUse whitespace to enhance readability\nNo trailing whitespace","category":"page"},{"location":"pkg_structure/#[DSGE.jl](https://github.com/FRBNY-DSGE/DSGE.jl)-1","page":"DSGE.jl","title":"DSGE.jl","text":"","category":"section"},{"location":"pkg_structure/#doc/:-Code-and-model-documentation.-1","page":"DSGE.jl","title":"doc/: Code and model documentation.","text":"","category":"section"},{"location":"pkg_structure/#examples/:-example-scripts-1","page":"DSGE.jl","title":"examples/: example scripts","text":"","category":"section"},{"location":"pkg_structure/#save/:-Sample-input-files;-default-input/output-directories.-1","page":"DSGE.jl","title":"save/: Sample input files; default input/output directories.","text":"","category":"section"},{"location":"pkg_structure/#src/-1","page":"DSGE.jl","title":"src/","text":"","category":"section"},{"location":"pkg_structure/#DSGE.jl:-The-main-module-file.-1","page":"DSGE.jl","title":"DSGE.jl: The main module file.","text":"","category":"section"},{"location":"pkg_structure/#abstractdsgemodel.jl:-Defines-the-AbstractModel-type.-1","page":"DSGE.jl","title":"abstractdsgemodel.jl: Defines the AbstractModel type.","text":"","category":"section"},{"location":"pkg_structure/#abstractvarmodel.jl:-Defines-the-AbstractVARModel,-AbstractDSGEVARModel,-and-AbstractDSGEVECMModel-types.-1","page":"DSGE.jl","title":"abstractvarmodel.jl: Defines the AbstractVARModel, AbstractDSGEVARModel, and AbstractDSGEVECMModel types.","text":"","category":"section"},{"location":"pkg_structure/#defaults.jl:-Default-settings-for-models.-1","page":"DSGE.jl","title":"defaults.jl: Default settings for models.","text":"","category":"section"},{"location":"pkg_structure/#statespace_types.jl:-Defines-types-for-computing-the-state-space-representation-of-models.-1","page":"DSGE.jl","title":"statespace_types.jl: Defines types for computing the state-space representation of models.","text":"","category":"section"},{"location":"pkg_structure/#statespace_functions.jl:-Defines-functions-for-computing-the-state-space-representation-of-models.-1","page":"DSGE.jl","title":"statespace_functions.jl: Defines functions for computing the state-space representation of models.","text":"","category":"section"},{"location":"pkg_structure/#data/:-Manipulating-and-updating-input-dataset.-1","page":"DSGE.jl","title":"data/: Manipulating and updating input dataset.","text":"","category":"section"},{"location":"pkg_structure/#solve/:-Solving-the-model;-includes-gensys.jl-code.-1","page":"DSGE.jl","title":"solve/: Solving the model; includes gensys.jl code.","text":"","category":"section"},{"location":"pkg_structure/#estimate/:-Optimization,-posterior-sampling,-and-other-functionality.-1","page":"DSGE.jl","title":"estimate/: Optimization, posterior sampling, and other functionality.","text":"","category":"section"},{"location":"pkg_structure/#forecast/:-Forecasts,-smoothing,-shock-decompositions,-and-impulse-response-functions.-1","page":"DSGE.jl","title":"forecast/: Forecasts, smoothing, shock decompositions, and impulse response functions.","text":"","category":"section"},{"location":"pkg_structure/#decomp/:-Decompose-changes-in-forecasts-into-three-reasons:-new-data,-data-revisions,-and-changes-in-the-calibration.-1","page":"DSGE.jl","title":"decomp/: Decompose changes in forecasts into three reasons: new data, data revisions, and changes in the calibration.","text":"","category":"section"},{"location":"pkg_structure/#analysis/:-Moment-tables-of-estimated-parameters,-computation-of-forecast-means-and-bands.-1","page":"DSGE.jl","title":"analysis/: Moment tables of estimated parameters, computation of forecast means and bands.","text":"","category":"section"},{"location":"pkg_structure/#altpolicy/:-Infrastructure-for-forecasting-under-alternative-monetary-policy-rules.-1","page":"DSGE.jl","title":"altpolicy/: Infrastructure for forecasting under alternative monetary policy rules.","text":"","category":"section"},{"location":"pkg_structure/#scenarios/:-Forecasting-alternative-scenarios.-1","page":"DSGE.jl","title":"scenarios/: Forecasting alternative scenarios.","text":"","category":"section"},{"location":"pkg_structure/#plot/:-Plot-estimation-results,-forecasts,-etc.-1","page":"DSGE.jl","title":"plot/: Plot estimation results, forecasts, etc.","text":"","category":"section"},{"location":"pkg_structure/#packet/:-Automatically-generate-documents-with-results-from-forecasts-and-estimations.-1","page":"DSGE.jl","title":"packet/: Automatically generate documents with results from forecasts and estimations.","text":"","category":"section"},{"location":"pkg_structure/#models/-1","page":"DSGE.jl","title":"models/","text":"","category":"section"},{"location":"pkg_structure/#representative/:-Representative-agent-models.-1","page":"DSGE.jl","title":"representative/: Representative agent models.","text":"","category":"section"},{"location":"pkg_structure/#m990/:-Contains-code-to-define-and-initialize-version-990-of-the-New-York-Fed-DSGE-model.-1","page":"DSGE.jl","title":"m990/: Contains code to define and initialize version 990 of the New York Fed DSGE model.","text":"","category":"section"},{"location":"pkg_structure/#m990.jl:-Constructs-a-Model990-object.-1","page":"DSGE.jl","title":"m990.jl: Constructs a Model990 object.","text":"","category":"section"},{"location":"pkg_structure/#eqcond.jl:-Constructs-Model990-equilibrium-condition-matrices-1","page":"DSGE.jl","title":"eqcond.jl: Constructs Model990 equilibrium condition matrices","text":"","category":"section"},{"location":"pkg_structure/#measurement.jl:-Constructs-Model990-measurement-equation-matrices.-1","page":"DSGE.jl","title":"measurement.jl: Constructs Model990 measurement equation matrices.","text":"","category":"section"},{"location":"pkg_structure/#pseudo_measurement.jl:-Constructs-Model990-pseudo-measurement-equation-matrices.-1","page":"DSGE.jl","title":"pseudo_measurement.jl: Constructs Model990 pseudo-measurement equation matrices.","text":"","category":"section"},{"location":"pkg_structure/#subspecs.jl:-Code-for-model-sub-specifications-is-defined-here.-See-[Editing-or-Extending-a-Model](@ref-editing-extending-model)-for-details-on-constructing-model-sub-specifications.-1","page":"DSGE.jl","title":"subspecs.jl: Code for model sub-specifications is defined here. See Editing or Extending a Model for details on constructing model sub-specifications.","text":"","category":"section"},{"location":"pkg_structure/#augment_states.jl:-Code-for-augmenting-the-state-space-system-after-model-solution.-1","page":"DSGE.jl","title":"augment_states.jl: Code for augmenting the state space system after model solution.","text":"","category":"section"},{"location":"pkg_structure/#[[m991/]]:-Code-for-new-models-should-be-kept-in-directories-at-this-level-in-the-directory-tree-1","page":"DSGE.jl","title":"[[m991/]]: Code for new models should be kept in directories at this level in the directory tree","text":"","category":"section"},{"location":"pkg_structure/#heterogeneous/:-Heterogeneous-agent-models-1","page":"DSGE.jl","title":"heterogeneous/: Heterogeneous agent models","text":"","category":"section"},{"location":"pkg_structure/#poolmodel/:-PoolModel-type-for-model-averaging.-1","page":"DSGE.jl","title":"poolmodel/: PoolModel type for model averaging.","text":"","category":"section"},{"location":"pkg_structure/#var/:-DSGE-VAR-and-DSGE-VECM-models.-1","page":"DSGE.jl","title":"var/: DSGE-VAR and DSGE-VECM models.","text":"","category":"section"},{"location":"pkg_structure/#test/:-Module-test-suite.-1","page":"DSGE.jl","title":"test/: Module test suite.","text":"","category":"section"},{"location":"io_dirtree/#dataroot/:-Root-data-directory.-1","page":"<dataroot>/: Root data directory.","title":"<dataroot>/: Root data directory.","text":"","category":"section"},{"location":"io_dirtree/#data/:-Macroeconomic-input-data-series.-1","page":"<dataroot>/: Root data directory.","title":"data/:  Macroeconomic input data series.","text":"","category":"section"},{"location":"io_dirtree/#cond/:-Conditional-data,-i.e.-1","page":"<dataroot>/: Root data directory.","title":"cond/: Conditional data, i.e.","text":"","category":"section"},{"location":"io_dirtree/#","page":"<dataroot>/: Root data directory.","title":"<dataroot>/: Root data directory.","text":"[\"nowcast\"](https://en.wikipedia.org/wiki/Nowcasting_%28economics%29).","category":"page"},{"location":"io_dirtree/#user/:-User-created-or-sample-model-input-files.-1","page":"<dataroot>/: Root data directory.","title":"user/: User-created or sample model input files.","text":"","category":"section"},{"location":"io_dirtree/#saveroot/:-Root-save-directory.-1","page":"<dataroot>/: Root data directory.","title":"<saveroot>/: Root save directory.","text":"","category":"section"},{"location":"io_dirtree/#output_data/-1","page":"<dataroot>/: Root data directory.","title":"output_data/","text":"","category":"section"},{"location":"io_dirtree/#m990/:-Input/output-files-for-the-Model990-type.-A-model-of-type-SPEC-will-create-its-own-save-directory-SPEC/-at-this-level-in-the-directory-tree.-1","page":"<dataroot>/: Root data directory.","title":"m990/: Input/output files for the Model990 type. A model of type SPEC will create its own save directory SPEC/ at this  level in the directory tree.","text":"","category":"section"},{"location":"io_dirtree/#ss0/:-Subdirectory-for-subspec-0.-A-model-of-a-different-subspec-will-have-similar-directories-at-this-level-of-the-tree.-1","page":"<dataroot>/: Root data directory.","title":"ss0/: Subdirectory for subspec 0. A model of a different subspec will have similar directories at this level of the tree.","text":"","category":"section"},{"location":"io_dirtree/#estimate/-1","page":"<dataroot>/: Root data directory.","title":"estimate/","text":"","category":"section"},{"location":"io_dirtree/#figures/:-Plots-and-other-figures-1","page":"<dataroot>/: Root data directory.","title":"figures/: Plots and other figures","text":"","category":"section"},{"location":"io_dirtree/#tables/:-LaTeX-tables-1","page":"<dataroot>/: Root data directory.","title":"tables/: LaTeX tables","text":"","category":"section"},{"location":"io_dirtree/#raw/:-Raw-output-data-from-estimation-step-1","page":"<dataroot>/: Root data directory.","title":"raw/: Raw output data from estimation step","text":"","category":"section"},{"location":"io_dirtree/#work/:-Derived-data-files-created-using-raw/-files-as-input-1","page":"<dataroot>/: Root data directory.","title":"work/: Derived data files created using raw/ files as input","text":"","category":"section"},{"location":"io_dirtree/#[xxx/]:-Other-model-outputs,-such-as-forecasts,-impulse-response-functions,-and-shock-decompositions;-subdirectory-structure-mirrors-that-of-estimate.-1","page":"<dataroot>/: Root data directory.","title":"[xxx/]: Other model outputs, such as forecasts, impulse response functions, and shock decompositions; subdirectory structure mirrors that of estimate.","text":"","category":"section"},{"location":"intro/#DSGE.jl-1","page":"DSGE.jl","title":"DSGE.jl","text":"","category":"section"},{"location":"intro/#","page":"DSGE.jl","title":"DSGE.jl","text":"CurrentModule = DSGE","category":"page"},{"location":"intro/#","page":"DSGE.jl","title":"DSGE.jl","text":"The DSGE.jl package implements the FRBNY DSGE model and provides general code to estimate many user-specified DSGE models. The package is introduced in the Liberty Street Economics blog post The FRBNY DSGE Model Meets Julia.","category":"page"},{"location":"intro/#","page":"DSGE.jl","title":"DSGE.jl","text":"This Julia-language implementation mirrors the MATLAB code included in the Liberty Street Economics blog post The FRBNY DSGE Model Forecast.","category":"page"},{"location":"intro/#","page":"DSGE.jl","title":"DSGE.jl","text":"FRBNY is currently working on extending the code to include forecasts and other features. Extensions of the DSGE model code may be released in the future at the discretion of FRBNY.","category":"page"},{"location":"intro/#Table-of-Contents-1","page":"DSGE.jl","title":"Table of Contents","text":"","category":"section"},{"location":"intro/#","page":"DSGE.jl","title":"DSGE.jl","text":"Pages = [\n  \"model_design.md\",\n  \"running_existing_model.md\",\n  \"advanced_usage.md\",\n  \"input_data.md\",\n  \"frbny_data.md\",\n  \"implementation_details.md\",\n  \"solving.md\",\n  \"estimation.md\",\n  \"contributing.md\",\n  \"license.md\"\n]","category":"page"},{"location":"intro/#Acknowledgements-1","page":"DSGE.jl","title":"Acknowledgements","text":"","category":"section"},{"location":"intro/#","page":"DSGE.jl","title":"DSGE.jl","text":"Developers of this package at FRBNY include","category":"page"},{"location":"intro/#","page":"DSGE.jl","title":"DSGE.jl","text":"Abhi Gupta\nPearl Li\nErica Moszkowski\nMicah Smith","category":"page"},{"location":"intro/#","page":"DSGE.jl","title":"DSGE.jl","text":"Contributors to this package at QuantEcon include","category":"page"},{"location":"intro/#","page":"DSGE.jl","title":"DSGE.jl","text":"Zac Cranko\nSpencer Lyon\nPablo Winant","category":"page"},{"location":"intro/#","page":"DSGE.jl","title":"DSGE.jl","text":"The gensys and csminwel routines DSGE.gensys and DSGE.csminwel are based on routines originally copyright Chris Sims. The files are released here with permission of Chris Sims under the BSD-3 License.","category":"page"},{"location":"intro/#","page":"DSGE.jl","title":"DSGE.jl","text":"The kalman_filter routine is loosely based on a version of the Kalman filter algorithm originally copyright Federal Reserve Bank of Atlanta and written by Iskander Karibzhanov. The files are released here with permission of the Federal Reserve Bank of Atlanta under the BSD-3 License.","category":"page"},{"location":"running_existing_model/#Running-an-Existing-Model-1","page":"Running An Existing Model","title":"Running an Existing Model","text":"","category":"section"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"The DSGE.jl package provides several example models:","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"A simple three-equation DSGE model from An and Schorfheide (2006)\nThe well-known Smets and Wouters (2007) model\nThe New York Fed DSGE model (version 990.2), which was introduced in this blog post\nThe New York Fed DSGE model (version 1002.9), which is documented here\nThe New York Fed DSGE model (version 1010.18)\nSeveral methods for model averaging over two models from Del Negro et al. (2016) through the concrete type PoolModel.","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"You can run these models using the description provided here. If you were to implement another model using DSGE.jl, these procedures can also be used to estimate those models.","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"Please see examples/ on the GitHub or the equivalent folder inside your Julia packages directory for example scripts we have created.","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"For getting started, see these two scripts.","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"run_default.jl: a simple example of the standard workflow with DSGE.jl\nmake_packet.jl: auto-generate a packet of plots and figures which help the user analyze estimation, forecast, and impulse response results. This script also provides an example of how we recommend structuring \"main\" files that launch a forecast and generate results with one \"click.\"","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"For more advanced usage, see","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"test_smc.jl: use SMC to estimate DSGE models.\ndecompose_forecast.jl: understand why a forecast has changed by running a forecast decomposition\nregime_switching.jl: set up a forecast with regime-switching in the history and forecast horizon\nuncertain_altpolicy_zlb.jl: set up a forecast with a temporary ZLB and imperfect awareness about the credibility of a policy switch to flexible AIT.\ntvis_system.jl: set up a state space system and forecast with time-varying information sets\nrun_dsgevar.jl: estimate and analyze impulse responses for a DSGEVAR.\nrun_dsgevecm.jl: analyze impulse response for DSGE-VECMs.","category":"page"},{"location":"running_existing_model/#Running-with-Default-Settings-1","page":"Running An Existing Model","title":"Running with Default Settings","text":"","category":"section"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"To estimate and forecast in Julia, simply create an instance of the model object and call estimate and forecast_all. A minimal example is reproduced below.","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"# estimate as of 2015-Q3 using the default data vintage from 2015 Nov 27\ncustom_settings = Dict{Symbol, Setting}(\n    :data_vintage        => Setting(:data_vintage, \"151127\"),\n    :date_forecast_start => Setting(:date_forecast_start, quartertodate(\"2015-Q4\")))\n\n# construct a model object\nm = Model990(custom_settings = custom_settings)\n\n# reoptimize parameter vector, compute Hessian at mode, and full posterior\n# parameter sampling\nestimate(m)\n\n# produce LaTeX tables of parameter moments\nmoment_tables(m)\n\n# forecast and compute means and bands using 10 processes\nmy_procs = addprocs(10)\n@everywhere using DSGE\n\nforecast_one(m, :full, :none, [:forecaststates, :forecastobs])\ncompute_meansbands(m, :full, :none, [:forecaststates, :forecastobs])\nrmprocs(my_procs)","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"For more details on changing the model's default settings, parameters, equilibrium conditions, etc., see Advanced Usage.","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"By default, the estimate routine loads the dataset, reoptimizes the initial parameter vector, computes the Hessian at the mode, and conducts full posterior parameter sampling using Metropolis-Hastings. (The initial parameter vector used is specified in the model's constructor.) Further options for estimation are described in Estimation:","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"To use updated data or alternative user-specified datasets, see Input Data.\nThe user may want to avoid reoptimizing the parameter vector and calculating the Hessian matrix at this new vector. Please see Reoptimizing.","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"For more information on the many types of forecasts that can be run on an existing or user-defined model, see Forecasting.","category":"page"},{"location":"running_existing_model/#Input/Output-Directory-Structure-1","page":"Running An Existing Model","title":"Input/Output Directory Structure","text":"","category":"section"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"The DSGE.jl estimation uses data files as input and produces large data files as outputs. One estimation saves several GB of parameter draws and related outputs. It is useful to understand how these files are loaded/saved and how to control this behavior.","category":"page"},{"location":"running_existing_model/#Directory-Tree-1","page":"Running An Existing Model","title":"Directory Tree","text":"","category":"section"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"The following subdirectory tree indicates the default locations of these input and outputs. Square brackets indicate directories in the tree that will become relevant as future features are implemented.","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"Note that this directory tree is not linked, although it appears to be.","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"Pages = [\"io_dirtree.md\"]\nDepth = 5","category":"page"},{"location":"running_existing_model/#Directory-Paths-1","page":"Running An Existing Model","title":"Directory Paths","text":"","category":"section"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"By default, input/output directories are located in the DSGE.jl package, along with the source code. Default values of the input/output directory roots:","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"saveroot(m): \"$(Pkg.dir())/DSGE/save\"\ndataroot(m): \"$(Pkg.dir())/DSGE/save/input_data\"","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"Note these locations can be overridden as desired. See Advanced Usage for more details.","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"m <= Setting(:saveroot, \"path/to/my/save/root\")\nm <= Setting(:dataroot, \"path/to/my/data/root\")","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"Utility functions are provided to create paths to input/output files. These should be used for best results.","category":"page"},{"location":"running_existing_model/#","page":"Running An Existing Model","title":"Running An Existing Model","text":"DSGE.inpath\nDSGE.rawpath\nDSGE.logpath\nDSGE.workpath\nDSGE.tablespath\nDSGE.figurespath","category":"page"},{"location":"scenarios/#Alternative-Scenarios-1","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"","category":"section"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"CurrentModule = DSGE","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"An alternative scenario is a set of forecasted paths for a subset of observables (\"targets\"), along with a subset of shocks (\"instruments\") which get the model to hit those paths. Each scenario has a description which tells a story about the scenario targets and instruments â€“ for example, \"High Spreads\" or \"Persistent Consumer Optimism\".","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"In an alternative scenario, we first solve for the values for specific shocks at specific horizons that create the paths of the observables imposed in the scenario. Only then do we run a regular forecast, imposing the path of shocks we just solved for and letting these propagate through the economy. (Compare to adding more periods of conditional data â€“ in this case, the model is free to use as many shocks as it wants to explain the deviation of the conditional data from trend in these additional periods.) This allows us to answer questions like:","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"Suppose a spread shock hits tomorrow, increasing spreads by 50 basis points. How large of a spread shock did this correspond to it? How does the economy respond? Suppose it is a discount factor shock instead.\nSuppose a discount factor shock hits for the next two quarters, causing a 100 basis point increase in spreads for two quarters, then reverting to zero (increase from baseline).  How does the economy respond?","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"We will conceive of all alternative scenario forecasts as occuring in \"deviations from baseline forecast\". That is, if the scenario consists of spreads increasing by 50 basis points, then we want this to be independent of the underlying model and baseline forecast, such that in our own forecast, spreads actually are 50 basis points above our baseline forecast.","category":"page"},{"location":"scenarios/#Basic-Scenarios-1","page":"Alternative Scenarios","title":"Basic Scenarios","text":"","category":"section"},{"location":"scenarios/#The-Scenario-Type-1","page":"Alternative Scenarios","title":"The Scenario Type","text":"","category":"section"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"The Scenario type encodes the basic information needed to forecast an alternative scenario. For now, we'll consider the following fields of the Scenario type:","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"key::Symbol: scenario identifier, appearing in file names\ndescription::String: longer name, e.g. \"High Spreads\"\ntarget_names::Vector{Symbol}: names of the observables targeted in this scenario. For the High Spreads scenario, this would just be [:obs_spread]. These observable names should correspond to keys in m.observables\ninstrument_names::Vector{Symbol}: names of the shocks used to hit the target paths, which should correspond to keys in m.exogenous_shocks. There must be at least as many instruments as there are targets. If this field is the empty array, then all model shocks will be used\ntargets::DataFrame: contains the specific target values, given in deviations from some baseline forecast. No :date field is required, since the scenario is assumed to begin in the first forecasted period of the model\ninstruments::DataFrame: initially empty DataFrame, which is populated after backing out the necessary shocks to hit the targets\nvintage::String: scenario vintage in yymmdd format, which can be different from the data vintage\nn_draws::Int: number of scenario draws. A scenario draw is one set of target paths. Often, multiple draws of target paths will be associated with one scenario name, which collectively make up a forecast distribution for the particular scenario. This field is usually initialized to 0 and then updated upon reading in the target draws","category":"page"},{"location":"scenarios/#Setting-Up-Input-Target-Paths-1","page":"Alternative Scenarios","title":"Setting Up Input Target Paths","text":"","category":"section"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"If you only want to forecast one scenario draw, it is sufficient to create an instance of the Scenario type and hard-code in the target paths. However, when forecasting multiple draws, it is convenient to load target draws from a file.","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"This file's name should be of the form inpath(m, \"scenarios\", <key>_<vintage>.jld) and should contain the following datasets:","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"arr::Array{Float64, 3}: array of target values of size ndraws x ntargets x horizon\ntarget_indices::OrderedDict{Symbol, Int}: maps target names to their indices along the ntargets dimension","category":"page"},{"location":"scenarios/#Forecasting-Scenarios-1","page":"Alternative Scenarios","title":"Forecasting Scenarios","text":"","category":"section"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"Forecasting scenarios is similar to running a normal full-distribution forecast, with some exceptions:","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"All draws of a particular scenario are forecasted under the modal parameters.\nSmoothed histories, shock decompositions, and IRFs are not supported.\nWe zero out the entries in the Q matrix (the variance-covariance of the shocks epsilon_t) corresponding to shocks which are not scenario instruments.\nForecasting is done in deviations from baseline. That is, let s^a_t and s^b_t be the state vectors under the alternative and baseline scenarios respectively, and define y^a_t and y^b_t analogously for observable vectors. Then the state space in deviations is\nbeginaligned\ns^a_t - s^b_t = T(s^a_t-1 - s^b_t-1) + R epsilon_t  mathrm(transition) \ny^a_t - y^b_t = Z(y^a_t - y^b_t)  mathrm(measurement)\nendaligned","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"The main function to run is forecast_scenario, which is similar in spirit to forecast_one. forecast_scenario loads the modal parameters for the model and calls forecast_scenario_draw, which does the following for each input draw:","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"Call load_scenario_targets! to read the ith scenario draw from the input file\nFilter and smooth to back out the necessary shocks, treating the targeted paths like data\nForecast paths for all variables (not just the targeted observables) using the smoothed shocks\nCheck that the forecasted observables match the targets and return","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"When all draws for the scenario have been forecasted, the forecasted observables and pseudo-observables are written to the files given by get_scenario_output_files.","category":"page"},{"location":"scenarios/#Computing-Means-and-Bands-1","page":"Alternative Scenarios","title":"Computing Means and Bands","text":"","category":"section"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"Computing means and bands is carried out by scenario_means_bands, which is likewise similar to compute_meansbands for regular forecasts. The default output_vars passed into scenario_means_bands are","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"output_vars = [:forecastutobs, :forecastobs, :forecast4qobs,\n               :forecastutpseudo, :forecastpseudo, :forecast4qpseudo]","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"The product :forecastut refers to untransformed forecasts, i.e. forecasts in model units (in deviations from baseline).","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"Since these forecasts are given in deviations from baseline, different transformations are used than in the usual case. These don't add back population growth to per-capita variables and approximate annualizing log differences (exponentiating and raising to the fourth power) by multiplying by four. The mapping from usual to scenario transformation is given by get_scenario_transform.","category":"page"},{"location":"scenarios/#Additional-Features-1","page":"Alternative Scenarios","title":"Additional Features","text":"","category":"section"},{"location":"scenarios/#Other-Scenario-Fields-1","page":"Alternative Scenarios","title":"Other Scenario Fields","text":"","category":"section"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"The remaining fields in the Scenario type are used to forecast scenarios using additional bells and whistles:","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"shock_scaling::Float64: after filtering and smoothing shocks, multiply them by shock_scaling before forecasting. Defaults to 1.0.\ndraw_states::Bool: if true, use the simulation smoother rather than the Kalman smoother to smooth shocks. This generates uncertainty around the target paths. Defaults to false.\naltpolicy::AltPolicy: solve for shocks under the historical policy rule, then switch to the alternative policy (see Alternative Policies) before forecasting. Defaults to AltPolicy(:historical, eqcond, solve).","category":"page"},{"location":"scenarios/#SwitchingScenarios-1","page":"Alternative Scenarios","title":"SwitchingScenarios","text":"","category":"section"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"Suppose you want to simulate a set of scenario draws which all start from some default scenario, switch to an alternative scenario (which we call the original scenario) with some probability in each period, and then revert back to the default scenario with some probability. This functionality is encoded in the SwitchingScenario type, which has the following fields:","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"key::Symbol: identifier, not the same as the original scenario's key\ndescription::Symbol: defaults to the original scenario's description\nvintage::String: defaults to the original scenario's vintage\noriginal::SingleScenario\ndefault::SingleScenario\nprobs_enter::Vector{Float64}: gives the probability of leaving the default scenario and entering the original scenario in each period\nprobs_exit::Vector{Float64}: gives the probability of leaving the original scenario and reverting to the default scenario in each period","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"SingleScenario is the abstract supertype of both Scenario and SwitchingScenario.","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"SwitchingScenarios cannot be forecasted like ordinary Scenarios. Instead, after simulating draws from both the original and default scenarios, you call simulate_switching to use these already-forecasted draws. For each draw i of the original scenario:","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"Randomly select a draw j of the default scenario.\nIn each period t (beginning in period 1), determine whether to switch to the original scenario with probability probs_enter[t]. If remaining in the default scenario, use the period t forecasted values of the jth default scenario draw.\nSuppose the last period in the default scenario is t0. Then for each subsequent period t0 + h, decide whether to revert to the default scenario with probability probs_exit[t0 + h]. If remaining in the original scenario, use the period h (not t0 + h) forecasted values of the ith original scenario draw.\nLet t1 be the last period in the original scenario. Then for each remaining period t1 + h, use the period t1 + h forecasted values of the jth default scenario draw.","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"simulate_switching saves simulated draws in the same format as forecast_scenario. Transforming and computing means and bands for SwitchingScenarios using scenario_means_bands is the same as for regular Scenarios.","category":"page"},{"location":"scenarios/#Aggregating-Multiple-Scenarios-1","page":"Alternative Scenarios","title":"Aggregating Multiple Scenarios","text":"","category":"section"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"Finally, we are sometimes interested in aggregating the forecast draws from multiple scenarios. We define the ScenarioAggregate type, which has the following fields:","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"key::Symbol\ndescription::String\nscenarios::Vector{AbstractScenario}: vector of component scenarios, some of which might be themselves ScenarioAggregates\nsample::Bool: indicates whether to\nproportions::Vector{Float64}: vector of relative scenario proportions\ntotal_draws::Int: desired final number of draws\nreplace::Bool: indicates whether to sample with replacement\nvintage::String","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"In addition to the default constructor, there are two more ScenarioAggregate constructors, corresponding to the two possible values of sample. The key, description, vector of component scenarios, and vintage are always specified.","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"sample = false: No additional fields are required for this constructor, as the component scenario draws are kept in their original proportions. The proportions and total_draws fields are initialized to dummy values and are updated when the component draws are read in. replace is set to false.\nsample = true: Additionally specify proportions, total_draws, and replace. Draws from scenarios[i] are sampled into the aggregate distribution with probability proportions[i]","category":"page"},{"location":"scenarios/#","page":"Alternative Scenarios","title":"Alternative Scenarios","text":"SingleScenario and ScenarioAggregate are both subtypes of the abstract type AbstractScenario. The actual sampling and aggregating of scenario draws happens entirely in scenario_means_bands, which calls functions that dispatch on the AbstractScenario subtype passed in. In particular, this means that we don't save a separate \"raw\" output file with the individual draws that made it into a particular ScenarioAggregate â€“ we only save the resulting MeansBands.","category":"page"},{"location":"learning_how_to_use_dsgejl/#Learning-How-to-Use-DSGE.jl-1","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"","category":"section"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"DSGE.jl is designed to facilitate the fast and efficient estimation and forecasting of DSGE models. For this reason, DSGE.jl does not have as friendly an API as other packages like Dynare. For example, building new models in DSGE.jl will be more involved than the model script approach taken by Dynare, and you will need to know basic Julia first. While the FRBNY DSGE team tries it best to write good documentation, users may still need to look at source code to learn how some functions work and to diagnose errors. Please file an issue or contact one of the developers (see Project.toml) if you ever have questions about the package or encounter errors that you are not sure how to fix. However, try to thoroughly examine the documentation first because, in our experience, many problems users have had were easily answered by referring them to the correct section of the documentation.","category":"page"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"To get started, we recommend taking a look at our example scripts as you read the documentation because the examples will make it easier to comprehend the documentation. The two scripts that will be most useful for learning the package are","category":"page"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"run_default.jl: a simple example of the standard workflow with DSGE.jl\nmake_packet.jl: auto-generate a packet of plots and figures which help the user analyze estimation, forecast, and impulse response results. This script also provides an example of how we recommend structuring \"main\" files that launch a forecast and generate results with one \"click.\"","category":"page"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"For details on all the example scripts, see Running Existing Models.","category":"page"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"Below, we give some additional pointers depending on what the user wants from the package.","category":"page"},{"location":"learning_how_to_use_dsgejl/#Building-New-DSGE-Models-1","page":"Learning How to Use DSGE.jl","title":"Building New DSGE Models","text":"","category":"section"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"For beginners, we recommend looking at the source code for AnSchorfheide to see the most basic example of a DSGE model in DSGE.jl. Unless you are experienced with object-oriented programming and implementing new types in Julia, we highly recommend you start with AnSchorfheide. In our experience, the typical economist who wants to use our code encounters a substantial learning curve, especially if they try to build their own DSGE models by modifying Model1002, the current New York Fed DSGE model. Because Model1002 continues to undergo development by the FRBNY DSGE team, it includes numerous features that require deep knowledge of the package and is generally not suitable for learning to build a new model.","category":"page"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"To help users, the source code for AnSchorfheide should have additional comments indicating which functions and lines should be edited when a user wants to build a new model. For this reason, we recommend that the user copies the source code for the model into a new folder and edit that source code to develop their new model. Substantial portions of the code for the model objects in DSGE.jl can be recycled for most DSGE models. Copy and paste will minimize errors and also reduce the time it takes to get a new model implemented.","category":"page"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"For more advanced programmers and for users familiar with the implementation of AnSchorfheide, SmetsWouters or SmetsWoutersOrig are suitable examples for building medium-scale DSGEs. The former uses our preferred parameterization of the Smets and Wouters model, and the latter uses the parameterization in the original paper. A more advanced model that is closer to the New York Fed DSGE model is Model904. To see the source code of these models, look in the representative agent DSGE folder. We recommend examining these models first before looking at Model1002 because there are notable differences in the size of these models compared to AnSchorfheide.","category":"page"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"Finally, after learning our implementation of medium-scale DSGEs, the user may start to look at Model1002 if they want to base their new model off of the New York Fed DSGE model. In addition, the most advanced features of DSGE.jl are typically implemented only for Model1002. To learn these features, you will likely need to examine the source code for Model1002. For example, we have extended Model1002 to model the economic impact of COVID-19 and the Federal Reserve's policy switch to flexible average inflation targeting. None of the other DSGE models in DSGE.jl has been extended to include these features, although it is certainly possible to do so.","category":"page"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"The user will also want to look at Solving the Model because it will explain the format in which equilibrium conditions must be provided in order for a DSGE model to be solvable by DSGE.jl. In particular, this page will guide the user when writing their own model's eqcond.jl script.","category":"page"},{"location":"learning_how_to_use_dsgejl/#Estimation-1","page":"Learning How to Use DSGE.jl","title":"Estimation","text":"","category":"section"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"The user should make sure they have a FRED API key (see these instructions) if they want to estimate a DSGE model because we load most US data automatically by querying FRED. Our package is designed to make the data retrieval process as automated as possible, but this approach means that more setup is required to load data into Julia than simply creating your own csv file and reading it into memory. Please see Input Data for guidance.","category":"page"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"A relatively high-level overview of the estimation process is given by Estimation. The run_default.jl script will be a particularly useful example, followed by test_smc.jl if the user wants to also learn how to call the Sequential Monte Carlo sampling algorithm instead of Random-Walk Metropolis-Hastings. The default settings for estimation are designed for the FRBNY DSGE team's typical work, but most users will need to adjust the defaults. For guidance on what settings can be changed and what they do, see Working with Settings as well as defaults.jl, which holds the complete description of default settings for every DSGE model in DSGE.jl. Note, however, that some of the values of these default settings will be over-written during instantiation of a DSGE object (see the model_settings! function for AnSchorfheide in an_schorfheide.jl).","category":"page"},{"location":"learning_how_to_use_dsgejl/#Forecasting-1","page":"Learning How to Use DSGE.jl","title":"Forecasting","text":"","category":"section"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"The user should make sure they have a FRED API key (see these instructions) if they want to forecast a DSGE model because we load most US data automatically by querying FRED. Our package is designed to make the data retrieval process as automated as possible, but this approach means that more setup is required to load data into Julia than simply creating your own csv file and reading it into memory. Please see Input Data for guidance.","category":"page"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"A relatively high-level overview of forecasting process is given by Forecasting and Computing Means and Bands. The first section describes the actual \"running\" of forecasts while the second section describes the MeansBands object we typically utilize to examine forecast output. In particular, most use cases will not require access to the matrix describing every single sample from the posterior forecast distribution. Instead, a user only wants to know what the mean forecast and the uncertainty bands around that mean are. For this reason, the MeansBands object is typically the object users will want in order to analyze the output of their forecast. A good example script of forecasting is make_packet.jl, which provides an instance of a typical workflow when forecasting a DSGE model.","category":"page"},{"location":"learning_how_to_use_dsgejl/#","page":"Learning How to Use DSGE.jl","title":"Learning How to Use DSGE.jl","text":"For more details on specific forecast outputs that can be computed, the user will find Impulse Response Functions, Alternative Policies, Forecasting Decomposition, and Plotting to be informative sections. Once the user is familiar with the basic applications of the forecasting tools in DSGE.jl, they may want to look at Advanced Usage for the many special features we have implemented for forecasting DSGEs.","category":"page"},{"location":"special_model_types/#Special-Model-Types-1","page":"Special Model Types","title":"Special Model Types","text":"","category":"section"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"CurrentModule = DSGE","category":"page"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"In addition to the AbstractDSGEModel type, DSGE.jl has several special types that implement models which are designed to interface with DSGEs. New users should skip this section and return later.","category":"page"},{"location":"special_model_types/#The-PoolModel-Type-1","page":"Special Model Types","title":"The PoolModel Type","text":"","category":"section"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"Unlike the other models contained in DSGE, the PoolModel type is not a proper DSGE model. It is a wrapper object for different methods to perform model averaging for two different models, which do not have to be DSGE models. For example, a user could average two different vector auto-regressions. Generally, a user only needs to provide the predictive density scores of the two models that the user wants to average. The reason is that we treat the predictive density scores as non-FRED observables. This approach makes interfacing with the rest of the machinery provided by DSGE.jl very simple.","category":"page"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"PoolModel","category":"page"},{"location":"special_model_types/#DSGE.PoolModel","page":"Special Model Types","title":"DSGE.PoolModel","text":"PoolModel{T}\n\nImplements several model averaging methods to pool the predictions of different models. Currently, PoolModel only works for pooling two different models, although it can be extended to more models. Confer with the paper for details.\n\nThe available methods are\n\ndynamic: weights on pooled models evolve over time and are          treated as a stochastic process.\nstatic:  weights on pooled models are assumed time-invariant.\nequal:   weights are set to 1/2.\nbma:     weights are updated according to Bayesian model averaging.\n\nThe default method is dynamic, which implements the Dynamic Pools method developed by Del Negro et al. (2016). To choose another method, use the keyword weight_type::Symbol, e.g.\n\npm = PoolModel(weight_type = :static) # creates a static PoolModel\n\nThe weight_type is stored as a setting, so users can retrieve at any point by using get_setting.\n\nFields\n\nParameters\n\nparameters::Vector{AbstractParameter}: Vector of all time-invariant hyperparameters   for the chosen method of model averaging.\nkeys::OrderedDict{Symbol,Int}: Maps human-readable names for predictive densities   of pooled models.\n\nInputs to Measurement and Equilibrium Condition Equations\n\nmodel::OrderedDict{Symbol,AbstractDSGEModel}: Maps name to its underlying model object.\n\nModel Specifications and Settings\n\nspec::String: The model specification identifier, \"an_schorfheide\", cached here for filepath computation.\nsubspec::String: The model subspecification number, indicating that some parameters from the original model spec (\"ss0\") are initialized differently. Cached here for filepath computation.\nsettings::Dict{Symbol,Setting}: Settings/flags that affect computation without changing the economic or mathematical setup of the model.\ntest_settings::Dict{Symbol,Setting}: Settings/flags for testing mode\n\nOther Fields\n\nrng::MersenneTwister: Random number generator. Can be is seeded to ensure reproducibility in algorithms that involve randomness (such as Metropolis-Hastings).\ntesting::Bool: Indicates whether the model is in testing mode. If true, settings from m.test_settings are used in place of those in m.settings.\nobservable_mappings::OrderedDict{Symbol,Observable}: A dictionary that stores data sources, series mnemonics, and transformations to/from model units. DSGE.jl will fetch data from the Federal Reserve Bank of St. Louis's FRED database; all other data must be downloaded by the user. See load_data and Observable for further details.\n\n\n\n\n\n","category":"type"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"See Del Negro et al. (2016) for theoretical details on the model averaging methods listed in the documentation.","category":"page"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"To facilitate analysis with the PoolModel type, we also provide the following functions.","category":"page"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"estimate_bma\nsample_Î»\npropagate_Î»\ncompute_EÎ»","category":"page"},{"location":"special_model_types/#DSGE.estimate_bma","page":"Special Model Types","title":"DSGE.estimate_bma","text":"estimate_bma(m, data, prior; return_output = false, filestring_addl = [])\n\nEstimate a Bayesian Model Average.\n\nArguments:\n\nm::PoolModel: PoolModel object\n\nOptional Arguments:\n\ndata: well-formed data as Matrix or DataFrame. If this is not provided, the load_data routine will be executed.\nprior::Float64: prior probability between the two models\n\nKeyword Arguments:\n\nreturn_output::Bool: option to return output. If false, nothing is returned.\nfilestring_addl::Vector{String}: Additional strings to append to output files.\n\n\n\n\n\n","category":"function"},{"location":"special_model_types/#DSGE.sample_Î»","page":"Special Model Types","title":"DSGE.sample_Î»","text":"sample_Î»(m, pred_dens, Î¸s, T = -1; parallel = true) where S<:AbstractFloat\nsample_Î»(m, pred_dens, T = -1; parallel = true) where S<:AbstractFloat\n\nComputes and samples from the conditional density p(Î»t|Î¸, It, P) for particle in Î¸s, which represents the posterior distribution. The sampled Î» particles represent the posterior distribution p(Î»{t|t} | It, P).\n\nIf no posterior distribution is passed in, then the function computes the distribution of Î»_{t|t} for a static pool.\n\nInputs\n\nm::PoolModel{S}: PoolModel object\npred_dens::Matrix{S}: matrix of predictive densities\nÎ¸s::Matrix{S}: matrix of particles representing posterior distribution of Î¸\nT::Int64: final period for tempered particle filter\n\nwhere S<:AbstractFloat.\n\nKeyword Argument\n\nparallel::Bool: use parallel computing to compute and sample draws of Î»\n\nOutputs\n\nÎ»_sample::Vector{Float64}: sample of draws of Î»s; together with (Î¸,Î») represents a joint density\n\n```\n\n\n\n\n\n","category":"function"},{"location":"special_model_types/#DSGE.propagate_Î»","page":"Special Model Types","title":"DSGE.propagate_Î»","text":"propgate_Î»(Î»vec, h, m, Î¸vec) where T<:AbstractFloat\n\nPropagates a Î» particle h periods forward.\n\nInputs\n\nÎ»::T: Î» sample from (Î¸,Î») joint distribution\nh::Int64: forecast horizon\nm::PoolModel: PoolModel object\nÎ¸vec::Vector{T}: optional vector of parameters to update PoolModel\n\n```\n\n\n\n\n\n","category":"function"},{"location":"special_model_types/#DSGE.compute_EÎ»","page":"Special Model Types","title":"DSGE.compute_EÎ»","text":"compute_EÎ»(m, h, Î»vec, Î¸mat = [], weights = [];\n    current_period = true, parallel = true) where T<:AbstractFloat\n\nComputes and samples from the conditional density p(Î»t|Î¸, It, P) for particle in Î¸s, which represents the posterior distribution.\n\nInputs\n\nm::PoolModel{T}: PoolModel object\nh::Int64: forecast horizon\nÎ»vec::Vector{T}: vector of particles of Î» samples from (Î¸,Î») joint distribution\n`Î¸mat::Matrix{T}': matrix of posterior parameter samples\nweights::Vector{T}: weights of Î» particles, defaults to equal weights\n\nKeyword Argument\n\ncurrent_period::Bool: compute EÎ» for current period t\nparallel::Bool: use parallel computing to compute and sample Î»\nget_dpp_pred_dens::Bool: compute predictive densities according to dynamic prediction pools\n\nOutputs\n\nÎ»hat_tplush::Float64: E[Î»{t+h|t} | It^P, P]\nÎ»hat_t::Float64: E[Î»{t|t} | It^P, P]\n\n```\n\n\n\n\n\n","category":"function"},{"location":"special_model_types/#DSGE-VARs-and-the-DSGEVAR-Type-1","page":"Special Model Types","title":"DSGE-VARs and the DSGEVAR Type","text":"","category":"section"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"We can approximate the dynamics of a linearized DSGE with a VAR(p), where p is the number of lags. This approximation gives a mapping from the parameters of a DSGE to the parameters of a VAR (the coefficients and innovations variance-covariance matrix). Since the number of parameters in a VAR are generally larger than the number of parameters in a DSGE, this mapping can be interpreted as cross-restrictions imposed by a DSGE on the parameters of a VAR. A DSGE-VAR combines a DSGE with a VAR to, among other reasons, evaluate the mis-specification of the DSGE and improve the DSGE's forecasting performance.","category":"page"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"For more details on the theory and performance, see Del Negro and Schorfheide (2004), Del Negro and Schorfheide (2006), [Del Negro, Schorfheide, Smets, and Wouters (2007)][https://www.jstor.org/stable/27638915], and Del Negro and Schorfheide (2009).","category":"page"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"We implement DSGE-VARs with the DSGEVAR concrete type so that it is easy to interface them with DSGE models. A DSGEVAR type holds information about the VAR with which we want to combine a given DSGE model and can be easily constructed, given a DSGE object. Once we have constructed a DSGEVAR object, then it is straightforward to estimate the object and compute impulse responses.","category":"page"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"DSGEVAR","category":"page"},{"location":"special_model_types/#DSGE.DSGEVAR","page":"Special Model Types","title":"DSGE.DSGEVAR","text":"DSGEVAR{T} <: AbstractDSGEVARModel{T}\n\nimplements a simple interface for combining a given DSGE model with a VAR to create a DSGE-VAR. Confer with Del Negro and Schorfheide (2004), Del Negro and Schorfheide (2006), Del Negro, Schorfheide, Smets, and Wouters (2007), and/or Del Negro and Schorfheide (2009) for details about DSGE-VARs. We recommend the first two papers as initial introductions to DSGE-VARs.\n\nThe recommended constructor requires the user to provide (1) an AbstractDSGEModel object, (2) which structural shocks from the DSGE to use, and (3) the subspec (optional, defaults to \"ss0\"). If the subspec \"ss0\" is used, then the result is a DSGEVAR whose VAR component is \"empty\" in that the observables, lags, and Î» weight are not specified. The reason why this constructor requires the user to specify which structural shocks of DSGE to use is that this information is DSGE-specific rather than information about the VAR.\n\nHowever, we can also construct a DSGEVAR without having to specify the structural shocks when calling the constructor, although we still need to give an instance of an AbstractDSGEModel.\n\nExample\n\nThe code below instantiates an empty DSGEVAR with AnSchorfheide as the underlying DSGE and then calls update! on the empty DSGE-VAR to add information about the desired DSGE-VAR spec.\n\ndsgevar = DSGEVAR(AnSchorfheide())\nDSGE.update!(dsgevar, shocks = [:rm_sh, :z_sh, :g_sh],\n    observables = [:obs_gdp, :obs_cpi, :obs_nominalrate],\n    Î» = 1., lags = 4)\n\nFields\n\nDSGE object\n\ndsge::AbstractDSGEModel{T}: underlying DSGE model object\n\nDSGE-VAR Information\n\nobservables::OrderedDict{Symbol,Int}: dictionary mapping observables   of the VAR to their index in the matrices representing the DSGE-VAR\nshocks::OrderedDict{Symbol,Int}: dictionary mapping structural   shocks in the DSGE to their index in the matrices representing the DSGE-VAR\nlags::Int: number of lags in the VAR\nÎ»::T: weight on the DSGE prior\n\nAuxiliary Information\n\nspec::String: concatenates dsgevar with the spec of the DSGE, e.g.   for AnSchorfheide, we have dsgevar_an_schorfheide.\nsubspec::String: specifies the model subspecification.   Cached here for filepath computation.\ntesting::Bool: indicates whether the model is in testing mode.   Currently, this setting has no uses in practice\n\n\n\n\n\n","category":"type"},{"location":"special_model_types/#tips-dsgevar-1","page":"Special Model Types","title":"Tips for Using DSGEVAR","text":"","category":"section"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"When extensively using DSGE-VARs, we recommend defining your own subspecs in subspecs.jl because it simplifies the process of saving, reading, and analyzing output from estimating and calculating impulse responses for DSGE-VARs. See Advanced Usage for a more detailed explanation on changing subspecs.\nThe names of the observables must exist as either observables or pseudo-observables in the DSGE because for most DSGEVAR methods, we need to construct the state space representation of the DSGEVAR using information from the underlying DSGE.\nIt is important to be careful about the order of the observables when constructing a DSGEVAR. Whether you define the names of the observables by calling update! or by creating a subspec, we assume that the order of the observables corresponds to the observable's index in the data and in the state space representation of the DSGEVAR. In the example provided above, if we estimate the DSGEVAR on data or construct the state space representation of the DSGEVAR, we assume that the order of observables in the data array, which has dimensions nobs x nperiods, is :obs_gdp in the first row, :obs_cpi in the second row, and :obs_nominalrate in the third row.\nWhen using functions that use the DSGE as a prior for a VAR (as opposed to a VAR approximation of the DSGE), then an intercept term is assumed and cannot be turned off. For example, the following two functions computes the VAR coefficients and innovations variance-covariance matrix for a DSGEVAR object m. The first one is for a VAR approximation of the DSGE in m, and it allows the user to specify whether or not they want an intercept term using the keyword use_intercept. The second function is for using the DSGE as a prior for a VAR estimated on data. This function does not have the use_intercept keyword because we require an intercept term when using the DSGE as a prior for a VAR.","category":"page"},{"location":"special_model_types/#DSGE-VECMs-and-the-DSGEVECM-Type-1","page":"Special Model Types","title":"DSGE-VECMs and the DSGEVECM Type","text":"","category":"section"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"We can extend DSGE-VARs to permit cointegrating relationships between observables using DSGE-VECMs. A VECM is a vector error-correction model, which extend VARs to account for long-run stochastic trends, i.e. cointegration..","category":"page"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"For more details on the theory and performance, see Del Negro and Schorfheide (2004), Del Negro and Schorfheide (2006), and [Del Negro, Schorfheide, Smets, and Wouters (2007)][https://www.jstor.org/stable/27638915].","category":"page"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"We implement DSGE-VECMs with the DSGEVECM concrete type so that it is easy to interface them with DSGE models. The DSGEVECM has very similar behavior to the DSGEVAR type, with extensions as needed. For example, the DSGEVECM type includes additional fields to hold information about cointegrating relationships.","category":"page"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"DSGEVECM","category":"page"},{"location":"special_model_types/#DSGE.DSGEVECM","page":"Special Model Types","title":"DSGE.DSGEVECM","text":"DSGEVECM{T} <: AbstractDSGEVECMModel{T}\n\nimplements a simple interface for combining a given DSGE model with a VECM (a VAR with cointegrating terms) to create a DSGE-VECM. Confer with Del Negro and Schorfheide (2006) and/or Del Negro, Schorfheide, Smets, and Wouters (2007) for details about DSGE-VECMs. We recommend the first paper as an initial introduction to DSGE-VECMs.\n\nThe recommended constructor requires the user to provide (1) an AbstractDSGEModel object, (2) which structural shocks from the DSGE to use, and (3) the subspec (optional, defaults to \"ss0\"). If the subspec \"ss0\" is used, then the result is a DSGEVECM whose VECM component is \"empty\" in that the observables, cointegrating relationships, lags, and Î» weight are not specified. The reason why this constructor requires the user to specify which structural shocks of DSGE to use is that this information is DSGE-specific rather than information about the VECM.\n\nHowever, we can also construct a DSGEVECM without having to specify the structural shocks when calling the constructor, although we still need to give an instance of an AbstractDSGEModel.\n\nExample\n\nThe code below instantiates an empty DSGEVECM with AnSchorfheide as the underlying DSGE and then calls update! on the empty DSGE-VECM to add information about the desired DSGE-VECM spec.\n\ndsgevecm = DSGEVECM(AnSchorfheide())\nDSGE.update!(dsgevecm, shocks = [:rm_sh, :z_sh, :g_sh],\n    observables = [:obs_gdp, :obs_cpi, :obs_nominalrate],\n    Î» = 1., lags = 4)\n\nFields\n\nDSGE object\n\ndsge::AbstractDSGEModel{T}: underlying DSGE model object\n\nDSGE-VECM Information\n\nobservables::OrderedDict{Symbol,Int}: dictionary mapping observables   of the VECM to their index in the matrices representing the DSGE-VECM.\ncointegrating::OrderedDict{Symbol,Int}: dictionary mapping cointegrating relationships   of the VECM to their index in the matrices representing the DSGE-VECM.   When creating the state space representation of a DSGE-VECM, the   cointegrating relationships will come after the observables. Accordingly,   the first cointegrating index will be after the last observable.\ncointegrating_add::OrderedDict{Symbol,Int}: dictionary mapping   additional cointegrating relationships of the VECM to their index   in the matrices representing the DSGE-VECM. These relationships are   intended to be ones that only add to the DD matrix in DSGE.jl's   representation of a state space model. Importantly, these relationships   do not require changing the ZZ matrix. As a result, the indices for   these relationships start at 1.\nshocks::OrderedDict{Symbol,Int}: dictionary mapping structural   shocks in the DSGE to their index in the matrices representing the DSGE-VECM\nlags::Int: number of lags in the VECM\nÎ»::T: weight on the DSGE prior\n\nAuxiliary Information\n\nspec::String: concatenates dsgevar with the spec of the DSGE, e.g.   for AnSchorfheide, we have dsgevar_an_schorfheide.\nsubspec::String: specifies the model subspecification.   Cached here for filepath computation.\ntesting::Bool: indicates whether the model is in testing mode.   Currently, this setting has no uses in practice\n\n\n\n\n\n","category":"type"},{"location":"special_model_types/#Tips-for-Using-DSGEVECM-1","page":"Special Model Types","title":"Tips for Using DSGEVECM","text":"","category":"section"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"The same tips for DSGEVAR models generally apply for DSGEVECM models.\nThe names of cointegrating relationships in the field cointegrating must exist as either observables or pseudo-observables in the DSGE. The reason is the same as the reason for why observables must be held.\nIn the state space representation of the underlying DSGE corresponding to a DSGE-VECM, cointegrating relationships are ordered after observables. For example, consider the measurement matrix ZZ. The first n_observables rows correspond to the observables in DSGE-VECM, and the next n_observables + 1:n_cointegrating + n_observables rows correspond to cointegrating in DSGE-VECM.\nWhen calculating the VECM coefficients of a DSGE-VECM, the coefficients are ordered with cointegrating relationships first, followed by the intercept term, and concluding with lags of past differences. See the docstring of vecm_approx_state_space.\nSome cointegrating relationships do not need to be added to the measurement matrix in the state space representation of a DSGE model. These relationships are considered \"additional\" ones and are added to the field cointegrating_add. To compute the constant vector which specify these additional relationships, we use compute_DD_coint_add. See its docstring for notes on usage.","category":"page"},{"location":"special_model_types/#Auxiliary-Methods-for-DSGE-VARs-and-DSGE-VECMs-1","page":"Special Model Types","title":"Auxiliary Methods for DSGE-VARs and DSGE-VECMs","text":"","category":"section"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"Listed below are some methods used internally in but not exported by DSGE.jl that users may also find useful. We also recommend looking at the various utility functions in abstractvarmodel.jl. Many of these functions are wrappers for similarly named functions defined on AbstractDSGEModel objects.","category":"page"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"Modules = [DSGE]\nPages = [\"models/var/util.jl\"]\nOrder = [:function]","category":"page"},{"location":"special_model_types/#DSGE.draw_VECM-Union{Tuple{S}, Tuple{Array{S,2},Array{S,2},Array{S,2},Int64,Int64,Int64,Int64}} where S<:Real","page":"Special Model Types","title":"DSGE.draw_VECM","text":"draw_VECM(YYYYC, XXYYC, XXXXC, TÌ„, n_obs, lags, n_coint; standard_orientation = true)\n\ndraws Î² and Î£ from the distribution p(Î², Î£ | Y, Î¸) implied by the population moments (or covariances) YYYYC, XXYYC, and XXXXC for a VECM with parameters Î¸.\n\nFor example, if these population moments are generated by a DSGE-VECM, then Î¸ are the structural parameters of the DSGE and the weight Î» placed on the cross-restrictions implied by the DSGE. The population moments would represent the moments of the sample data and dummy observables generated to implement the DSGE prior.\n\nGiven these moments, we compute the maximum-likelihood estimates of Î² and Î£ using OLS. Denote these estimates by Î’ and S. Then we generate draws from p(Î², Î£ | Y, Î¸) using the fact that\n\nÎ£ | Y, Î¸ âˆ¼ â„ð’² (TÌ„ Ã— S, TÌ„ - (1 + lags * n_obs), n_obs),\nÎ² | Y, Î£,Î¸ âˆ¼ ð’© (B, Î£ âŠ— XXXXCâ»Â¹).\n\nInputs\n\nYYYYC::Matrix{<:Real}: covariance of observables\nXXYYC::Matrix{<:Real}: covariance of observables with their lags\nXXXXC::Matrix{<:Real}: covariance of the lags of the observables\nTÌ„::Int: total number of time periods of observations, including sample observables   from actual data and any dummy observables generated to implement priors.\nn_obs::Int: number of distinct observables\nlags::Int: number of lags in the VECM\nn_coint::Int: number of distinct cointegrating relationships\n\nKeywords\n\nstandard_orientation::Bool: if true, the draw of Î² has   dimensions (n_obs * lags) x n_obs. Otherwise, it has the transposed dimensions.\nAll other keywords are used for testing purposes.\n\n\n\n\n\n","category":"method"},{"location":"special_model_types/#DSGE.draw_stationary_VAR-Union{Tuple{S}, Tuple{Array{S,2},Array{S,2},Array{S,2},Int64,Int64,Int64}} where S<:Real","page":"Special Model Types","title":"DSGE.draw_stationary_VAR","text":"draw_stationary_VAR(YYYYC, XXYYC, XXXXC, TÌ„, n_obs, lags; standard_orientation = true)\ndraw_stationary_VAR(YYYYC, XXYYC, XXXXC, TÌ„; standard_orientation = true)\n\ndraws Î² and Î£ from the distribution p(Î², Î£ | Y, Î¸) implied by the population moments (or covariances) YYYYC, XXYYC, and XXXXC for a VAR with parameters Î¸.\n\nFor example, if these population moments are generated by a DSGE-VAR, then Î¸ are the structural parameters of the DSGE and the weight Î» placed on the cross-restrictions implied by the DSGE. The population moments would represent the moments of the sample data and dummy observables generated to implement the DSGE prior.\n\nGiven these moments, we compute the maximum-likelihood estimates of Î² and Î£ using OLS. Denote these estimates by Î’ and S. Then we generate draws from p(Î², Î£ | Y, Î¸) using the fact that\n\nÎ£ | Y, Î¸ âˆ¼ â„ð’² (TÌ„ Ã— S, TÌ„ - (1 + lags * n_obs), n_obs),\nÎ² | Y, Î£,Î¸ âˆ¼ ð’© (B, Î£ âŠ— XXXXCâ»Â¹).\n\nFinally, we check that these draws generate a stationary state space system. If they do not, then we keep drawing until we obtain a pair of draws (Î², Î£) that are stationary.\n\nInputs\n\nYYYYC::Matrix{<:Real}: covariance of observables\nXXYYC::Matrix{<:Real}: covariance of observables with their lags\nXXXXC::Matrix{<:Real}: covariance of the lags of the observables\nTÌ„::Int: total number of time periods of observations, including sample observables   from actual data and any dummy observables generated to implement priors.\nn_obs::Int: number of distinct observables\nlags::Int: number of lags in the VAR\n\nKeywords\n\nstandard_orientation::Bool: if true, the draw of Î² has   dimensions (n_obs * lags) x n_obs. Otherwise, it has the transposed dimensions.\nAll other keywords are used for testing purposes.\n\n\n\n\n\n","category":"method"},{"location":"special_model_types/#","page":"Special Model Types","title":"Special Model Types","text":"var_approx_state_space\nvecm_approx_state_space\ncompute_DD_coint_add\nmeasurement_error\ndsgevar_likelihood\ndsgevecm_likelihood","category":"page"},{"location":"special_model_types/#DSGE.var_approx_state_space","page":"Special Model Types","title":"DSGE.var_approx_state_space","text":"var_approx_state_space(TTT, RRR, QQQ, DD, ZZ, EE, MM, p; get_population_moments = false,\nuse_intercept = false) where {S<:Real}\n\ncomputes the VAR(p) approximation of the linear state space system\n\nsâ‚œ = TTT * sâ‚œâ‚‹â‚ + RRR * Ïµâ‚œ,\nyâ‚œ = ZZ * sâ‚œ + DD + uâ‚œ,\n\nwhere the disturbances are assumed to follow\n\nÏµâ‚œ âˆ¼ ð’© (0, QQ),\nuâ‚œ = Î·â‚œ + MM * Ïµâ‚œ,\nÎ·â‚œ âˆ¼ ð’© (0, EE).\n\nThe MM matrix implies\n\ncov(Ïµâ‚œ, uâ‚œ) = QQ * MM'.\n\nOutputs\n\nIf get_population_moments = false:\n\nÎ²: VAR(p) coefficients\nÎ£: innovations variance-covariance matrix for the VAR(p) representation\n\nyâ‚œ = Xâ‚œÎ² + Î¼â‚œ\n\nwhere Xâ‚œ appropriately stacks the constants and p lags of yâ‚œ, and Î¼â‚œ âˆ¼ ð’© (0, Î£).\n\nIf get_population_moments = true: we return the limit cross product matrices.\n\nyyyyd: ð”¼[y,y]\nXXXXd: ð”¼[y,X(lag rr)]\nXXyyd: ð”¼[X(lag rr),X(lag ll)]\n\nUsing these matrices, the VAR(p) representation is given by\n\nÎ² = XXXXd \\ XXyyd\nÎ£ = yyyyd - XXyyd' * Î²\n\nThe keyword use_intercept specifies whether or not to use an intercept term in the VAR approximation.\n\n\n\n\n\n","category":"function"},{"location":"special_model_types/#DSGE.vecm_approx_state_space","page":"Special Model Types","title":"DSGE.vecm_approx_state_space","text":"vecm_approx_state_space(TTT, RRR, QQQ, DD, ZZ, EE, MM, n_obs, p, n_coint,\nn_coint, n_coint_add, DD_coint_add; get_population_moments = false,\nuse_intercept = false) where {S<:Real}\n\ncomputes the VECM(p) approximation of the linear state space system\n\nsâ‚œ = TTT * sâ‚œâ‚‹â‚ + RRR * Ïµâ‚œ,\nyâ‚œ = ZZ * sâ‚œ + DD + uâ‚œ,\n\nwhere the disturbances are assumed to follow\n\nÏµâ‚œ âˆ¼ ð’© (0, QQ),\nuâ‚œ = Î·â‚œ + MM * Ïµâ‚œ,\nÎ·â‚œ âˆ¼ ð’© (0, EE).\n\nThe MM matrix implies\n\ncov(Ïµâ‚œ, uâ‚œ) = QQ * MM'.\n\nOutputs\n\nIf get_population_moments = false:\n\nÎ²: VECM(p) coefficients. The first n_coint + n_coint_add\n\ncoefficients for each observable comprise the error correction terms, while the following 1 + p * n_obs terms are the VAR terms.\n\nÎ£: innovations variance-covariance matrix for the VECM(p) representation\n\nÎ”yâ‚œ = eâ‚œÎ²â‚‘ + Xâ‚œÎ²áµ¥ + Î¼â‚œ\n\nwhere Î²â‚‘ are the coefficients for the error correction terms; eâ‚œ are the error correction terms specifying the cointegrating relationships; Î²áµ¥ are the coefficients for the VAR terms; Xâ‚œ appropriately stacks the constants and p lags of Î”yâ‚œ; and Î¼â‚œ âˆ¼ ð’© (0, Î£).\n\nNote that the error correction terms satisfy the mapping eâ‚œ' = C * yâ‚œâ‚‹â‚, where C is a matrix.\n\nIf get_population_moments = true: we return the limit cross product matrices.\n\nyyyyd: ð”¼[y,y]\nXXXXd: ð”¼[y,X(lag rr)]\nXXyyd: ð”¼[X(lag rr),X(lag ll)]\n\nNote that in the rows of XXyyd and the rows and columns of XXXXd, the cointegrating relationships are stacked above the constants and lagged Î”yâ‚œ.\n\nUsing these matrices, the VAR(p) representation is given by\n\nÎ² = XXXXd \\ XXyyd\nÎ£ = yyyyd - XXyyd' * Î²,\n\nwhere Î² has dimensions n_obs Ã— (n_coint + n_coint_add + 1 + p * n_obs), and Î£ has dimensions n_obs Ã— n_obs.\n\nThe keyword use_intercept specifies whether or not to use an intercept term in the VECM approximation.\n\n\n\n\n\n","category":"function"},{"location":"special_model_types/#DSGE.compute_DD_coint_add","page":"Special Model Types","title":"DSGE.compute_DD_coint_add","text":"function compute_DD_coint_add(m::AbstractDSGEVECMModel{S}, system::System,\ncointegrating_add::Vector{Symbol}) where {S <: Real}\n\ncomputes DD_coint_add for a DSGEVECM model. This vector holds additional cointegrating relationships that do not require changes to the ZZ matrix.\n\nNote\n\nWe recommend overloading this function if there are cointegrating relationships which a user does not want to add to the underlying DSGE. The function compute_system first checks for a method compute_DD_coint_add that takes a Type tuple of (model_type, Vector{Symbol}) and then (model_type, ) before calling this method.\n\nThis function is generally intended to be internal. As an example of other such functions, eqcond must be user-defined but is primarily used internally and not directly called by the user in a script.\n\n\n\n\n\n","category":"function"},{"location":"special_model_types/#DSGE.dsgevar_likelihood","page":"Special Model Types","title":"DSGE.dsgevar_likelihood","text":"dsgevar_likelihood(YYYY::Matrix{S}, XXYY::Matrix{S},\n    XXXX::Matrix{S}, YYYYD::Matrix{S}, XXYYD::Matrix{S},\n    XXXXD::Matrix{S}, T::Int, Î»::S,\n    lags::Int, n_obs::Int) where {S<:Real}\n\nevaluates the likelihood of a DSGE-VAR given the population moments of the raw data (YYYY, XXYY, XXXX) and the population moments implied by the DSGE prior (YYYYD, XXYYD, XXXXD).\n\nOther Inputs\n\nT: number of time periods in data\nÎ»: weight placed on the DSGE prior\nlags: number of lags in the VAR\nn_obs: number of observables (e.g. number of time series).\n\n\n\n\n\n","category":"function"},{"location":"special_model_types/#DSGE.dsgevecm_likelihood","page":"Special Model Types","title":"DSGE.dsgevecm_likelihood","text":"dsgevecm_likelihood(m::AbstractDSGEVECMModel{S}, data::Matrix{S};\n    apply_altpolicy::Bool = false) where {S<:Real}\n\nevaluates the likelihood of a DSGE-VECM. It is assumed that get_Î»(m) retrieves the prior weight Î» on the DSGE.\n\nThe matrix data is assumed an nobs x T+lags matrix, where the lags indicate we cut off the data for presampling.\n\nIn the future, this function may be combined with dsgevar_likelihood because the two functions are almost exactly the same. We currently have them implemented separately so that the naming convention does not create any confusion. One can think of DSGE-VECMs as DSGE-VARs with an additional regressor that corrects for errors to account for cointegration, hence it would not be \"wrong\" per se to add a couple if-else conditions inside dsgevar_likelihood and let this function cover both DSGE-VARs and DSGE-VECMS. But the current decision to have separate functions makes it clear that the dsgevar_likelihood specifically operates on DSGE-VARs without an error correction term, and dsgevecm_likelihood operates on DSGE-VECMs specifically.\n\n\n\n\n\ndsgevecm_likelihood(YYYY::Matrix{S}, XXYY::Matrix{S},\n    XXXX::Matrix{S}, YYYYD::Matrix{S}, XXYYD::Matrix{S},\n    XXXXD::Matrix{S}, T::Int, Î»::S,\n    lags::Int, n_obs::Int,\n    coint_inds::Union{Vector{Int}, UnitRange{Int}}) where {S<:Real}\n\nevaluates the likelihood of a DSGE-VECM given the population moments of the raw data (YYYY, XXYY, XXXX) and the population moments implied by the DSGE prior (YYYYD, XXYYD, XXXXD).\n\nOther Inputs\n\nT: number of time periods in data\nÎ»: weight placed on the DSGE prior\nlags: number of lags in the VECM\nn_obs: number of observables (e.g. number of time series).\ncoint_inds: indices of the cointegrated observables\n\n\n\n\n\n","category":"function"},{"location":"forecast_decomposition/#forecast-decomp-1","page":"Forecast Decomposition","title":"Forecast Decomposition","text":"","category":"section"},{"location":"forecast_decomposition/#","page":"Forecast Decomposition","title":"Forecast Decomposition","text":"CurrentModule = DSGE","category":"page"},{"location":"forecast_decomposition/#","page":"Forecast Decomposition","title":"Forecast Decomposition","text":"Separate from the standard Forecasting routines, we have also implemented a function decompose_forecast for explaining why a forecast changes as new data becomes available and new estimations are run. Please note that this function does not decompose a forecast into the shocks that produce it. For example, if you want to understand whether TFP or financial shocks are driving a forecast, then you should be calculating the shock decomposition output variable (see Calculating Shock Decompositions).","category":"page"},{"location":"forecast_decomposition/#","page":"Forecast Decomposition","title":"Forecast Decomposition","text":"DSGE.decompose_forecast","category":"page"},{"location":"forecast_decomposition/#DSGE.decompose_forecast","page":"Forecast Decomposition","title":"DSGE.decompose_forecast","text":"decompose_forecast(m_new, m_old, df_new, df_old, input_type, cond_new, cond_old,\n    classes; verbose = :low, kwargs...)\n\ndecompose_forecast(m_new, m_old, df_new, df_old, params_new, params_old,\n    cond_new, cond_old, classes; check = false)\n\nexplains the differences between an old forecast and a new forecast by decomposing the differences into three sources:\n\n(1) Data revisions, (2) News (e.g. new data that has become available since the old forecast), (3) Re-estimation (i.e. changes in model parameters).\n\nThis function does not compute which shocks explain a forecast. For example, if you want to know whether TFP or financial shocks drive a given forecast, then you want to compute the shock decomposition output variable (see ?shock_decompositions, forecast_one, and compute_meansbands).\n\nNote that this function currently does not work for a model in which there are changes in the degree of \"regime-switching\" in the TTT, RRR, CCC, ZZ, and DD matrices, e.g. decomposing the changes in the forecast when the monetary policy rule changes or if a temporary policy is implemented that did not occur in the old forecast.\n\nInputs\n\nm_new::M and m_old::M where M<:AbstractDSGEModel\ndf_new::DataFrame and df_old::DataFrame\ncond_new::Symbol and cond_old::Symbol\nclasses::Vector{Symbol}: some subset of [:states, :obs, :pseudo]\n\nMethod 1 only:\n\ninput_type::Symbol: estimation type to use. Parameters will be loaded using load_draws(m_new, input_type) and load_draws(m_old, input_type) in this method\n\nMethod 2 only:\n\nparams_new::Vector{Float64} and params_old::Vector{Float64}: single parameter draws to use\n\nKeyword Arguments\n\ncheck::Bool: whether to check that the individual components add up to the correct total difference in forecasts. This roughly doubles the runtime\n\nMethod 1 only:\n\nverbose::Symbol\n\nOutputs\n\nThe first method returns nothing. The second method returns decomp::Dict{Symbol, Matrix{Float64}}, which has keys of the form :decomp<component><class> and values of size Ny x Nh, where\n\nNy is the number of variables in the given class\nNh is the number of common forecast periods, i.e. periods between date_forecast_start(m_new) and date_forecast_end(m_old)\n\n\n\n\n\n","category":"function"},{"location":"forecast_decomposition/#","page":"Forecast Decomposition","title":"Forecast Decomposition","text":"For an example of how to use this functionality, see decompose_forecast.jl on the Github page (or directly inside the directory where DSGE.jl has been downloaded).","category":"page"},{"location":"julia_forecasting/#Macroeconomic-Forecasting-with-DSGEs-Using-Julia-and-Parallel-Computing-1","page":"MATLAB to Julia Transition: Forecast","title":"Macroeconomic Forecasting with DSGEs Using Julia and Parallel Computing","text":"","category":"section"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Marco Del Negro, Abhi Gupta, Pearl Li, Erica Moszkowski","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"April 17, 2017","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"In December 2015, we announced DSGE.jl, our open-source, Julia-language package for working with dynamic stochastic general equilibrium (DSGE) models. At that time, DSGE.jl contained only the code required to specify, solve, and estimate such models using Bayesian methods. Now, we present the additional code needed to produce economic forecasts using estimated DSGE models. This new code replicates our MATLAB codebase while being more efficient, easier to read, and open source.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"As we noted in our last post and its corresponding technical post, porting our code to Julia presented us with the opportunity to improve both our code's performance and our team's workflow. While the estimation step was largely a direct port, we redesigned the forecast section to obtain code that is faster and easier to use. In this post, we will discuss the performance improvements we have achieved in forecasting the DSGE model, as well as the design principles and Julia tools (particularly related to parallel computing) that helped us achieve those results.","category":"page"},{"location":"julia_forecasting/#Performance-Improvements-1","page":"MATLAB to Julia Transition: Forecast","title":"Performance Improvements","text":"","category":"section"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"To motivate our decision to redesign the forecasting code, we first present some overall performance comparisons between our MATLAB and Julia codebases. Because the design of the code has changed significantly, these results should not be taken as a horse race between Julia and MATLAB. Rather, they should indicate the extent to which our design decisions, in conjunction with the power of the Julia language, have improved the process of running a DSGE forecast.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"These tests were conducted on a single core on an IntelÂ® XeonÂ® E5-2697 v2 2.70GHz CPU running GNU/Linux. The exception is computing all the full-distribution results, which was done using 50 parallel workers.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Benchmark Times Relative to MATLAB 2014a (Smaller is Better)","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Test MATLAB (2014a) Julia (0.4.5)\nSimulation smoothing 1.00 0.38\nForecasting 1.00 0.24\nComputing shock decompositions 1.00 0.12\nFull set of forecast outputs (modal parameters) 1.00 0.10\nFull set of forecast outputs (full distribution of parameters) 1.00* 0.22","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"*Unlike the other steps being tested, the full-distribution forecast timing was run in MATLAB 2009a. Our code relies on MATLAB parallelization features that were deprecated with the introduction of the Parallel Computing Toolbox.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Post estimation, we produce a number of forecast-related outputs, either at the mode or using the full estimated posterior distribution. The tasks involved include smoothing, forecasting (both enforcing the zero lower bound and not), and computing shock decompositions (exercises that allow us to account for the evolution of observed variables in terms of their driving forces).","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"With our most recent model, which is available in DSGE.jl, we can compute all the full-distribution forecast outputs in approximately fifteen minutes. In comparison, the same computations in MATLAB typically take about seventy minutes. As a result, we can experiment with different options and correct mistakes much more flexibly than we could previously.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"In the next sections, we discuss the design principles that guided our port, as well as the Julia parallel programming tools that enabled us to write efficient parallel code.","category":"page"},{"location":"julia_forecasting/#Design-Principles-1","page":"MATLAB to Julia Transition: Forecast","title":"Design Principles","text":"","category":"section"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Our goal when porting the forecast step to Julia was to write code that could efficiently produce easy-to-interpret results. Furthermore, because we are often interested in looking at just one kind of result (for instance, impulse response functions), we wanted it to be equally simple to produce a single, very specific output as it was to produce all results. These two goals translated into two related principles that guided our Julia code development: type-orientation and modularity.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Type-Orientation","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"As we discussed in our previous post, Julia's type system allows us to write very clean, well-structured code, and we use types heavily throughout the codebase. For example, in the forecast step, we use types heavily to keep track of the information we need to download and transform our input data. As an example, let's consider the process of downloading and transforming the GDP series for use in the DSGE model. First, using the FredData.jl package, we pull the aggregate nominal GDP series (in dollars) from the Federal Reserve Economic Database (FRED) programmatically. Before the estimation, we transform this series into the appropriate units for the log-linearized model: quarter-to-quarter log differences of real, per-capita GDP. After estimating and forecasting the model, we finally transform the results into the units most frequently discussed by policymakers and researchers: annualized GDP growth in percentage terms.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"We wanted a simple way to keep track of all of the information associated with the GDP variable in a single place. To do this, we created a new Julia type called an Observable. An instance of the Observable type bundles together the name of the variable, sources used to create the series, and all transformations associated with that series. An instance of this Observable type has the following fields:","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"type Observable\n    key::Symbol\n    input_series::Vector{Symbol}\n    fwd_transform::Function\n    rev_transform::Function\n    name::UTF8String\n    longname::UTF8String\nend","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"The key, name, and longname fields serve similar but slightly different purposes. The key is used as the primary way we refer to the GDP variable in the code: when we construct the entire dataset, we create a DataFrame (2-dimensional table) and label each series with its key. By contrast, name is a longer-form name that we intend to use to label plots, while longname is more of a description of the series. This information helps us to label variables easily and keep the code clear.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"The more interesting fields are input_series, fwd_transform, and rev_transform. The input_series field is a vector of Symbols, each of which must be of the form :SERIES__SOURCE. In the case of GDP, this field is the vector [:GDP__FRED, :CNP16OV__FRED, :GDPDEF__FRED]. All of these series come from FRED, and in particular, we use the nominal GDP, working-age civilian population, and GDP deflator series to construct the real per-capita GDP growth.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"The fwd_transform and rev_transform fields encode the transformations we make to the GDP series to go from raw data to model units and from model units to output units, respectively. These fields are particularly interesting because they must be populated by objects that are of type Function. That's rightâ€”a function is an instance of the Function type! Therefore, a given function is really no different than any other variable in Julia. That means we can define any function we want (abstract, named, with or without keyword arguments) and assign the name of that function to the fwd_transform and rev_transform fields. In the data step of the code, for instance, we can retrieve the name of the function by querying the Observable object and then apply the function to an appropriate set of arguments. This is a very direct method of looking up which transforms to apply, and simultaneously provides the opportunity for us to abstract common transformations into an appropriately named function. Abstraction is a technique for encapsulating low-level functionality or pieces of data into a well-named, reusable function or type. In our case, abstracting transformations into functions is useful because multiple observables can make use of the same commonly used functions.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Finally, we can construct the gdp observable as follows:","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"data_series = [:GDP__FRED, :CNP16OV__FRED, :GDPDEF__FRED]\nfwd_transform = function (levels) ... end    # an anonymous function definition\nrev_transform = loggrowthtopct_annualized_percapita\nobs_gdp = Observable(:obs_gdp, data_series, fwd_transform, rev_transform,\n    \"Real GDP  Growth\", \"Real GDP Growth Per Capita\")","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"We then store obs_gdp in a Dict{Symbol, Observable}, a lookup table that allows us to look up Observable objects, which is in turn stored in the observables field of the model object. We can query the model object for the rev_transform ofgdp_obs by simply calling m.observables[:gdp_obs].rev_transform (where m is an instance of a model type). Since this information is stored inside the model object for every observable, it is automatically available to every function that accepts a model objectâ€”helping us keep our function calls manageable and our data organized.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"We have found Julia's type system to be a helpful way to abstract the details associated with transforming data to and from various units. Observables are clearly a DSGE.jl-specific example of a user-defined type, but we hope this discussion illustrates how Julia types and effective abstraction can help economists structure and clarify their code.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Modularity","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Most software systems (and economic models, for that matter) are designed to produce a wide variety of outputs. Macroeconomists often want to produce tables of parameters, impulse response functions, and time series plots for different economic variables. Often, users want to choose which of a set of possible outputs to compute. In a DSGE model, it is common to compute smoothed histories and forecasts of observables and unobservable states, shock decompositions (which decompose the path of each economic variable into the shocks responsible for its fluctuations), and impulse response functions. Additionally, users may want to change various settings. In our case, we can choose to forecast using the modal parameters or a selection of draws from the posterior distribution of the parameters. We can decide whether or not to enforce the zero lower bound on nominal interest rates. We can use no data from the current quarter, condition on only financial data from the current quarter, or use both financial data and GDP data from the current quarter. We can choose from several different smoothers to compute smoothed histories of states and observables.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Producing and storing all of these results takes both time and disk space. As users of our own old codebase, we found that these costs were often burdensome if we only wanted to produce a single result (for instance, an unconditional shock decomposition for GDP growth). This occurred because the top-level forecast function always called every subroutine, computed every output, and returned all outputs. Redesigning the codebase gave us the opportunity to write code that could produce specific outputs in addition to all outputs.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Fundamentally, in the DSGE forecast, there are three pieces of information we need to produce the specific outputs desired by the user. First, does the user want to produce a modal forecast or a full distribution forecast with uncertainty bands? Second, does she want to condition on any data from the current quarter? And third, which kinds of outputs does she want to produce (forecasts, shock decompositions, etc.)?  Once we know the answers to these questions, we can logically determine which outputs need to be produced and which can be ignored. Therefore, we present the user with one top-level function, which takes in these arguments and determines which subroutines need to be run.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"This modular approach to control flow can be taken in any language, but it is an important component of developing a large software system or economic model and thus we decided it was important to mention. Writing modular, type-oriented, and well-abstracted code improves the robustness of our workflow by making our code and results easier to interpret and less prone to error. In the next section, we'll discuss the main reason our Julia codebase is so fast: we are able to exploit Julia's parallel programming tools.","category":"page"},{"location":"julia_forecasting/#Parallel-Computing-1","page":"MATLAB to Julia Transition: Forecast","title":"Parallel Computing","text":"","category":"section"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"The types of forecast-related computations we do are naturally suited to parallelization. While our MATLAB code was parallelized to an extent (and was written before the advent of the MATLAB Parallel Computing Toolbox!), we decided to reassess our design when we ported the forecast step to Julia. We considered two approaches: \"parallel maps\" and distributed storage. The first is largely similar to our MATLAB parallelization implementation, while the latter takes advantage of the DistributedArrays.jl package and represents a substantial design shift. Over the course of development, we learned a great deal about writing effective parallelized Julia code and about parallel computing in general. Though the distributed storage approach did not end up improving on the parallel mapping approach, our final Julia code is faster and better designed than the original MATLAB implementation.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Like many academic institutions, the New York Fed's Research Group maintains a Linux-based cluster for use by the economists and RAs. This setup allows us to distribute computing jobs across multiple processes on multiple compute nodes, so that non-serially dependent jobs can be executed at the same time. However, our jobs must also coexist with those of other researchers, which limits both the amount of CPU time and memory we can use before disrupting other work. Our code is designed to take advantage of the features of and respect the constraints of this environment.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"During the estimation step, we simulate drawing a large number of parameters (typically 100,000) from their posterior distribution. In the forecast step, these draws are read in and used to compute the desired outputs for our observed variables and the latent states. As discussed before, these outputs can include smoothed shock times series, forecasts, shock decompositions, and impulse response functions. Since these computations are independent for each parameter draw, forecasting using the full distribution lends itself well to parallelization.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"To reduce our impact on other users of the cluster, we make use of a \"blocking\" scheme in our Julia code. The parameter draws are read in blocks of typically 5,000 draws. These draws are then immediately distributed using Julia's pmap function (\"parallel map\") to worker processes, each of which carries out the entire forecast step for just one draw. When all of the draws from that block have completed, the originator process re-collects the forecast outputs and saves them to disk. This repeats until all blocks have completed. Through this blocking, we can avoid keeping too much data in memory, since we only operate on a fraction of the parameter draws at any given time. However, we can still write structured output files using the HDF5 file format, which allows us to write to specific subsets of pre-allocated arrays, so that the end result is as if we had computed all the draws at once without blocking.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Before settling on this version, we also tried using Julia's DistributedArrays.jl package, which distributes large arrays in memory over many processes. This allowed us to hold all of our parameter draws and their corresponding forecast outputs in memory at the same time, and it allowed each process to operate on the parameter draws it held locally without needing to copy data back and forth between processes. However, using distributed arrays also forced us to explicitly handle lower-level tasks like assigning parameter draws to processes. Since each process handled a predetermined set of draws, it was not easy to reallocate draws if some of the compute nodes on which the processes lived happened to be busier than others on a particular day. Switching to pmap allowed us to abstract away from many of these concerns, as it has already been optimized to take advantage of the aforementioned independence of parameter draws.","category":"page"},{"location":"julia_forecasting/#StateSpaceRoutines.jl-1","page":"MATLAB to Julia Transition: Forecast","title":"StateSpaceRoutines.jl","text":"","category":"section"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"A big benefit of using Julia is the large and growing package ecosystem, which allows all users to access high-quality open-source code. Thanks to this system, Julia developers can focus their development time on the issues and projects they really care about, without having to repeatedly reinvent the wheel. For example, DSGE.jl depends on the DataFrames.jl package to help us manage data and dates. Similarly, DSGE.jl is available for members of the community to modify, extend, and make use of as they see fit. In this spirit, we have decided to break out some DSGE-independent components of DSGE.jl into their own package.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"DSGE models define a linear system that links observed variables to unobserved states. In order to actually perform inference on these latent states, we apply the Kalman filter and smoothing algorithms. State space models are commonly used across many disciplines, and indeed the routines we use in DSGE.jl can be applied to any sort of linear state space model. As such, we have decided to move the filtering and smoothing routines that we have historically used with the DSGE model into StateSpaceRoutines.jl, a new package that will provide DSGE.jl-independent filtering and smoothing routines.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"StateSpaceRoutines.jl currently features the one filter and four smoothers we most commonly use in DSGE.jl. On the filtering front, we implement the standard Kalman filter found in James Hamilton's Time Series Analysis StateSpaceRoutines.jl also contains two Kalman smoothers and two simulation smoothers. In addition to the Kalman smoother presented in Time Series Analysis, we also have Jan Koopman's disturbance smoother from his paper Disturbance Smoother for State Space Models. The two simulation smoothers are based on Carter and Kohn's On Gibbs Sampling for State Space Models and Durbin and Koopman's A Simple and Efficient Simulation Smoother for State Space Time Series Analysis. In our experience, the Koopman smoother is faster than the standard Kalman smoother, as it does not require us to calculate the pseudo- inverses of the predicted variance matrices. For the same reason, we have also found that the Durbin and Koopman simulation smoother is faster than the Carter and Kohn one. All of these methods support time-varying matrices and variances. We use this feature to model preâ€“zero-lower-bound and zero-lower-bound regimes in our DSGE models, but the functionality is general enough to be applied to a wider range of models with regime switching or time varying matrices and variances. We hope that the broader Julia community finds these functions as useful as we have!","category":"page"},{"location":"julia_forecasting/#Disclaimer-1","page":"MATLAB to Julia Transition: Forecast","title":"Disclaimer","text":"","category":"section"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"This post reflects the experience of the authors with Julia and MATLAB and does not represent an endorsement by the Federal Reserve Bank of New York or the Federal Reserve System of any particular product or service. The views expressed in this post are those of the authors and do not necessarily reflect the position of the Federal Reserve Bank of New York or the Federal Reserve System. Any errors or omissions are the responsibility of the authors.","category":"page"},{"location":"julia_forecasting/#References-1","page":"MATLAB to Julia Transition: Forecast","title":"References","text":"","category":"section"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Carter, C. and Cohn, R. (1994). On Gibbs Sampling for State Space models. Biometrika.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Durbin, K. and Koopman, S. (2002). A Simple and Efficient Smoother for State Space Time Series Analysis. Biometrika.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Hamilton, J. (1994). Time Series Analysis. Princeton: Princeton University Press.","category":"page"},{"location":"julia_forecasting/#","page":"MATLAB to Julia Transition: Forecast","title":"MATLAB to Julia Transition: Forecast","text":"Koopman, S. (1993). Disturbance Smoother for State Space Models. Biometrika.","category":"page"},{"location":"irf/#irf-doc-1","page":"Impulse Response Functions","title":"Impulse Responses","text":"","category":"section"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"CurrentModule = DSGE","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"We provide many different types of impulse responses for DSGEs, VARs, VECMs, DSGE-VARs, and DSGE-VECMs. The forecast step allows the user to automatically compute \"structural\" impulse responses specifically for DSGEs, but for some purposes, a user may just want impulse responses without having to compute any other quantities. We provide this functionality with the impulse_responses function. See the end of this page for the docstrings of all available impulse response functions.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"We overload impulse_responses to cover specific use cases. For any AbstractDSGEModel, we can compute the impulse responses over a specified horizon for all endogenous state variables, observables, and pseudo-observables by running","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"m = AnSchorfheide()\nsystem = compute_system(m)\nhorizon = 40\nstates_irf, obs_irf, pseudo_irf = impulse_response(system, horizon)","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"For an AbstractRepModel (a subtype of AbstractDSGEModel for representative agent models), we can also grab the impulse responses by running","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"states_irf, obs_irf, pseudo_irf = impulse_response(m, system)","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"This use case requires the user to add a setting under the key :impulse_response_horizons, which is set by default to 40.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"If a user wants to specify a subset of the exogenous shocks and the size of those shocks, the user can run","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"shock_names = [:g_sh, :b_sh]\nshock_values = [1.0, 1.0]\nimpulse_responses(m, system, horizon, shock_names, shock_values)","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"For the response of an endogenous state or observable to a specific shock,","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"shock_name  =  :g_sh\nvar_name = :obs_gdp\nvar_value = 0.\nimpulse_responses(m, system, horizon, shock_name , var_name, var_value)","category":"page"},{"location":"irf/#DSGE-Impulse-Responses-1","page":"Impulse Response Functions","title":"DSGE Impulse Responses","text":"","category":"section"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"There are two categories of impulse responses for DSGEs provided by DSGE.jl. It is easy to distinguish them by examining the state space form of a DSGE model (see Solving):","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"beginaligned\ns_t = T s_t-1 + R epsilon_t + C  epsilon_t sim N(0 Q)  mathrm(transition) \ny_t = Z s_t + D + u_t  u_t sim N(0 E)  mathrm(measurement)\nendaligned","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"Impulse responses in the first category are \"structural\" impulse responses, which are the response of states and observables to the exogenous structural shocks epsilon_t.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"Impulse responses in the second category are \"observables-identified\" impulse responses. First, we may suppose that the measurement equation generically follows","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"y_t = F(s_t) + eta_t","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"where F(cdot) is some function of the unknown states s_t, and eta_t are random innovation to the observables y_t. By innovations, we mean that these random variables are potentially endogenous shocks, i.e. shocks which do not have a causal interpretation. An \"observables-identified\" impulse response specifies a certain response of y_t to the innovations eta_t, and uses this response to identify the underlying structural shocks which are consistent with these innovations. A DSGE identifies these innovations using the state space form of a DSGE.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"We provide three types of \"observables-identified\" impulse responses for DSGEs.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"Short-Run Cholesky\nLong-Run Cholesky\nMaximizing Explained Cyclical Variance","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"We document the details of the identification in the docstrings of these impulse response functions. For the first two types of impulse responses, search the docstrings at the end of the page for","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"function impulse_responses(system::System{S}, horizon::Int, permute_mat::AbstractMatrix{T},\n                           shocks::AbstractVector{S} = Vector{S}(undef, 0);\n                           restriction::Symbol = :short_run, flip_shocks::Bool = false,\n                           get_shocks::Bool = false) where {S <: Real, T <: Number}","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"For the third type of impulse response, search for","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"function impulse_responses(system::System{S}, horizon::Int, frequency_band::Tuple{S,S},\n                           n_obs_shock::Int; flip_shocks::Bool = false,\n                           get_shocks::Bool = false) where {S <: Real}","category":"page"},{"location":"irf/#VAR-Impulse-Responses-1","page":"Impulse Response Functions","title":"VAR Impulse Responses","text":"","category":"section"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"While we have not yet implemented a VAR model, we do have impulse responses often used on VARs because of DSGE-VARs. Consider the VAR","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"y_t = X_t beta + epsilon_t","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"where X_t is a matrix of the lags of y_t, beta are the VAR coefficients, and epsilon_t sim N(0 Omega) are the innovations to observables.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"We provide three types of impulse responses, each of which provide a different way of identifying orthogonalized shocks from the innovations.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"Short-Run Cholesky\nLong-Run Cholesky\nMaximizing Explained Cyclical Variance","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"These impulse responses are named the same as the observables-identified impulse responses for DSGEs because they are considering the same response of observables to the innovations. However, the treatment of identification is different when using a VAR because the mathematical structure of a VAR is not the same as a DSGE's. As a result, there are slight differences between these impulse responses and the observables-identified DSGE impulse responses.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"impulse_responses(Î², Î£, n_obs_shock, horizon, shock_size = 1;\n    method = :cholesky, flip_shocks = false, use_intercept = true,\n    frequency_band = (2Ï€/32, 2Ï€/6)) where {S<:Real}","category":"page"},{"location":"irf/#DSGE-VAR-Impulse-Responses-1","page":"Impulse Response Functions","title":"DSGE-VAR Impulse Responses","text":"","category":"section"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"There are two types of impulse responses we can compute for a DSGE-VAR. For both types, we first draw from the posterior distributions of the VAR(p) coefficients and innovations variance-covariance matrix, where p is the number of lags. With these draws, we can do one of two things:","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"Compute the VAR impulse response implied by the draws.\nUse the DSGE's structural impact response (i.e. the first period of an impulse response) to identify a mapping from the (endogenous) innovations in the VAR to the structural shocks of the DSGE.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"The first type of impulse response uses the same code as the VAR impulse responses once we compute the coefficients and innovations variance-covariance matrix. We call the second type of impulse responses \"DSGE-VAR rotation impulse responses\" because we effectively use the DSGE to identify a rotation matrix.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"For the first type of impulse response, see","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"function impulse_responses(m::AbstractDSGEVARModel{S}, data::AbstractArray{S}, method::Symbol,\n                           n_obs_shock::Int; horizon::Int = 0 ,use_intercept::Bool = false,\n                           flip_shocks::Bool = false, verbose::Symbol = :none) where {S <: Real}\n\nfunction impulse_responses(m::AbstractDSGEVARModel{S}, method::Symbol,\n                           n_obs_shock::Int; horizon::Int = 0 ,use_intercept::Bool = false,\n                           flip_shocks::Bool = false, verbose::Symbol = :none) where {S <: Real}","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"The second function is for the specific case when lambda = infty, where the data does not matter for the impulse response.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"For the second type of impulse responses, see","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"function impulse_responses(m::AbstractDSGEVARModel{S}, data::AbstractArray{S},\n    XÌ‚::Matrix{S} = Matrix{S}(undef, 0, 0);\n    horizon::Int = 0, MM::Matrix{S} = Matrix{S}(undef, 0, 0),\n    flip_shocks::Bool = false, draw_shocks::Bool = false,\n    deviations::Bool = false,\n    verbose::Symbol = :none) where {S <: Real}","category":"page"},{"location":"irf/#VECM-Impulse-Responses-1","page":"Impulse Response Functions","title":"VECM Impulse Responses","text":"","category":"section"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"While we have not yet implemented a VECM model, we do have impulse responses often used on VECMs because of DSGE-VECMs. Consider the VECM","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"Delta y_t = e_t - 1 beta_e +  X_t beta_v + epsilon_t","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"where e_t - 1 are cointegrating relationships (the error correction terms); X_t is a matrix of the lags of Delta y_t; beta_e and beta_v are the VECM coefficients; and epsilon_t sim N(0 Omega) are the innovations to observables. We identify orthogonalized shocks for VECMs from the innovations using the short-run Cholesky method. Other methods have yet to be implemented, hence passing keywords specific to these methods will not do anything (namely frequency_band). Find the docstring of the following function for details.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"impulse_responses(Î², Î£, coint_mat, n_obs_shock, horizon, shock_size = 1;\n    method = :cholesky, flip_shocks = false, use_intercept = true,\n    frequency_band = (2Ï€/32, 2Ï€/6)) where {S<:Real}","category":"page"},{"location":"irf/#DSGE-VECM-Impulse-Responses-1","page":"Impulse Response Functions","title":"DSGE-VECM Impulse Responses","text":"","category":"section"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"Most of the impulse responses for DSGE-VARs have been implemented for DSGE-VECMs. The two impulse responses that have not been implemented, due to the differences in VECMs and VARs, are the maxBC and cholesky_long_run impulse responses. For the first type of impulse responses, which use the VECM impulse response code, see the functions","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"function impulse_responses(m::AbstractDSGEVECMModel{S}, data::AbstractArray{S},\n                           coint_mat::AbstractMatrix{S}, method::Symbol,\n                           n_obs_shock::Int; horizon::Int = 0 ,use_intercept::Bool = false,\n                           flip_shocks::Bool = false, verbose::Symbol = :none) where {S <: Real}\n\nfunction impulse_responses(m::AbstractDSGEVECMModel{S}, coint_mat::AbstractMatrix{S}, method::Symbol,\n                           n_obs_shock::Int; horizon::Int = 0 ,use_intercept::Bool = false,\n                           flip_shocks::Bool = false, verbose::Symbol = :none) where {S <: Real}","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"The second function is for the specific case when lambda = infty, where the data does not matter for the impulse response.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"For the second type of impulse responses, which we call rotation impulse responses, see","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"function impulse_responses(m::AbstractDSGEVECMModel{S}, data::AbstractArray{S},\n                           coint_mat::AbstractMatrix{S},\n                           XÌ‚::Matrix{S} = Matrix{S}(undef, 0, 0);\n                           horizon::Int = 0, MM::Matrix{S} = Matrix{S}(undef, 0, 0),\n                           flip_shocks::Bool = false, draw_shocks::Bool = false,\n                           deviations::Bool = false,\n                           verbose::Symbol = :none) where {S <: Real}","category":"page"},{"location":"irf/#Wrappers-for-Impulse-Response-Functions-1","page":"Impulse Response Functions","title":"Wrappers for Impulse Response Functions","text":"","category":"section"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"The forecast_one function provides a wrapper for computing structural DSGE impulse responses when drawing from a distribution of parameters and for saving these impulse responses as MeansBands objects (see Computing Means and Bands).","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"However, forecast_one currently cannot compute observables-identified DSGE impulse responses, VAR impulse responses, or DSGE-VAR impulse responses, and we do not plan on modifying forecast_one to make it possible to do so. Instead, we provide three wrapper functions specifically for computing means and bands for these impulse responses. Please see their docstrings for details. The first wrapper is for observables-identified DSGE impulse responses, and the second two are for DSGE-VAR impulse responses. The first one applies generically to a DSGE-VAR with any prior weight lambda, but the second one is a convenience wrapper for the case of lambda = infty, which is equivalent to computing the impulse responses of the VAR approximation to a DSGE.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"No wrappers for DSGE-VECM impulse responses have been implemented because we have not constructed a DSGE model that can be interfaced with the DSGEVECM type yet. As a result, there are no explicit test cases for these wrappers. We have decided against implementing wrappers for DSGE-VECM impulse responses until we have test cases to guarantee the wrappers do not have bugs.","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"For observables-identified DSGE impulse responses, find","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"function impulse_responses(m::AbstractDSGEModel, paras::Matrix{S},\n                           input_type::Symbol, method::Symbol, n_obs_shock::Int,\n                           output_vars::Vector{Symbol} =\n                           [:irfstates, :irfobs, :irfpseudo]; parallel::Bool = false,\n                           permute_mat::Matrix{S} = Matrix{Float64}(undef,0,0),\n                           frequency_band::Tuple{S,S} = (2*Ï€/32, 2*Ï€/6),\n                           flip_shocks::Bool = false,\n                           density_bands::Vector{Float64} = [.5, .6, .7, .8, .9],\n                           create_meansbands::Bool = false, test_meansbands::Bool = false,\n                           minimize::Bool = true,\n                           forecast_string::String = \"\",\n                           do_rev_transform::Bool = false,\n                           verbose::Symbol = :high) where {S<:Real}","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"For DSGE-VAR impulse responses, find","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"function impulse_responses(m::AbstractDSGEVARModel{S}, paras::Matrix{S},\n                           data::Matrix{S}, input_type::Symbol, method::Symbol;\n                           parallel::Bool = false,\n                           frequency_band::Tuple{S,S} = (2*Ï€/32, 2*Ï€/6),\n                           n_obs_shock::Int = 1, draw_shocks::Bool = false,\n                           flip_shocks::Bool = false,\n                           XÌ‚::AbstractMatrix{S} = Matrix{S}(undef, 0, 0),\n                           deviations::Bool = false\n                           density_bands::Vector{Float64} = [.5, .6, .7, .8, .9],\n                           create_meansbands::Bool = false, test_meansbands::Bool = false,\n                           minimize::Bool = true,\n                           forecast_string::String = \"\",\n                           verbose::Symbol = :high) where {S<:Real}","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"For the impulse response of a VAR approximation to a DSGE, find","category":"page"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"function impulse_responses(m::AbstractDSGEModel, paras::Union{Vector{S}, Matrix{S}},\n                           input_type::Symbol, method::Symbol,\n                           lags::Int, observables::Vector{Symbol},\n                           shocks::Vector{Symbol},\n                           n_obs_shock::Int; parallel::Bool = false,\n                           frequency_band::Tuple{S,S} = (2*Ï€/32, 2*Ï€/6),\n                           flip_shocks::Bool = false,\n                           use_intercept::Bool = false,\n                           density_bands::Vector{Float64} = [.5, .6, .7, .8, .9],\n                           create_meansbands::Bool = false,\n                           minimize::Bool = true,\n                           forecast_string::String = \"\",\n                           verbose::Symbol = :high) where {S<:Real}","category":"page"},{"location":"irf/#Docstrings-1","page":"Impulse Response Functions","title":"Docstrings","text":"","category":"section"},{"location":"irf/#","page":"Impulse Response Functions","title":"Impulse Response Functions","text":"DSGE.impulse_responses","category":"page"},{"location":"irf/#DSGE.impulse_responses","page":"Impulse Response Functions","title":"DSGE.impulse_responses","text":"impulse_responses(m, system)\n\nimpulse_responses(system, horizon)\n\nCompute impulse responses for a single draw.\n\nInputs\n\nm::AbstractDSGEModel: model object\nsystem::System{S}: state-space system matrices\nhorizon::Int: number of periods ahead to forecast\nflip_shocks::Bool: Whether to compute IRFs in response to a positive shock (by default the shock magnitude is a negative 1 std. shock)\n\nwhere S<:AbstractFloat\n\nOutputs\n\nstates::Array{S, 3}: matrix of size nstates x horizon x nshocks of state impulse response functions\nobs::Array{S, 3}: matrix of size nobs x horizon x nshocks of observable impulse response functions\npseudo::Array{S, 3}: matrix of size npseudo x horizon x nshocks of pseudo-observable impulse response functions\n\n\n\n\n\nfunction impulse_responses(system::System{S}, horizon::Int, permute_mat::AbstractMatrix{T},\n                           shocks::AbstractVector{S} = Vector{S}(undef, 0);\n                           restriction::Symbol = :short_run, flip_shocks::Bool = false,\n                           get_shocks::Bool = false) where {S <: Real, T <: Number}\n\ncomputes impulse responses using a Cholesky-identified shock to observables, with the ability to apply a permutation matrix.\n\nInputs\n\nsystem::System{S}: state-space system matrices\nhorizon::Int: number of periods ahead to forecast\npermute_mat::AbstractMatrix{T}: permutation matrix\nshocks::AbstractVector{S}: vector of orthogonal shocks to observables.   See the section Restriction Types below for a mathematical explanation.   If no vector is provided, then we assume the user wants a shock vector   whose first entry is one and all other entries are zero (a 1 standard deviation   shock to the innovation affecting the first variable).\nrestriction::Symbol: type of restriction for the Cholesky identification.   Can be either :short_run or :long_run. We also let :cholesky refer   specifically to the :short_run restriction and   :choleskyLR or :cholesky_long_run refer to the :long_run restriction.\nflip_shocks::Bool: Whether to compute IRFs in response to a positive shock   (by default the shock magnitude is a negative 1 std. shock)\nget_shocks::Bool: Whether to return the Cholesky-identified shocks and the   underlying structural shocks\n\nOutputs\n\nstates::Matrix{S}: matrix of size nstates x horizon x nshocks of state impulse response functions\nobs::Matrix{S}: matrix of size nobs x horizon x nshocks of observable impulse response functions\npseudo::Matrix{S}: matrix of size npseudo x horizon x nshocks of pseudo-observable impulse response functions\ncholesky_shock::Vector{S}: Cholesky-identified shock on impact (only if get_shocks = true)\nstructural_shock::Vector{S}: structural shocks causing the   Cholesky-identified shock (only if get_shocks = true)\n\nRestriction Types\n\nConsider a state space system\n\nsâ‚œ = TTT * sâ‚œâ‚‹â‚ + RRR * sqrt(QQ) * Ïµâ‚œ\nyâ‚œ = ZZ * sâ‚œ\n\nwhere Ïµâ‚œ âˆ¼ ð’© (0, I) and QQ is a diagonal matrix specifying the variances of the structural shocks Ïµâ‚œ. Under this specification, the units of Ïµâ‚œ are standard deviations.\n\nA Cholesky identification searches for a lower triangular matrix M such that M * M' equals the covariance of observables. The restriction is short-run if we take the short-run covariance and is long run if we take the long-run covariance (i.e. the covariance of observables when shocks occur to the stationary level of sâ‚œ). Explicitly, the short- and long-run restrictions are, respectively,\n\nCovâ‚›áµ£ = (ZZ * RRR) * QQ * (ZZ * RRR)',\nCovâ‚—áµ£ = (ZZ * (I - TTT)â»Â¹ * RRR) * QQ * (ZZ * (I - TTT)â»Â¹ * RRR)'.\n\nTaking the Cholesky decomposition of the appropriate covariance matrix yields the lower triangular matrix M.\n\nUsing M, we may re-write the measurement equation of the state space as\n\nyâ‚œ = ZZ * TTT * sâ‚œâ‚‹â‚ + M * uâ‚œ,\n\nwhere uâ‚œ âˆ¼ ð’© (0, I) are orthogonal shocks identified from the covariance of yâ‚œ using M. The orthogonal shocks uâ‚œ are precisely the input argument shocks. We can map uâ‚œ to Ïµâ‚œ, i.e. identify structural shocks, by solving the linear system\n\n(ZZ * RRR * sqrt(QQ)) * Ïµâ‚œ = M * uâ‚œ\n\nwhen using the short-run restriction and\n\n(ZZ * (I - TTT)â»Â¹ * RRR * sqrt(QQ)) * Ïµâ‚œ = M * uâ‚œ\n\nwhen using the long-run restriction.\n\n\n\n\n\nfunction impulse_responses(system::System{S}, horizon::Int, frequency_band::Tuple{S,S},\n                           n_obs_shock::Int; flip_shocks::Bool = false,\n                           get_shocks::Bool = false) where {S<:Real}\n\ncomputes impulse responses by identifying the shock which maximizes the variance explained of a chosen observable within a certain frequency band.\n\nFor typical business-cycle frequences, we recommend setting frequency_band = (2 * Ï€ / 32, 2 * Ï€ / 6).\n\nInputs\n\nsystem::System{S}: state-space system matrices\nhorizon::Int: number of periods ahead to forecast\nfrequency_band::Tuple{S, S}: the frequencies at which we want to maximize the variance explained.   The first frequency must be less than the second one.\nn_obs_shock::Int: the index of the observable whose variance we want to maximally explain   in the state space model implied by system.\nflip_shocks::Bool: Whether to compute IRFs in response to a positive shock (by default the shock magnitude is a negative 1 std. shock)\nget_shocks::Bool: Whether to return the structural shocks.\n\nwhere S <: Real\n\nOutputs\n\nstates::Matrix{S}: matrix of size nstates x horizon x nshocks of state impulse response functions\nobs::Matrix{S}: matrix of size nobs x horizon x nshocks of observable impulse response functions\npseudo::Matrix{S}: matrix of size npseudo x horizon x nshocks of pseudo-observable impulse response functions\nstructural_shock::Vector{S}: structural shocks causing the   Cholesky-identified shock (only if get_shocks = true)\n\n\n\n\n\nfunction impulse_responses(m::AbstractDSGEModel, paras::Union{Vector{S}, Matrix{S}},\n                           input_type::Symbol, method::Symbol,\n                           lags::Int, observables::Vector{Symbol},\n                           shocks::Vector{Symbol},\n                           n_obs_shock::Int; parallel::Bool = false,\n                           frequency_band::Tuple{S,S} = (2*Ï€/32, 2*Ï€/6),\n                           flip_shocks::Bool = false,\n                           use_intercept::Bool = false,\n                           density_bands::Vector{Float64} = [.5, .6, .7, .8, .9],\n                           create_meansbands::Bool = false,\n                           minimize::Bool = true,\n                           forecast_string::String = \"\",\n                           verbose::Symbol = :high) where {S<:Real}\n\ncomputes the impulse responses of a VAR(p) approximation to a DSGE.\n\nInputs\n\nm::Union{AbstractDSGEModel,AbstractDSGEVARModel}: DSGE/DSGEVAR model object\nparas::Matrix{S} or paras::Vector{S}: parameters to calibrate the model\ninput_type::Symbol: :mode specifies a modal impulse response, and   :full specifies a full-distribution forecast if paras is not given.   This argument is also used to construct the file names of computed MeansBands.\nmethod::Symbol: type of impulse response to compute. The options are   :cholesky, :maximum_business_cycle_variance or :maxBC,   and :cholesky_long_run or :choleskyLR. See ?cholesky_shock,   ?maxBC_shock, and ?choleskyLR_shock.\nlags::Int: number of lags in the VAR(p) approximation, i.e. p = lags\nobservables::Vector{Symbol}: observables to be used in the VAR. These can be   any of the observables or pseudo-observables in m.\nshocks::Vector{Symbol}: (structural) exogenous shocks to be used in the DSGE-VAR.   These shocks must be in m.\nn_obs_shock::Int: the index of the observable corresponding to the orthogonalized shock causing the impulse response.\n\nKeywords\n\nparallel::Bool: use parallel workers or not\nfrequency_band::Tuple{S,S}: See ?maxBC_shock.\nflip_shocks::Bool: impulse response shocks are negative by default. Set to true for   a positive signed shock.\ndensity_bands::Vector{Float64}: bands for full-distribution IRF computations\ncreate_meansbands::Bool: set to true to save output as a MeansBands object.\nminimize::Bool: choose shortest interval if true, otherwise just chop off lowest and   highest (percent/2)\nforecast_string::String: string tag for identifying this impulse response\nverbose::Symbol: quantity of output desired\n\n\n\n\n\nfunction impulse_responses(m::AbstractDSGEVARModel{S}, paras::Matrix{S},\n                           data::Matrix{S}, input_type::Symbol, method::Symbol;\n                           parallel::Bool = false,\n                           frequency_band::Tuple{S,S} = (2*Ï€/32, 2*Ï€/6),\n                           n_obs_shock::Int = 1, draw_shocks::Bool = false,\n                           flip_shocks::Bool = false,\n                           XÌ‚::AbstractMatrix{S} = Matrix{S}(undef, 0, 0),\n                           deviations::Bool = false, normalize_rotation::Bool = false,\n                           density_bands::Vector{Float64} = [.5, .6, .7, .8, .9],\n                           create_meansbands::Bool = false, test_meansbands::Bool = false,\n                           minimize::Bool = true,\n                           forecast_string::String = \"\",\n                           verbose::Symbol = :high) where {S<:Real}\n\ncomputes the VAR impulse responses identified by the state space system\n\nsâ‚œ = TTT Ã— sâ‚œâ‚‹â‚ + RRR Ã— impact[:, i],\nyâ‚œ = ZZ Ã— sâ‚œ + DD + MM Ã— impact[:, i],\n\nwhere impact[:, i] is a linear combination of (orthogonal) structural shocks Ïµâ‚œ âˆ¼ ð’© (0, I), and MM Ã— impact[:, i] are the correlated measurement errors.\n\nThe VAR impulse responses are computed according to\n\nyÌ‚â‚œâ‚Šâ‚ = XÌ‚â‚œâ‚Šâ‚Î² + uâ‚œâ‚Šâ‚,\n\nwhere XÌ‚â‚œâ‚Šâ‚ are the lags of observables in period t + 1, i.e. yâ‚œ, yâ‚œâ‚‹â‚, ..., yâ‚œâ‚‹â‚š.\n\nIf the method is :rotation, the shock uâ‚œâ‚Šâ‚ is identified via\n\nÎ£áµ¤ = ð”¼[u Ã— u'] = chol(Î£áµ¤) Ã— Î© Ã— Ïµâ‚œ,\n\nwhere the rotation matrix Î© is the Q matrix from a QR decomposition of the impact response matrix corresponding to the state space system, i.e.\n\nÎ©, _ = qr(âˆ‚yâ‚œ / âˆ‚Ïµâ‚œ').\n\nOtherwise, we draw a Î² and Î£áµ¤ from the posterior implied by the DSGE and data, and we then compute normal VAR impulse responses given those coefficients and innovations variance-covariance matrix.\n\n\n\nNOTE: this function generally involves taking random draws from probability distributions, so seeds need to be set to achieve reproducibility. ****\n\nInputs\n\nm::Union{AbstractDSGEModel,AbstractDSGEVARModel}: DSGE/DSGEVAR model object\nparas::Matrix{S} or paras::Vector{S}: parameters to calibrate the model\ninput_type::Symbol: :mode specifies a modal impulse response, and   :full specifies a full-distribution forecast if paras is not given.   This argument is also used to construct the file names of computed MeansBands.\nmethod::Symbol: type of impulse response to compute. The options are   :cholesky and :rotation. For the first, see ?cholesky_shock,   and for the latter, we use the DSGE model to identify the rotation matrix   which maps the DSGE's structural shocks to the innovations in the VAR's observables.\nlags::Int: number of lags in the VAR(p) approximation, i.e. p = lags\nobservables::Vector{Symbol}: observables to be used in the VAR. These can be   any of the observables or pseudo-observables in m.\nshocks::Vector{Symbol}: (structural) exogenous shocks to be used in the DSGE-VAR.   These shocks must be in m.\nn_obs_shock::Int: the index of the observable corresponding to the orthogonalized shock causing the impulse response.\n\nKeywords\n\nparallel::Bool: use parallel workers or not\nfrequency_band::Tuple{S,S}: See ?maxBC_shock.\nn_obs_shock::Int: Index of observable to be shocked when using a Cholesky-based impulse response\ndraw_shocks::Bool: true if you want to draw shocks along the entire horizon\nflip_shocks::Bool: impulse response shocks are negative by default. Set to true for   a positive signed shock.\nXÌ‚::AbstractMatrix{S}: matrix stacking the intercept and lags of the data for   rotation IRFs. Set to a vector of zeros with length 1 + n_observables * p   to compute the rotation IRFs in deviations from the baseline forecast.\ndeviations::Bool: set true to compute the impulse response in deviations   rather than as a forecast. Mechnically, we ignore XÌ‚ (treated as zeros)   and the intercept term.\nnormalize_rotation::Bool: set to true to normalize the rotation   so that rows have the correct sign. This requires as many structural shocks   as there are observables in the DSGE-VAR.\ndensity_bands::Vector{Float64}: bands for full-distribution IRF computations\ncreate_meansbands::Bool: set to true to save output as a MeansBands object.\nminimize::Bool: choose shortest interval if true, otherwise just chop off lowest and   highest (percent/2)\nforecast_string::String: string tag for identifying this impulse response\nverbose::Symbol: quantity of output desired\n\n\n\n\n\nimpulse_responses(Î², Î£, n_obs_shock, horizon, shock_size = 1;\n    method = :cholesky, flip_shocks = false, use_intercept = true,\n    frequency_band = (2Ï€/32, 2Ï€/6)) where {S<:Real}\n\ncomputes the impulse responses of a VAR system represented in the form\n\nyâ‚œ = Xâ‚œÎ² + Ïµâ‚œ,\n\nwhere Xâ‚œ stacks the lags of yâ‚œ (with dimensions nobservables x nregressors), and\n\nÏµâ‚œ âˆ¼ ð’© (0, Î£).\n\nInputs\n\nÎ²::AbstractMatrix{S}: coefficient matrix\nÎ£::AbstractMatrix{S}: innovations variance-covariance matrix\nn_obs_shock::Int: index of the observable corresponding to the orthogonalized shock   causing the impulse response.\nshock_size::S: number of standard deviations of the shock\n\nKeywords\n\nmethod::Symbol: type of impulse response to compute. The available options are   :cholesky (default), :maximum_business_cycle_variance or :maxBC, and   :cholesky_long_run or :choleskyLR. See ?cholesky_shock, ?maxBC_shock,   and ?cholesky_long_run_shock.\nflip_shocks::Bool: by default, we compute the impulse responses to a negative shock.   Set flip_shocks = true to obtain a positive shock.\nuse_intercept::Bool: impulse_responses assumes Î² has constant term(s). If there   are no such terms, then use_intercept must be set to false.\nfrequency_band::Tuple{S,S}: See ?maxBC_shock.\n\nOutputs\n\nY::AbstractMatrix: Impulse response matrix with dimensions horizons x n_observables\n\n\n\n\n\nimpulse_responses(Î², Î£, coint_mat, n_obs_shock, horizon, shock_size = 1;\n    method = :cholesky, flip_shocks = false, use_intercept = true,\n    frequency_band = (2Ï€/32, 2Ï€/6)) where {S<:Real}\n\ncomputes the impulse responses of a VECM system represented in the form\n\nÎ”yâ‚œ = eâ‚œâ‚‹â‚ Î²â‚‘ + Xâ‚œ Î²áµ¥ + Ïµâ‚œ,\n\nwhere Î²â‚‘ are the coefficients for the error correction terms; eâ‚œ are the error correction terms specifying the cointegrating relationships; Î²áµ¥ are the coefficients for the VAR terms (including the intercept); Xâ‚œ are the lags of observables in period t, i.e. yâ‚œâ‚‹â‚, yâ‚œâ‚‹2, ..., yâ‚œâ‚‹â‚š; and Ïµâ‚œ âˆ¼ ð’© (0, Î£). We assume that Î² = [Î²â‚‘; Î²áµ¥].\n\nInputs\n\nÎ²::AbstractMatrix{S}: coefficient matrix\nÎ£::AbstractMatrix{S}: innovations variance-covariance matrix\ncoint_mat::AbstractMatrix{S}: matrix specifying the cointegrating relationships.   Multiplying coint_mat * data, where data is an n_observables Ã— T matrix, should yield   an n_coint Ã— T matrix, where n_coint are the number of cointegrating   relationships and T are the number of periods of data.\nn_obs_shock::Int: index of the observable corresponding to the orthogonalized shock   causing the impulse response.\nshock_size::S: number of standard deviations of the shock\n\nKeywords\n\nmethod::Symbol: type of impulse response to compute. The available option is   :cholesky (default).\nflip_shocks::Bool: by default, we compute the impulse responses to a negative shock.   Set flip_shocks = true to obtain a positive shock.\nuse_intercept::Bool: impulse_responses assumes Î² has constant term(s). If there   are no such terms, then use_intercept must be set to false.\nfrequency_band::Tuple{S,S}: See ?maxBC_shock.\n\nOutputs\n\nY::AbstractMatrix: Impulse response matrix with dimensions horizons x n_observables\n\n\n\n\n\nfunction impulse_responses(m::AbstractDSGEVARModel{S}, data::AbstractArray{S}, method::Symbol,\n                           n_obs_shock::Int; horizon::Int = 0,\n                           flip_shocks::Bool = false, verbose::Symbol = :none) where {S <: Real}\n\nfunction impulse_responses(m::AbstractDSGEVARModel{S}, method::Symbol,\n                           n_obs_shock::Int; horizon::Int = 0, use_intercept::Bool = false,\n                           flip_shocks::Bool = false, verbose::Symbol = :none) where {S <: Real}\n\ncomputes the VAR impulse responses identified by the DSGE\n\nsâ‚œ = TTT Ã— sâ‚œâ‚‹â‚ + RRR Ã— impact[:, i],\nyâ‚œ = ZZ Ã— sâ‚œ + DD + MM Ã— impact[:, i],\n\nwhere impact[:, i] is a linear combination of (orthogonal) structural shocks Ïµâ‚œ âˆ¼ ð’© (0, I), and MM Ã— impact[:, i] are the correlated measurement errors.\n\nWe draw a Î² and Î£áµ¤ from the posterior implied by the DSGE and data, and we then compute normal VAR impulse responses given those coefficients and innovations variance-covariance matrix. The weight placed on the DSGE is encoded by the field Î» of the DSGEVAR object m.\n\nGiven Î², Î£áµ¤, we compute impulse responses to the VAR system\n\nyÌ‚â‚œâ‚Šâ‚ = XÌ‚â‚œâ‚Šâ‚Î² + uâ‚œâ‚Šâ‚,\n\nwhere XÌ‚â‚œâ‚Šâ‚ are the lags of observables in period t + 1, i.e. yâ‚œ, yâ‚œâ‚‹â‚, ..., yâ‚œâ‚‹â‚šâ‚Šâ‚ using one of the available identification methods for VARs\n\nIf the second function is used (where data is not an input), then we assume the user wants to compute the VAR approximation of the DSGE, regardless of the Î» value in m. Note that this function will not update the value of Î» in m (even though we are computing the DSGE-VAR(âˆž) approximation).\n\nInputs\n\nmethod::Symbol: The available methods are :cholesky, :maxBC, and :choleskyLR.   See the docstrings impulse_responses for VARs specifically.\nn_obs_shock::Int: The index of the observable corresponding to the orthogonalized shock   causing the impulse response.\n\nKeyword Arguments\n\nhorizon::Int: the desired horizon of the impulse responses.\nuse_intercept::Bool: use an intercept term for the VAR approximation\nflip_shocks::Bool: default is a \"negative\" impulse response on impact.   Set to true for the positive impulse response.\n\n\n\n\n\nfunction impulse_responses(m::AbstractDSGEVARModel{S}, data::AbstractArray{S},\n                           XÌ‚::Matrix{S} = Matrix{S}(undef, 0, 0);\n                           horizon::Int = 0, MM::Matrix{S} = Matrix{S}(undef, 0, 0),\n                           flip_shocks::Bool = false, draw_shocks::Bool = false,\n                           deviations::Bool = false, normalize_rotation::Bool = false,\n                           verbose::Symbol = :none) where {S <: Real}\n\ncomputes the VAR impulse responses identified by the DSGE\n\nsâ‚œ = TTT Ã— sâ‚œâ‚‹â‚ + RRR Ã— impact[:, i],\nyâ‚œ = ZZ Ã— sâ‚œ + DD + MM Ã— impact[:, i],\n\nwhere impact[:, i] is a linear combination of (orthogonal) structural shocks Ïµâ‚œ âˆ¼ ð’© (0, I), and MM Ã— impact[:, i] are the correlated measurement errors.\n\nThe VAR impulse responses are computed according to\n\nyÌ‚â‚œâ‚Šâ‚ = XÌ‚â‚œâ‚Šâ‚Î² + uâ‚œâ‚Šâ‚,\n\nwhere XÌ‚â‚œâ‚Šâ‚ are the lags of observables in period t + 1, i.e. yâ‚œ, yâ‚œâ‚‹â‚, ..., yâ‚œâ‚‹â‚š. Note these impulse responses are not computed in deviations from the baseline forecast yÌ‚â‚œâ‚Šâ‚ = XÌ‚â‚œâ‚Šâ‚Î². To compute these impulse responses, use the keyword deviations.\n\nThe shock uâ‚œâ‚Šâ‚ is identified by assuming\n\nÎ£áµ¤ = ð”¼[u Ã— u'] = chol(Î£áµ¤) Ã— Î© Ã— Ïµâ‚œ,\n\nwhere the rotation matrix Î© is the Q matrix from a QR decomposition of the impact response matrix corresponding to the state space system, i.e.\n\nÎ©, _ = qr(âˆ‚yâ‚œ / âˆ‚Ïµâ‚œ').\n\nFor reference, see Del Negro and Schorfheide (2004), Del Negro and Schorfheide (2006), and Del Negro and Schorfheide (2009).\n\nInputs\n\nXÌ‚::Matrix{S}: covariates for the first \"forecast\" period   of the impulse response, i.e. if we have a VAR with p lags, then\n\nXÌ‚ = [1, yÌ‚â‚œ, yÌ‚â‚œâ‚‹â‚, ..., yÌ‚â‚œâ‚‹â‚šâ‚Šâ‚]\n\nso that, when Î² is the vector of VAR coefficients, then\n\nð”¼[yÌ‚â‚œâ‚Šâ‚] = kron(I, XÌ‚') * Î².\n\nInternally, we do equivalent matrix operations to avoid allocating the Kronecker product.\n\n\n\nNOTE: this function generally involves taking random draws from probability distributions, so seeds need to be set to achieve reproducibility. ****\n\nKeywords\n\nhorizon::Int: horizon of impulse responses\nflip_shocks::Bool: impulse response shocks are negative by default. Set to true for   a positive signed shock.\ndraw_shocks::Bool: true if you want to draw shocks along the entire horizon\ndeviations::Bool: set true to compute the impulse response in deviations   rather than as a forecast. Mechnically, we ignore XÌ‚ (treated as zeros)   and the intercept term.\nnormalize_rotation::Bool: set to true to normalize the rotation   so that rows have the correct sign. Requires same number of structural shocks   as observables.\nverbose::Symbol: quantity of output desired\n\n\n\n\n\nfunction impulse_responses(TTT::Matrix{S}, RRR::Matrix{S}, ZZ::Matrix{S},\n                           DD::Vector{S}, MM::Matrix{S}, impact::Matrix{S}, horizon::Int;\n                           accumulate::Bool = false,\n                           cum_inds::Union{Int,UnitRange{Int},Vector{Int}} = 0) where {S<:Real}\n\ncomputes the impulse responses of the linear state space system to linear combinations of (orthogonal) structural shocks specified by impact. Measurement error that is correlated with the impact matrix is allowed. We also include the option to accumulate certain observables.\n\nThis state space model takes the form\n\nsâ‚œ = TTT Ã— sâ‚œâ‚‹â‚ + RRR Ã— impact[:, i],\nyâ‚œ = ZZ Ã— sâ‚œ + DD + MM Ã— impact[:, i],\n\nwhere impact[:, i] is a linear combination of orthogonal structural shocks with mean zero and identity covariance, and MM Ã— impact[:, i] are the correlated measurement errors.\n\nThe impact matrix must be nshock Ã— nirf, where nshock is  the number of structural shocks and nirf is the number of desired impulse responses. For each row of impact, we compute the corresponding impulse responses.\n\nA standard choice for impact is a square diagonal matrix. In this case, we compute the impulse response of observables to each structural shock, scaled by the desired size of the shock.\n\nKeywords\n\naccumulate: set to true if an observable should be accumulated.\ncum_inds: specifies the indices of variables to accumulated.\n\nOutputs\n\nirf_results::Matrix{S}: a nobs x horizon Ã— nirf matrix, where    nobs is the number of observables.\n\n\n\n\n\nfunction impulse_responses(TTT::Matrix{S}, RRR::Matrix{S}, ZZ::Matrix{S},\n                           DD::Vector{S}, MM::Matrix{S}, QQ::Matrix{S},\n                           k::Int, Î²::Matrix{S}, Î£::Matrix{S},\n                           horizon::Int, XÌ‚::Matrix{S} = zeros(S, k);\n                           flip_shocks::Bool = false, draw_shocks::Bool = false,\n                           deviations::Bool = false, normalize_rotation::Bool = false,\n                           test_shocks::Matrix{S} =\n                           Matrix{S}(undef, 0, 0)) where {S<:Real}\n\ncomputes the VAR impulse responses identified by the state space system\n\nsâ‚œ = TTT Ã— sâ‚œâ‚‹â‚ + RRR Ã— Ïµâ‚œ\nyâ‚œ = ZZ Ã— sâ‚œ + DD + MM Ã— Ïµâ‚œ\n\nwhere Ïµâ‚œ âˆ¼ ð’© (0, QQ) and MM Ã— Ïµâ‚œ are the correlated measurement errors.\n\nThe VAR impulse responses are computed according to\n\nyÌ‚â‚œâ‚Šâ‚ = XÌ‚â‚œâ‚Šâ‚Î² + uâ‚œâ‚Šâ‚,\n\nwhere XÌ‚â‚œâ‚Šâ‚ are the lags of observables in period t + 1, i.e. yâ‚œ, yâ‚œâ‚‹â‚, ..., yâ‚œâ‚‹â‚š. Note these impulse responses are not computed in deviations from the baseline forecast yÌ‚â‚œâ‚Šâ‚ = XÌ‚â‚œâ‚Šâ‚Î². To compute these impulse responses, set the keyword deviations = true.\n\nThe shock uâ‚œâ‚Šâ‚ is identified via\n\nÎ£áµ¤ = ð”¼[u Ã— u'] = chol(Î£áµ¤) Ã— Î© Ã— Ïµâ‚œ,\n\nwhere the rotation matrix Î© is the Q matrix from a QR decomposition of the impact response matrix corresponding to the state space system, i.e.\n\nÎ©, _ = qr(âˆ‚yâ‚œ / âˆ‚Ïµâ‚œ').\n\nTo normalize the rotation so that rows have the correct sign, set normalize_rotation = true. This requires that there are as many structural shocks as observables.\n\nFor reference, see Del Negro and Schorfheide (2004), Del Negro and Schorfheide (2006), and Del Negro and Schorfheide (2009).\n\n\n\n\n\nfunction impulse_responses(m::AbstractDSGEVECMModel{S}, data::AbstractArray{S},\n                           coint_mat::AbstractMatrix{S}, method::Symbol,\n                           n_obs_shock::Int; horizon::Int = 0,\n                           flip_shocks::Bool = false, verbose::Symbol = :none) where {S <: Real}\n\nfunction impulse_responses(m::AbstractDSGEVECMModel{S}, coint_mat::AbstractMatrix{S}, method::Symbol,\n                           n_obs_shock::Int; horizon::Int = 0, use_intercept::Bool = false,\n                           flip_shocks::Bool = false, verbose::Symbol = :none) where {S <: Real}\n\ncomputes the VECM impulse responses identified by the DSGE\n\nsâ‚œ = TTT Ã— sâ‚œâ‚‹â‚ + RRR Ã— impact[:, i],\nyâ‚œ = ZZ Ã— sâ‚œ + DD + MM Ã— impact[:, i],\n\nwhere impact[:, i] is a linear combination of (orthogonal) structural shocks Ïµâ‚œ âˆ¼ ð’© (0, I), and MM Ã— impact[:, i] are the correlated measurement errors.\n\nWe draw a Î² and Î£áµ¤ from the posterior implied by the DSGE and data, and we then compute normal VECM impulse responses given those coefficients, innovations variance-covariance matrix, and the matrix specifying cointegrating relationships in observables. The weight placed on the DSGE is encoded by the field Î» of the DSGEVECM object m.\n\nGiven Î², Î£áµ¤, we compute impulse responses using one of the available identifiction strategies to the VECM system\n\nÎ”yÌ‚â‚œâ‚Šâ‚ = eâ‚œÎ²â‚‘ + XÌ‚â‚œâ‚Šâ‚Î²áµ¥ + uâ‚œâ‚Šâ‚,\n\nwhere Î²â‚‘ are the coefficients for the error correction terms; eâ‚œâ‚Šâ‚ are the error correction terms specifying the cointegrating relationships; Î²áµ¥ are the coefficients for the VAR terms; XÌ‚â‚œâ‚Šâ‚ are the lags of observables in period t + 1, i.e. yâ‚œ, yâ‚œâ‚‹â‚, ..., yâ‚œâ‚‹â‚š, and uâ‚œâ‚Šâ‚ âˆ¼ ð’© (0, Î£).\n\nIf the second function is used (where data is not an input), then we assume the user wants to compute the VECM approximation of the DSGE, regardless of the Î» value in m. Note that this function will not update the value of Î» in m (even though we are computing the DSGE-VECM(âˆž) approximation).\n\nInputs\n\ncoint_mat::AbstractMatrix{S}: matrix specifying the cointegrating relationships   in observables. Given a matrix data with dimensions n_observables Ã— T,   multiplying coint_mat * data should yield a n_coint Ã— T matrix, where   n_coint is the number of cointegrating relationships and T is   the number of periods of data.\nmethod::Symbol: The available methods are :cholesky, :maxBC, and :choleskyLR.   See the docstrings impulse_responses for VECMs specifically.\nn_obs_shock::Int: The index of the observable corresponding to the orthogonalized shock   causing the impulse response.\n\nKeyword Arguments\n\nhorizon::Int: the desired horizon of the impulse responses.\nuse_intercept::Bool: use an intercept term for the VECM approximation\nflip_shocks::Bool: default is a \"negative\" impulse response on impact.   Set to true for the positive impulse response.\n\n\n\n\n\nfunction impulse_responses(m::AbstractDSGEVECMModel{S}, data::AbstractArray{S},\n    XÌ‚::Matrix{S} = Matrix{S}(undef, 0, 0);\n    horizon::Int = 0, MM::Matrix{S} = Matrix{S}(undef, 0, 0),\n    flip_shocks::Bool = false, draw_shocks::Bool = false,\n    verbose::Symbol = :none) where {S <: Real}\n\ncomputes the VECM impulse responses identified by the DSGE\n\nsâ‚œ = TTT Ã— sâ‚œâ‚‹â‚ + RRR Ã— impact[:, i],\nyâ‚œ = ZZ Ã— sâ‚œ + DD + MM Ã— impact[:, i],\n\nwhere impact[:, i] is a linear combination of (orthogonal) structural shocks Ïµâ‚œ âˆ¼ ð’© (0, I), and MM Ã— impact[:, i] are the correlated measurement errors.\n\nThe VECM impulse responses are computed according to\n\nÎ”yÌ‚â‚œâ‚Šâ‚ = eâ‚œÎ²â‚‘ + XÌ‚â‚œâ‚Šâ‚Î²áµ¥ + uâ‚œâ‚Šâ‚,\n\nwhere Î²â‚‘ are the coefficients for the error correction terms; eâ‚œ are the error correction terms specifying the cointegrating relationships; Î²áµ¥ are the coefficients for the VAR terms; XÌ‚â‚œâ‚Šâ‚ are the lags of observables in period t + 1, i.e. yâ‚œ, yâ‚œâ‚‹â‚, ..., yâ‚œâ‚‹â‚š, and uâ‚œâ‚Šâ‚ âˆ¼ ð’© (0, Î£). Note these impulses responses are not computed in deviations from the baseline forecast Î”yÌ‚â‚œâ‚Šâ‚ = eâ‚œâ‚Šâ‚Î²â‚‘ + XÌ‚â‚œâ‚Šâ‚Î²áµ¥. To compute these impulse responses, use the keyword deviations.\n\nThe shock uâ‚œâ‚Šâ‚ is identified by assuming\n\nÎ£áµ¤ = ð”¼[u Ã— u'] = chol(Î£áµ¤) Ã— Î© Ã— Ïµâ‚œ,\n\nwhere the rotation matrix Î© is the Q matrix from a QR decomposition of the impact response matrix corresponding to the state space system, i.e.\n\nÎ©, _ = qr(âˆ‚yâ‚œ / âˆ‚Ïµâ‚œ').\n\nThe impact response matrix is constructed using only the stationary component of the state space system and ignores the cointegration components of ZZ and DD.\n\nFor reference, see Del Negro and Schorfheide (2004), Del Negro and Schorfheide (2006), and Del Negro and Schorfheide (2009).\n\nInputs\n\ncoint_mat::Matrix{S}: matrix specifying the cointegrating relationships   in the actual data matrix. Evaluating coint_mat * data should yield   a time series of the cointegrating relationships.\nXÌ‚::Matrix{S}: covariates for the first \"forecast\" period   of the impulse response, i.e. if we have a VECM with p lags, then\n\nXÌ‚ = [eâ‚œ, 1, yÌ‚â‚œ, yÌ‚â‚œâ‚‹â‚, ..., yÌ‚â‚œâ‚‹â‚šâ‚Šâ‚]\n\nso that, when Î² is the vector of VECM coefficients, then\n\nð”¼[yÌ‚â‚œâ‚Šâ‚] = kron(I, XÌ‚') * Î².\n\nInternally, we do equivalent matrix operations to avoid allocating the Kronecker product.\n\n\n\nNOTE: this function generally involves taking random draws from probability distributions, so seeds need to be set to achieve reproducibility. ****\n\nKeywords\n\nhorizon::Int: horizon of impulse responses\nflip_shocks::Bool: impulse response shocks are negative by default. Set to true for   a positive signed shock.\ndraw_shocks::Bool: true if you want to draw shocks along the entire horizon\ndeviations::Bool: set true to compute the impulse response in deviations   rather than as a forecast. Mechnically, we ignore XÌ‚ (treated as zeros)   and the intercept term.\nverbose::Symbol: quantity of output desired\n\n\n\n\n\nfunction impulse_responses(TTT::Matrix{S}, RRR::Matrix{S}, ZZ::Matrix{S},\n                           DD::Vector{S}, MM::Matrix{S}, QQ::Matrix{S},\n                           k::Int, n_obs::Int, n_coint::Int, Î²::Matrix{S}, Î£::Matrix{S},\n                           coint_mat::Matrix{S}, horizon::Int, XÌ‚::Matrix{S} = zeros(S, k);\n                           flip_shocks::Bool = false, draw_shocks::Bool = false,\n                           deviations::Bool = false,\n                           test_shocks::Matrix{S} =\n                           Matrix{S}(undef, 0, 0)) where {S<:Real}\n\ncomputes the VECM impulse responses identified by the state space system\n\nsâ‚œ = TTT Ã— sâ‚œâ‚‹â‚ + RRR Ã— Ïµâ‚œ\nyâ‚œ = ZZ Ã— sâ‚œ + DD + MM Ã— Ïµâ‚œ\n\nwhere Ïµâ‚œ âˆ¼ ð’© (0, QQ) and MM Ã— Ïµâ‚œ are the correlated measurement errors.\n\nConsider the VECM\n\nÎ”yÌ‚â‚œâ‚Šâ‚ = eâ‚œÎ²â‚‘ + XÌ‚â‚œâ‚Šâ‚Î²áµ¥ + uâ‚œâ‚Šâ‚,\n\nwhere Î²â‚‘ are the coefficients for the error correction terms; eâ‚œ are the error correction terms specifying the cointegrating relationships; Î²áµ¥ are the coefficients for the VAR terms (including the intecept)o; XÌ‚â‚œâ‚Šâ‚ are the lags of observables in period t + 1, i.e. yâ‚œ, yâ‚œâ‚‹â‚, ..., yâ‚œâ‚‹â‚šâ‚Šâ‚; and uâ‚œâ‚Šâ‚ âˆ¼ ð’© (0, Î£). Note these impulses responses are not computed in deviations from the baseline forecast Î”yÌ‚â‚œâ‚Šâ‚ = eâ‚œâ‚Šâ‚Î²â‚‘ + XÌ‚â‚œâ‚Šâ‚Î²áµ¥. To compute these impulse responses, set the keyword deviations = true.\n\nThe shock uâ‚œâ‚Šâ‚ is identified via\n\nÎ£áµ¤ = ð”¼[u Ã— u'] = chol(Î£áµ¤) Ã— Î© Ã— Ïµâ‚œ,\n\nwhere the rotation matrix Î© is the Q matrix from a QR decomposition of the impact response matrix corresponding to the state space system, i.e.\n\nÎ©, _ = qr(âˆ‚yâ‚œ / âˆ‚Ïµâ‚œ').\n\nThe impact response matrix is constructed using only the stationary component of the state space system and ignores the cointegration components of ZZ and DD.\n\nThe data are assumed to have dimensions n_obs Ã— T, and the cointegration relationships in the data are given by coint_mat * data, where coint_mat has dimensions n_coint Ã— n_obs. The variable k is the number of total regressors in the VECM, including cointegration terms.\n\nFor reference, see Del Negro and Schorfheide (2004), Del Negro and Schorfheide (2006), and Del Negro, Schorfheide, Smets, and Wouters (2007).\n\n\n\n\n\n","category":"function"},{"location":"MatlabToJuliaTransition/#The-DSGE-MATLAB-to-Julia-Transition:-Improvements-and-Challenges-1","page":"MATLAB to Julia Transition: Estimation","title":"The DSGE MATLAB to Julia Transition: Improvements and Challenges","text":"","category":"section"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Zac Cranko, Pearl Li, Spencer Lyon, Erica Moszkowski, Micah Smith, Pablo Winant","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"December 3, 2015","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"The FRBNY DSGE model is a relatively large New Keynesian model augmented with financial frictions and a variety of innovations. Here at the Fed, we use it both for forecasting and policy analysis. Research using this model includes looking at the dynamics of inflation during the great recession, the effects of forward guidance, and much more.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"When we were approached by the folks at QuantEcon about a possible collaboration, we jumped at the idea, as it would give us an opportunity to rework our code in an arguably faster language, redesign it from the ground up, and release it open source for the benefit of the community. A full-fledged package for the FRBNY DSGE model would also provide QuantEcon another opportunity to highlight its contribution to high-performance, quantitative economic modeling. Julia was the language of choice, recommended by the QuantEcon group for its high performance and suitability for this breed of technical computing.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"In this post, weâ€™ll discuss our experiences redesigning our code from the ground up, the resulting performance changes, and the challenges we faced working with such a young language.  We created a suite to assess the performance of our Julia code, relative to our MATLAB code. We focus on both the core functions used in solving and estimating the model, as well as on longer-running routines of greater scope. These tests were conducted on a single core on an IntelÂ® XeonÂ® E5-2697 v2 2.70GHz CPU running GNU/Linux:","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Benchmark times relative to MATLAB (smaller is better)","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Test MATLAB (14a) Julia (0.4.0)\ngensys 1.00 0.17\nsolve 1.00 0.09\nkalman_filter 1.00 0.75\nposterior 1.00 0.26\ncsminwel 1.00 0.33\nhessian 1.00 0.23\nmetropolis_hastings 1.00 0.11","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"We ultimately achieve an increase of speed that reduces running time to 1/10th to 3/4th that of the MATLAB code. The Metropolis-Hastings sampling step is the most time consuming, and hence the relevant one in terms of assessing speed improvement. On the basis of this step, we conclude that DSGE.jl is approximately ten times faster than the MATLAB code.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"How much of this increase is due to native performance adventures of Julia, and how much is simply due to the improvements in design that came from rebuilding this project from the ground up? It is of course difficult to say, and it is important to emphasize that one cannot be sure what portion of the performance increase can be attributed to inherent language features as opposed to design differences. Indeed, our MATLAB code suffers from many inefficiencies due to its long, cumulative development, and support for a plethora of models and features. Meanwhile, these design issues have been largely addressed in our Julia package. To best isolate differences in the languages themselves, we can look at our code to compute the model solution with gensys and apply the Kalman filter with kalman_filter. These two functions have relatively little redesign and optimization as compared to the MATLAB code and provide the most comparable, though still imperfect, measurements of performance. The reduction of 1/5th to 3/4th in computing time, therefore, could be taken as a first estimate of Julia's advantage in this single arena of computation.","category":"page"},{"location":"MatlabToJuliaTransition/#Code-Improvements-1","page":"MATLAB to Julia Transition: Estimation","title":"Code Improvements","text":"","category":"section"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Julia provides versatile language features that allow us to improve our code's performance and clarity in several fundamental ways. First and foremost of these is the highly integrated, robust, and flexible type system that lends itself naturally to our DSGE model. At the center of the DSGE.jl package is the model object. Here, one can store all information associated with the model â€“ including the numerous parameters, priors, states, equilibrium conditions, computational settings, and flags â€“ in one place.  By simply passing the model object as an argument to any function, the function has access to all of the model's fields.  By comparison, our MATLAB code stored all variables directly in the global workspace â€“ an approach that scaled poorly as model specifications become more and more complex. To illustrate just how unwieldy our MATLAB code was, many of our function calls required more than 20 positional arguments, a serious challenge for usage and human-readability:","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"[post_new,like_new,zend_new,ZZ_new,DD_new,QQ_new] = ...\n    feval('objfcnmhdsge',para_new,bounds,YY,YY0,nobs,nlags,nvar,mspec,npara,...\n    trspec,pmean,pstdd,pshape,TTT_new,RRR_new,CCC_new,valid_new,para_mask,...\n    coint,cointadd,cointall,YYcoint0,args_nant_antlags{:});","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"While several of these arguments (e.g., coint) relate to a feature not-implemented in Julia, one can still see the excesses of providing so much information about the model separately in function calls.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"The same code in Julia:","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"post_out = posterior!(m, para_new, data; mh=true)","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Certainly, one could approximate a \"model object\" in MATLAB by using its own object-oriented classes, or by \"bundling\" model attributes into a struct or other data structure.  However, MATLAB classes are both relatively complicated and slower than non-object implementations. And using structs in this way results in copies of all model variables made on every function call.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Indeed, changes like this reduce the number of lines of code in DSGE.jl, a rough proxy for ease of maintenance. We find that the fixed cost of setting up the type system is offset by savings in core programs.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Language Lines of code (hundreds)\nMatlab 63\nJulia 37","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"A type-based approach allows us to take advantage of method dispatch in Julia by defining different model types for different model specifications. As detailed in the README file, changes to the model's equilibrium conditions and measurement equation are referred to as changes in a model's \"specification.\"  In the Julia code, model specifications have a 1:1 correspondence with concrete types.  Where necessary, a single function can have multiple methods defined, that are customized for different model types. For example, the augment_states function augments the model's transition matrices after it has been solved.  We can pass any model object m to augment_states, and Julia ensures that the proper, model-specific method is dispatched:","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"TTT, RRR, CCC = augment_states(m, TTT_gensys, RRR_gensys, CCC_gensys)","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"In our MATLAB code, on the other hand, we would approximate this type of dispatch by using a switch statement over a model identifier variable. For the hundreds of models we have worked with in a development capacity, this led to bloat in our model solution code. In Julia, we encapsulate this behavior within the model definition itself.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"It is easy to see that all model types constructed for use with DSGE.jl are closely related: they will have the same fields, and are passed to the same methods.  If it sounds to you like we have an implicit interface here, youâ€™re right. Rather than implementing each object as a standalone type, we define an abstract type, AbstractModel, to serve as the parent for all model types. Because most of our routines are not model-specific, we need only define them once (with an argument of type AbstractModel) and Julia's dispatch system takes care of the rest. We similarly define model parameters as subtypes of a common abstract type AbstractParameter. This allows us to abstract to one notion of a model parameter, while implementing different kinds of parameters in different ways. We also use parameterized (generic) types to increase the flexibility of model parameters (as well as elsewhere in our codebase):","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"# A parameter contains values of data type `T` and embeds a transformation of\n# type `U`\nabstract Parameter{T,U<:Transform} <: AbstractParameter{T}\n\n# One transformation used is the identity\ntype UnscaledParameter{T,U} <: Parameter{T,U}\n    # ...\nend","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"These functions expect the model object to have certain fields, and for those fields to have certain types. (As an example of Julia's youthful status as a language, discussion continues, as of this writing, on an appropriate manner to explicitly introduce interfaces.)","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"With a clear interface in place, running new model specifications using DSGE.jl is relatively straightforward. (See here for detailed instructions).","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Julia's JIT compilation provides significant performance boosts in some areas. For example, we allow a variable number of anticipated monetary policy shocks, beginning in 2008Q4, that we use to treat the zero lower bound. In our MATLAB code, we suffer some dynamic code generation to implement this feature.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"if exist('nant','var')\n    for i=1:nant\n        eval(strcat('rm_tl',num2str(i),'  = ',num2str(nstates+i)));\n        eval(strcat('rm_tl',num2str(i),'  = ',num2str(nstates+i)));\n    end\nend","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Julia's faster evaluation of such statements reduces this performance hit, as these symbols can be associated with the model object.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"[symbol(\"rm_tl$i\") for i = 1:n_anticipated_shocks(m)]\n# ...\n[symbol(\"rm_shl$i\") for i = 1:n_anticipated_shocks(m)]","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Granted, there may be better solutions to our problem in both languages, but similar situations involving code generation are easily addressed in Julia.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"We have found that a number of Julia features make working with DSGE.jl simply more pleasant and user-friendly than working with our old codebase. Julia's clearly integrated testing infrastructure has made our development workflow significantly more robust. Unicode support means that code can correspond more closely to actual model equations, reducing the headache associated with translating from \"math\" to \"code\".  (Inline Markdown documentation helps in a similar way.) Operator overloading and user-defined syntax make it easy to be much more expressive with our code.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"julia> m[:Î±]                         # Access value of param Î± from model m\njulia> m <= parameter(:Ïµ_p, 10.000)  # Add parameter Ïµ_p to model\njulia> Î“0, Î“1, C, Î¨, Î   = eqcond(m)  # Get equilibrium conditions","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"We have found that Julia's highly integrated, Git-based package manager is an improvement over MATLAB's decentralized FileExchange. As Julia users, we can now pull in high-quality, fully tested, community-supported external packages that can each be installed or updated with a single command.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"julia> Pkg.add(\"QuantEcon\")          # That's it!","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"This reduces the need for users to create their own, likely lower-quality functionality, increasing developer and code performance. (Or the need to fight for the toolbox licenses available to their department.)","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"We acknowledge that our package is far from perfect. Possible improvements to DSGE.jl are many and varied. We may experiment with alternative, modern, numerical routines to improve speed. Ultimately, powerful metaprogramming support would allow user to specify model equations more literally, in mathematical notation. We welcome improvements to the existing code from the community.","category":"page"},{"location":"MatlabToJuliaTransition/#Challenges-1","page":"MATLAB to Julia Transition: Estimation","title":"Challenges","text":"","category":"section"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Converting the FRBNY DSGE model from MATLAB, a mature and well-supported language, to an extremely young language like Julia involved no shortage of challenges. Significant changes to the Julia language itself are introduced in rapid succession, and using DSGE.jl with a new Julia version inevitably floods the userâ€™s screen with deprecation warnings. There is significant difficulty in finding written resources on the language beyond the Julia Manual itself. Google searches frequently return discussions in GitHub Issues, which are unhelpful to elementary users and can be actively misleading at times.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Differences between the behavior of MATLAB and Juliaâ€™s core linear algebra libraries led to many roadblocks in the development of DSGE.jl. Julia uses multithreaded BLAS functions for some linear algebra functions.  Using a different number of threads can change the results of matrix decomposition when the matrix is singular. This indeterminacy caused significant problems for our testing suite, both in comparing output matrices to MATLAB results and in testing for reproducibility among Julia outputs.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"We ran into similar numerical problems while porting the model solution algorithm, gensys. At one point, the generalized Schur (QZ) decomposition is computed, yielding the decompositions A=QSZ' and B=QTZ'. In MATLAB, upper triangular matrices S and T are returned. In Julia, meanwhile, the default behavior is to return a real decomposition with upper Hessenberg (blocked diagonal) matrices S and T. Differing behaviors like this in the two languages might expose a user without deep knowledge of the procedure to errors.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"Finally, dealing with a recently introduced language can make it more difficult for new users to produce performant code.  A typical economist, especially one coming from a MATLAB background, may be unfamiliar with the nature and use of language concepts like type stability, parametric types, and preallocation. Julia's profiler and debugger lack the flexibility of those in MATLAB, and can make it difficult to identify the source of errors or performance bottlenecks. And Julia IDEs, like Juno, while admirable, are not as mature or featured as the MATLAB IDE.","category":"page"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"It is important to note again that similar improvements could have been made to our MATLAB code directly. (As we would be the first ones to admit.) Regardless, the Julia paradigm results in code that is high-quality from the outset.","category":"page"},{"location":"MatlabToJuliaTransition/#Conclusion-1","page":"MATLAB to Julia Transition: Estimation","title":"Conclusion","text":"","category":"section"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"After months of hard work, we are pleased to be able to increase the performance of our model and provide our project for the benefit of the community. For those considering similar projects, we find the benefits of a transition to Julia are significant. One should, however, be realistic about the challenges that will be faced transitioning to a young language.","category":"page"},{"location":"MatlabToJuliaTransition/#Disclaimer-1","page":"MATLAB to Julia Transition: Estimation","title":"Disclaimer","text":"","category":"section"},{"location":"MatlabToJuliaTransition/#","page":"MATLAB to Julia Transition: Estimation","title":"MATLAB to Julia Transition: Estimation","text":"This post reflects the experience of the authors with Julia and MATLAB and does not represent an endorsement by the Federal Reserve Bank of New York or the Federal Reserve System of any particular product or service. The views expressed in this post are those of the authors and do not necessarily reflect the position of the Federal Reserve Bank of New York or the Federal Reserve System. Any errors or omissions are the responsibility of the authors.","category":"page"},{"location":"altpolicy/#altpol-doc-1","page":"Alternative Policies","title":"Alternative Policies","text":"","category":"section"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"CurrentModule = DSGE","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"This section describes forecasting under an alternative monetary policy rule. That is:","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"The state space system is split into two exogenous and unanticipated regimes,","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"the \"historical\" regime and the \"forecast\" regime. The historical policy rule applies during the \"historical\" regime, and the alternative policy rule applies to the \"forecast' regime.","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"Filtering and smoothing is done under the historical monetary policy rule, i.e. the one defined in the eqcond method for the given model.\nForecasts and IRFs are computed under the alternative rule.","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"See Regime-Switching Forecasts for details on how forecasting works when the state space system includes exogenous regime-switching.","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"Alternative policies can be either permanent or temporary. To use alternative policies, the user needs to ensure that the model can be solved with regime-switching (see Regime-Switching).","category":"page"},{"location":"altpolicy/#Procedure-for-Permanent-Alternative-Policies-1","page":"Alternative Policies","title":"Procedure for Permanent Alternative Policies","text":"","category":"section"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"The user defines some instance of the AltPolicy type (described below) and then calls the function setup_permanent_altpol!. Then the function calls made to forecast and compute means and bands remain the same as usual (see Forecasting and Computing Means and Bands).","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"For example, suppose you have defined the functions taylor93_eqcond and taylor93_solve corresponding to Taylor (1993)'s proposed monetary policy rule. Then you can run:","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"m = AnSchorfheide()\nsetup_permanent_altpol!(m, AltPolicy(:taylor93, taylor93_eqcond, taylor93_solve); cond_type = :none)\nforecast_one(m, :mode, :none, [:forecastobs, :forecastpseudo])\ncompute_meansbands(m, :mode, :none, [:forecastobs, :forecastpseudo])","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"Permanent alternative policies utilize some of the same machinery as temporary alternative policies, but they use different algorithms for converting the equilibrium conditions from gensys form to the reduced form transition matrices for a state space system. The function setup_permanent_altpol! performs the setup required to interface with this machinery. The keyword argument cond_type is necessary because when the alternative policy is applied depends on whether the forecast is conditional or not. If a forecast is conditional, it is assumed that the alternative policy does not occur until after the conditional horizon, to maintain the idea that the alternative policy is entirely unanticipated.","category":"page"},{"location":"altpolicy/#tempaltpol-procedure-1","page":"Alternative Policies","title":"Procedure for Temporary Alternative Policies","text":"","category":"section"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"Another counterfactual exercise is temporarily imposing a different monetary policy rule, i.e. a temporary alternative policy, before switching back to either the historical rule or some (permanent) alternative rule. To implement this, we utilize exogenous regime switching in the forecast horizon.","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"In a rational expectations equilibrium, agents will take into account the fact that the temporary policy is expected to terminate. A different algorithm than Chris Sims's standard gensys algorithm is required, which we have implemented as gensys2. Note that this gensys2 is different from the gensys2 Chris Sims has implemented to calculate second-order perturbations.","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"To set up a temporary alternative policy, a user first needs to specify alternative policy using the type AltPolicy. For instance, this code implements a Nominal GDP targeting policy, and the AltPolicy is constructed by calling DSGE.ngdp(), or equivalently","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"AltPolicy(policy, DSGE.ngdp_eqcond, DSGE.ngdp_solve, forecast_init = DSGE.ngdp_forecast_init)","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"where the inputs to AltPolicy here are","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"DSGE.ngdp_eqcond\nDSGE.ngdp_replace_eq_entries\nDSGE.ngdp_solve\nDSGE.ngdp_forecast_init","category":"page"},{"location":"altpolicy/#DSGE.ngdp_eqcond","page":"Alternative Policies","title":"DSGE.ngdp_eqcond","text":"ngdp_eqcond(m::AbstractDSGEModel, reg::Int = 1)\n\nSolves for the transition equation of m under a price level targeting rule (implemented by adding a price-gap state)\n\n\n\n\n\n","category":"function"},{"location":"altpolicy/#DSGE.ngdp_solve","page":"Alternative Policies","title":"DSGE.ngdp_solve","text":"ngdp_solve(m::AbstractDSGEModel)\n\nSolves for the transition equation of m under a price level targeting rule (implemented by adding a price-gap state)\n\n\n\n\n\n","category":"function"},{"location":"altpolicy/#DSGE.ngdp_forecast_init","page":"Alternative Policies","title":"DSGE.ngdp_forecast_init","text":"init_ngdp_forecast(m::AbstractDSGEModel, shocks::Matrix{T}, final_state::Vector{T})\n\nAdjust shocks matrix and final state vector for forecasting under the NGDP rule\n\n\n\n\n\n","category":"function"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"Note that ngdp_replace_eq_entries is called by ngdp_eqcond but is not a direct input to AltPolicy.","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"The user also needs to complete the following steps to apply temporary alternative policies.","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"Adding a regime for every period during which the alternative policy applies, plus one more regime for the policy which will be permanently in place after the temporary policies end.\nAdding the setting Setting(:gensys2, true) to indicate gensys2 should be used. If this setting is false or non-existent, then alternative policies will be treated as if they are permanent. Their equilibrium conditions will be solved using gensys, which can lead to determinacy and uniqueness problems if the alternative policy should be temporary (e.g. a temporary ZLB).\nAdding the setting Setting(:replace_eqcond, true) to indicate equilibrium conditions will be replaced.\nAdding the setting Setting(:regime_eqcond_info, info), where info should be a Dict{Int, DSGE.EqcondEntry} mapping regimes to instances of EqcondEntry, a type which holds any information needed to update equilibrium conditions to implement a given alternative policy. Borrowing the example of temporary NGDP targeting, the relevant EqcondEntry would be constructed as EqcondEntry(DSGE.ngdp()). Note that the user only needs to populate this dictionary with regimes in which the eqcond function differs from the default.","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"To see an example of using temporary alternative policies, see the example script for regime-switching.","category":"page"},{"location":"altpolicy/#[Alternative-Policy-Uncertainty-and-Imperfect-Awareness](@ref-uncertainaltpol)-1","page":"Alternative Policies","title":"Alternative Policy Uncertainty and Imperfect Awareness","text":"","category":"section"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"Click on the section header for details on how to add policy uncertainty or imperfect credibility to alternative policies (both permanent and temporary).","category":"page"},{"location":"altpolicy/#[MultiPeriodAltPolicy](@ref-imperfect-awareness-multiperaltpol)-1","page":"Alternative Policies","title":"MultiPeriodAltPolicy","text":"","category":"section"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"Click on the section header to see the primary use of the type MultiPeriodAltPolicy, which extends AltPolicy to specify multiple regimes. In particular, one of the fields of MultiPeriodAltPolicy is regime_eqcond_info, which stores a dictionary that can be used to update a model's regime_eqcond_info Setting, i.e.","category":"page"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"m <= Setting(:regime_eqcond_info, multi_period_altpol.regime_eqcond_info)","category":"page"},{"location":"altpolicy/#altpol-types-1","page":"Alternative Policies","title":"Types","text":"","category":"section"},{"location":"altpolicy/#","page":"Alternative Policies","title":"Alternative Policies","text":"DSGE.AltPolicy\nDSGE.EqcondEntry\nDSGE.MultiPeriodAltPolicy","category":"page"},{"location":"altpolicy/#DSGE.AltPolicy","page":"Alternative Policies","title":"DSGE.AltPolicy","text":"mutable struct AltPolicy\n\nTypes defining an alternative policy rule.\n\nFields\n\nkey::Symbol: alternative policy identifier\neqcond::Function: a version of DSGE.eqcond which computes the equilibrium condition matrices under the alternative policy. Like DSGE.eqcond, it should take in one argument of mutable struct AbstractDSGEModel and return the Î“0, Î“1, C, Î¨, and Î  matrices.\nsolve::Function: a version of DSGE.solve which solves the model under the alternative policy. Like DSGE.solve, it should take in one argument of mutable struct AbstractDSGEModel and return the TTT, RRR, and CCC matrices.\nforecast_init::Function: a function that initializes forecasts under the alternative policy rule. Specifically, it accepts a model, an nshocks x n_forecast_periods matrix of shocks to be applied in the forecast, and a vector of initial states for the forecast. It must return a new matrix of shocks and a new initial state vector. If no adjustments to shocks or initial state vectors are necessary under the policy rule, this field may be omitted.\ncolor::Colorant: color to plot this alternative policy in. Defaults to blue.\nlinestyle::Symbol: line style for forecast plots under this alternative policy. See options from Plots.jl. Defaults to :solid.\n\n\n\n\n\n","category":"type"},{"location":"altpolicy/#DSGE.EqcondEntry","page":"Alternative Policies","title":"DSGE.EqcondEntry","text":"mutable struct EqcondEntry\n\nType to hold the entries in the regimeeqcondinfo dictionary for alternative policies, regime switching, and imperfect awareness.\n\n\n\n\n\n","category":"type"},{"location":"altpolicy/#DSGE.MultiPeriodAltPolicy","page":"Alternative Policies","title":"DSGE.MultiPeriodAltPolicy","text":"mutable struct MultiPeriodAltPolicy\n\nTypes defining an alternative policy rule.\n\nFields\n\nkey::Symbol: alternative policy identifier\nregime_eqcond_info::AbstractDict{Int64, EqcondEntry}: a dictionary mapping   regimes to equilibrium conditions which replace the default ones in a   given regime.\ngensys2::Bool: if true, the multi-period alternative policy needs   to call gensys2 instead of gensys to work.\ntemporary_altpolicy_names::Union{Vector{Symbol}, Nothing}: specifies   the names of temporary policies which may occur, e.g. [:zero_rate]   if a temporary ZLB is implemented using the zero_rate AltPolicy.\ntemporary_altpolicy_length::Int64: the temporary alternative policy's length   which is used to determine which regimes need to be solved using gensys2   instead of gensys.\ninfoset::Union{Vector{UnitRange{Int64}}, Nothing}: either a vector specifying   the information set used for expectations in the measurement equation or   nothing to indicate myopia in expectations across regimes.\nperfect_credibility_identical_transitions::Union{Dict{Int64, Int64}, Nothing}: if not a Nothing,   then this field specifies regimes which have identical transition equations   in the case of perfect credibility.\nidentical_eqcond_regimes::Union{Dict{Int64, Int64}, Nothing}: if not a Nothing,   then this field specifies regimes which have identical equilibrium conditions.\nforecast_init::Function: a function that initializes forecasts under the alternative policy rule. Specifically, it accepts a model, an nshocks x n_forecast_periods matrix of shocks to be applied in the forecast, and a vector of initial states for the forecast. It must return a new matrix of shocks and a new initial state vector. If no adjustments to shocks or initial state vectors are necessary under the policy rule, this field may be omitted.\ncolor::Colorant: color to plot this alternative policy in. Defaults to blue.\nlinestyle::Symbol: line style for forecast plots under this alternative policy. See options from Plots.jl. Defaults to :solid.\n\n\n\n\n\n","category":"type"},{"location":"input_data/#input-data-step-1","page":"Input Data","title":"Input Data","text":"","category":"section"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"CurrentModule = DSGE","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Given all of the hard work put into specifying the model, one should be able to maintain the input data painlessly. To that extent, DSGE.jl provides facilities to download appropriate vintages of data series from FRED (Federal Reserve Economic Data).","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Note that a sample input dataset for use with model m990 is provided; see New York Fed Model 990 Data for more details. To update this sample dataset for use with model m990, see Update sample input data.","category":"page"},{"location":"input_data/#Setup-1","page":"Input Data","title":"Setup","text":"","category":"section"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"To take advantage of the ability to automatically download data series from FRED via the FredData.jl package, set up your FRED API access by following the directions here.","category":"page"},{"location":"input_data/#Loading-data-1","page":"Input Data","title":"Loading data","text":"","category":"section"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"At the most basic, loading data looks like this:","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"m = Model990()\ndf = load_data(m)","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"By default, load_data will look on the disk first to see if an appropriate vintage of data is already present. If data on disk are not present, or if the data are invalid for any reason, a fresh vintage will be downloaded from FRED and merged with the other data sources specified. See load_data for more details.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"The resulting DataFrame df contains all the required data series for this model, fully transformed. The first row is given by the Setting date_presample_start and the last row is given by date_mainsample_end. The first n_presample_periods rows of df are the presample.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Driver functions including estimate accept this df as an argument and convert it into a Matrix suitable for computations using df_to_matrix, which sorts the data, ensures the full sample is present, discards the date column, and sorts the observable columns according to the observables field of the model object.","category":"page"},{"location":"input_data/#Non-FRED-data-sources-1","page":"Input Data","title":"Non-FRED data sources","text":"","category":"section"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Some data series may not be available from FRED or one may simply wish to use a different data source, for whatever reason. The data sources and series are specified in the input_series field of an Observable object (see ModelConstructors.jl). For each data source that is not :fred, a well-formed CSV of the form <source>_<yymmdd>.csv is expected in the directory indicated by inpath(m, \"raw\").  For example, the following might be the contents of a data source for two series :series1 and :series2:","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"date,series1,series2\n1959-06-30,1.0,NaN\n1959-09-30,1.1,0.5\n# etc.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Note that quarters are represented by the date of the last day of the quarter and missing values are specified by NaN.","category":"page"},{"location":"input_data/#Example-1","page":"Input Data","title":"Example","text":"","category":"section"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Let's consider an example dataset comprised of 10 macro series sourced from FRED and one survey-based series sourced from, say, the Philadelphia Fed's Survey of Professional Forecasters via Haver Analytics. The Observable for that data series might look like this:","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Observable(:obs_longcpi, [:ASAXC10__SPF], annualtoquarter, quartertoannual,\n           \"Median 10Y CPI Expectations\", \"Median 10Y CPI Expectations\")","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"If the data vintage specified for the model is 151127 (Nov. 27, 2015), then the following files are expected in inpath(m, \"raw\"):","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"spf_151127.csv\nfred_151127.csv","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"The FRED series will be downloaded and the fred_151127.csv file will be automatically generated, but the spf_151127.csv file must be manually compiled as shown above:","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"date,ASACX10\n1991-12-31,4.0\n# etc.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Now, suppose that we set the data vintage to 151222, to incorporate the BEA's third estimate of GDP. The fred_151222.csv file will be downloaded, but there are no updates to the SPF dataset during this period. Regardless, the file spf_151222.csv must be present to match the data vintage. The solution in this case is to manually copy and rename the older SPF dataset. Although this is not an elegant approach, it is consistent with the concept of a vintage as the data available at a certain point in time â€“- in this example, it just so happens that the SPF data available on Nov. 27 and Dec. 22 are the same.","category":"page"},{"location":"input_data/#Incorporate-population-forecasts-1","page":"Input Data","title":"Incorporate population forecasts","text":"","category":"section"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Many variables enter the model in per-capita terms. To that extent, we use data on population levels to adjust aggregate variables into per-capita variables. Furthermore, we apply the Hodrick-Prescott filter (\"H-P filter\") to the population levels to smooth cyclical components.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"The user will ultimately want to produce forecasts of key variables such as GDP and then represent these forecasts in standard terms. That is, one wants to report GDP forecasts in aggregate terms, which is standard, rather than per-capita terms. To do this, we either extrapolate from the last periods of population growth in the data, or use external population forecasts.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Note that if external population forecasts are provided, non-forecast procedures, such as model estimation, are also affected because the H-P filter smoothes back from the latest observation.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"To incorporate population forecasts,","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Set the model setting use_population_forecast to true.\nProvide a file population_forecast_<yymmdd>.csv to inpath(m, \"raw\"). Population forecasts should be in levels, and represent the same series as given by the population_mnemonic setting (defaults to :CNP16OV, or \"Civilian Noninstitutional Population, Thousands\"). If your population forecast is in growth rates, convert it to levels yourself. The first row of data should correspond to the last period of the main sample, such that growth rates can be computed. As many additional rows of forecasts as desired can be provided.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"The file should look like this:","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"date,POPULATION\n2015-12-31,250000\n2016-03-31,251000\n# etc.","category":"page"},{"location":"input_data/#Dataset-creation-implementation-details-1","page":"Input Data","title":"Dataset creation implementation details","text":"","category":"section"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Let's quickly walk through the steps DSGE.jl takes to create a suitable dataset.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"First, a user provides a detailed specification of the data series and transformations used for their model.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"the user specifies m.observables; the keys of this dictionary name   the series to be used in estimating the model.\nthe user specifies m.observable_mappings; the keys of this dictionary name observed variables, and the values correspond to the observable object, which contains information about the forward and reverse transforms as well as the input data series from which the observable is constructed.\nFor a given observable, an input series, e.g.   m.observable_mappings[:obs_gdp].input_series, is an array of mnemonics to be   accessed from the data source listed after the mnemonic (separated by the double   underscore). Note that these mnemonics do not correspond to observables one-to-one,   but rather are usually series in levels that will be further transformed.\nThere are also both forward and reverse transforms for a given observable,   e.g. m.observable_mappings[:obs_gdp].fwd_transform and   m.observable_mappings[:obs_gdp].rev_transform. The forward transform operates on a   single argument, levels, which is a DataFrame of the data in levels returned by the   function load_data_levels. The reverse transform operates on a forward transformed   series (which is in model units) transforming it into human-readable units, such   as one quarter percent changes or per-capita adjustments. Both transforms return a   DataArray for a single series. These functions could do nothing, or they could   perform a more complex transformation. See   Data Transforms and Utilities for more information about series-specific   transformations.\nthe user adjusts data-related settings, such as data_vintage, data_id,   dataroot, date_presample_start, date_zlb_start, date_forecast_start,   and use_population_forecast. See Working with Settings for details.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Second, DSGE.jl attempts to construct the dataset given this setup through a call to load_data. See load_data for more details.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Intermediate data in levels are loaded. See load_data_levels for more details.\nTransformations are applied to the data in levels. See transform_data for more details.\nThe data are saved to disk. See save_data for more details.","category":"page"},{"location":"input_data/#Conditional-data-1","page":"Input Data","title":"Conditional data","text":"","category":"section"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"The user can easily add conditional data for any observables. By \"conditional data\", we mean that, in reality, some data has not become available yet, but we believe that a certain number is a decent guess, so we want to forecast conditional on our guessed data. For example, suppose we are in 2019:Q4, in which case we have not observed 2019:Q4 GDP growth yet. However, we might have some idea of the number, so we want our forecasts to be conditional on that guess.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"To load such data, the user needs to include a \"cond\" folder within the input data folder, i.e. this folder joinpath(get_setting(m, :input_data), \"cond\") should exist. Within this folder, the user can create a csv file taking the form cond_cdid=<xx>_cdvt=<yymmdd>.csv. The user should then make sure that the model object being used has the following settings","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"cond_id::Int64: the conditional data's equivalent of data_id and will be inserted after the cdid. Note that the ID must be less than 100.\ncond_vintage::String: the conditional data's equivalent of data_vintage and will be inserted after the cdvt.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"The contents of cond_cdid=<xx>_cdvt=<yymmdd>.csv should have columns for each raw data series that is then used to construct a given conditional observable. The first column should be date for the quarters of the conditional horizon, and the following columns should be for the raw data series. For example, to obtain real GDP growth, we need to have a population forecast file with both CNP16OV and CE16OV, the forecasted value of nominal GDP (under pnemonic GDP), and the forecasted value of the GDP deflator (under pnemonic GDPDEF) since these series are all required to compute obs_gdp, which is per-capita real GDP growth. For core inflation, we just need the index level for core PCE (under pnemonic PCEPILFE).","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Note that the csv should have only conditional horizon data. If you have data for any historical quarters, then the DataFrame with both historical and conditional data will not be created in REPL correctly. For example, if I am forecasting 2019:Q4 with a conditional forecast of 2019:Q4 values, then the data conditional csv should have only values for 2019:Q4 (and onward). No values for 2019:Q3 or before should be in the conditional data csv.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Finally, to specify which variables should have conditional observations, make sure to set","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"cond_full_names::Vector{Symbol}: variables when running a \"full\" conditional forecast. For Model 1002, this means averages of the current quarter's daily financial data as well as nowcasts of real GDP growth and core PCE inflation.\ncond_semi_names::Vector{Symbol}: variables when running a \"semi\" conditional forecast. For Model 1002, this means averages of the current quarter's daily financial data.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"See the default settings for an example of how these cond_full_names and cond_semi_names are initialized.","category":"page"},{"location":"input_data/#Common-pitfalls-1","page":"Input Data","title":"Common pitfalls","text":"","category":"section"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Given the complexity of the data download, you may find that the dataset generated by load_data is not exactly as you expect. It is a good idea to compare the observables.jl file for your model with the one used by Model1002, which uses all the features provided by the package for handling data. Be certain that any significant differences are intentional. Here are also some common pitfalls to look out for:","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Ensure that the data_vintage and cond_vintage model settings are as you expect. (Try checking   data_vintage(m) and cond_vintage(m).)\nEnsure that the data_id and cond_id model settings are correct for the given model.\nEnsure that the date_forecast_start model setting is as you expect, and that is not   logically incompatible with data_vintage.\nEnsure that the date_conditional_end model setting is as you expect, and that is not   logically incompatible with cond_vintage.\nDouble check the transformations specified in the data_transforms field of the model   object.\nEnsure that the keys of the observables and data_transforms fields of the model object   match.\nCheck the input files for Non-FRED data sources. They should be   in the directory indicated by inpath(m, \"raw\"), be named appropriately given the   vintage of data expected, and be formatted appropriately. One may have to copy and   rename files of non-FRED data sources to match the specified vintage, even if the   contents of the files would be identical.\nLook for any immediate issues in the final dataset saved   (data_dsid=<xx>_vint=<yymmdd>.csv). If a data series in this file is all   NaN values, then likely a non-FRED data source was not provided correctly.\nEnsure that the column names of the data CSV match the keys of the observables field of   the model object.\nYou may receive a warning that an input data file \"does not contain the entire date range   specified\". This means that observations are not provided for some periods in which the   model requires data. This is perfectly okay if your data series starts after   date_presample_start.\nIf you successfully created a data set but it is missing observations that you want to add, you may need to recreate the data set. By default, load_data checks if a data set with the correct vintage already exists. If it does, then load_data loads the saved data rather than recreate a data set from scratch. However, if the saved data set is missing observations, then you want to recreate it by calling load_data(m; try_disk = false).\nIf you have a column that is completely empty (all missing/NaN data), but you still want to load the data, then use the keyword check_empty_columns = false.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"If you experience any problems using FredData.jl, ensure your API key is provided correctly and that there are no issues with your firewall, etc. Any issues with FredData.jl proper should be reported on that project's page.","category":"page"},{"location":"input_data/#Update-sample-input-data-1","page":"Input Data","title":"Update sample input data","text":"","category":"section"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"A sample dataset is provided for the 2015 Nov 27 vintage. To update this dataset:","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Step 1. See Setup to setup automatic data pulls using FredData.jl.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Step 2. Specify the exact data vintage desired:","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"julia>  m <= Setting(:data_vintage, \"yymmdd\")","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Step 3. Create data files for the non-FRED data sources. For model m990, the required data files include    spf_<yymmdd>.csv (with column ASACX10), longrate_<yymmdd>.csv (with    column FYCCZA), and fernald_<yymmdd>.csv (with columns TFPJQ and    TFPKQ). To include data on expected interest rates, the file    ois_<yymmdd>.csv is also required. To include data on population forecasts,    the file population_forecst_<yymmdd>.csv is also required (see    Incorporate population forecasts. See    New York Fed Model Input Data for details on the series    used and links to data sources.","category":"page"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Step 4. Run load_data(m); series from FRED will be downloaded and merged with the series from    non-FRED data sources that you have already created. See Common pitfalls for some potential issues.","category":"page"},{"location":"input_data/#Data-Transforms-and-Utilities-1","page":"Input Data","title":"Data Transforms and Utilities","text":"","category":"section"},{"location":"input_data/#","page":"Input Data","title":"Input Data","text":"Modules = [DSGE]\nPages   = [\"load_data.jl\", \"fred_data.jl\", \"transform_data.jl\", \"transformations.jl\", \"src/data/util.jl\"]\nOrder   = [:function, :type]","category":"page"},{"location":"input_data/#DSGE.df_to_matrix-Tuple{Union{AbstractDSGEModel, AbstractVARModel},DataFrames.DataFrame}","page":"Input Data","title":"DSGE.df_to_matrix","text":"df_to_matrix(m, df; cond_type = :none, in_sample = true)\n\nReturn df, converted to matrix of floats, and discard date column. Also ensure that rows are sorted by date and columns by m.observables, with the option to specify whether or not the out of sample rows are discarded. The output of this function is suitable for direct use in estimate, posterior, etc.\n\nKeyword Arguments:\n\ninclude_presample::Bool: indicates whether or not there are presample periods.\nin_sample::Bool: indicates whether or not to discard rows that are out of sample. Set this flag to false in\n\nthe case that you are calling filter_shocks! in the scenarios codebase.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.load_cond_data_levels-Tuple{AbstractDSGEModel}","page":"Input Data","title":"DSGE.load_cond_data_levels","text":"load_cond_data_levels(m::AbstractDSGEModel; verbose::Symbol=:low)\n\nCheck on disk in inpath(m, \"cond\") for a conditional dataset (in levels) of the correct vintage and load it.\n\nThe following series are also loaded from inpath(m, \"raw\") and either appended or merged into the conditional data:\n\nThe last period of (unconditional) data in levels (data_levels_<yymmdd>.csv), used to calculate growth rates\nThe first period of forecasted population (population_forecast_<yymmdd>.csv), used for per-capita calculations\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.load_data-Tuple{AbstractDSGEModel}","page":"Input Data","title":"DSGE.load_data","text":"load_data(m::AbstractDSGEModel; try_disk::Bool = true, verbose::Symbol = :low,\n          check_empty_columns::Bool = true, summary_statistics::Symbol = :low)\n\nCreate a DataFrame with all data series for this model, fully transformed.\n\nFirst, check the disk to see if a valid dataset is already stored in inpath(m, \"data\"). A dataset is valid if every series in m.observable_mappings is present and the entire sample is contained (from date_presample_start to date_mainsample_end. If no valid dataset is already stored, the dataset will be recreated. This check can be eliminated by passing try_disk=false.\n\nIf the dataset is to be recreated, in a preliminary stage, intermediate data series as specified in m.observable_mappings are loaded in levels using load_data_levels. See ?load_data_levels for more details.\n\nThen, the series in levels are transformed as specified in m.observable_mappings. See ?transform_data for more details.\n\nIf m.testing is false, then the resulting DataFrame is saved to disk as data_<yymmdd>.csv. The data are then returned to the caller.\n\nThe keyword check_empty_columns throws an error whenever a column is completely empty in the loaded data set if it is set to true.\n\nThe keyword summary_statistics prints out a variety of summary statistics on the loaded data. When set to :low, we print only the number of missing/NaNs for each data series. When set to :high, we also print means, standard deviations,\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.load_data_levels-Tuple{AbstractDSGEModel}","page":"Input Data","title":"DSGE.load_data_levels","text":"load_data_levels(m::AbstractDSGEModel; verbose::Symbol=:low)\n\nLoad data in levels by appealing to the data sources specified for the model. Data from FRED is loaded first, by default; then, merge other custom data sources.\n\nCheck on disk in inpath(m, \"data\") datasets, of the correct vintage, corresponding to the ones required by the entries in m.observable_mappings. Load the appropriate data series (specified in m.observable_mappings[key].input_series) for each data source.\n\nTo accomodate growth rates and other similar transformations, more rows of data may be downloaded than otherwise specified by the date model settings. (By the end of the process, these rows will have been dropped.)\n\nData from FRED (i.e. the :fred data source) are treated separately. These are downloaded using load_fred_data. See ?load_fred_data for more details.\n\nData from non-FRED data sources are read from disk, verified, and merged.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.parse_data_series-Tuple{AbstractDSGEModel}","page":"Input Data","title":"DSGE.parse_data_series","text":"parse_data_series(m::AbstractDSGEModel)\n\nParse m.observable_mappings for the data sources and mnemonics to read in.\n\nReturns a Dict{Symbol, Vector{Symbol}} mapping sources => mnemonics found in that data file.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.save_data-Tuple{AbstractDSGEModel,DataFrames.DataFrame}","page":"Input Data","title":"DSGE.save_data","text":"save_data(m::AbstractDSGEModel, df::DataFrame; cond_type::Symbol = :none)\n\nSave df to disk as CSV. File is located in inpath(m, \"data\").\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.load_fred_data-Tuple{AbstractDSGEModel}","page":"Input Data","title":"DSGE.load_fred_data","text":"load_fred_data(m::AbstractDSGEModel; start_date=\"1959-03-31\", end_date=prev_quarter())\n\nChecks in inpath(m, raw) for a FRED dataset corresponding to data_vintage(m). If a FRED vintage exists on disk, any required FRED series that is contained therein will be imported. All missing series will be downloaded directly from FRED using the FredData package. The full dataset is written to the appropriate data vintage file and returned.\n\nArguments\n\nm::AbstractDSGEModel: the model object\nstart_date: starting date.\nend_date: ending date.\n\nNotes\n\nThe FRED API reports observations according to the quarter-start date. load_fred_data returns data indexed by quarter-end date for compatibility with other datasets.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.transform_data-Tuple{AbstractDSGEModel,DataFrames.DataFrame}","page":"Input Data","title":"DSGE.transform_data","text":"transform_data(m::AbstractDSGEModel, levels::DataFrame; cond_type::Symbol = :none,\n    verbose::Symbol = :low)\n\nTransform data loaded in levels and order columns appropriately for the DSGE model. Returns DataFrame of transformed data.\n\nThe DataFrame levels is output from load_data_levels. The series in levels are transformed as specified in m.observable_mappings.\n\nTo prepare for per-capita transformations, population data are filtered using hpfilter. The series in levels to use as the population series is given by the population_mnemonic setting. If use_population_forecast(m), a population forecast is appended to the recorded population levels before the filtering. Both filtered and unfiltered population levels and growth rates are added to the levels data frame.\nThe transformations are applied for each series using the levels DataFrame as input.\n\nConditional data (identified by cond_type in [:semi, :full]) are handled slightly differently: If use_population_forecast(m), we drop the first period of the population forecast because we treat the first forecast period date_forecast_start(m) as if it were data. We also only apply transformations for the observables given in cond_full_names(m) or cond_semi_names(m).\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.annualtoquarter-Tuple{Any}","page":"Input Data","title":"DSGE.annualtoquarter","text":"annualtoquarter(v)\n\nConvert from annual to quarter frequency... by dividing by 4.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.difflog-Tuple{AbstractArray{T,1} where T}","page":"Input Data","title":"DSGE.difflog","text":"difflog(x::AbstractVector)\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.difflog-Tuple{AbstractArray}","page":"Input Data","title":"DSGE.difflog","text":"difflog(x::AbstractArray{AbstractFloat})\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.hpfilter-Tuple{AbstractArray{T,1} where T,Real}","page":"Input Data","title":"DSGE.hpfilter","text":"yt, yf = hpfilter(y, Î»)\n\nApplies the Hodrick-Prescott filter (\"H-P filter\"). The smoothing parameter Î» is applied to the columns of y, returning the trend component yt and the cyclical component yf. For quarterly data, one can use Î»=1600.\n\nConsecutive missing values at the beginning or end of the time series are excluded from the filtering. If there are missing values within the series, the filtered values are all missing.\n\nSee also:\n\nHodrick, Robert; Prescott, Edward C. (1997). \"Postwar U.S. Business Cycles: An Empirical\nInvestigation\". Journal of Money, Credit, and Banking 29 (1): 1â€“16.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.loggrowthtopct-Tuple{AbstractArray}","page":"Input Data","title":"DSGE.loggrowthtopct","text":"loggrowthtopct(y)\n\nTransform from annualized quarter-over-quarter log growth rates to annualized quarter-over-quarter percent change.\n\nNote\n\nThis should only be used in Model 510, which has the core PCE inflation observable in annualized log growth rates.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.loggrowthtopct_4q_approx","page":"Input Data","title":"DSGE.loggrowthtopct_4q_approx","text":"loggrowthtopct_4q_approx(y, data = fill(NaN, 3))\n\nTransform from log growth rates to approximate 4-quarter percent change.\n\nThis method should only be used to transform scenarios forecasts, which are in   deviations from baseline.\n\nInputs\n\ny: the data we wish to transform to aggregate 4-quarter percent change from log per-capita growth rates. y is either a vector of length nperiods or an ndraws xnperiods` matrix.\ndata: if y = [y_t, y_{t+1}, ..., y_{t+nperiods-1}], then data = [y_{t-3}, y_{t-2}, y_{t-1}]. This is necessary to compute 4-quarter percent changes for the first three periods.\n\n\n\n\n\n","category":"function"},{"location":"input_data/#DSGE.loggrowthtopct_annualized-Tuple{AbstractArray}","page":"Input Data","title":"DSGE.loggrowthtopct_annualized","text":"loggrowthtopct_annualized(y)\n\nTransform from log growth rates to annualized quarter-over-quarter percent change.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.loggrowthtopct_annualized_percapita-Tuple{AbstractArray,AbstractArray{T,1} where T}","page":"Input Data","title":"DSGE.loggrowthtopct_annualized_percapita","text":"loggrowthtopct_annualized_percapita(y, pop_growth)\n\nTransform from log per-capita growth rates to annualized aggregate (not per-capita) quarter-over-quarter percent change.\n\nNote\n\nThis should only be used for output, consumption, investment and GDP deflator (inflation).\n\nInputs\n\ny: the data we wish to transform to annualized percent change from quarter-over-quarter log growth rates. y is either a vector of length nperiods or an ndraws xnperiods` matrix.\npop_growth::Vector: the length nperiods vector of log population growth rates.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.loggrowthtopct_percapita-Tuple{AbstractArray,AbstractArray{T,1} where T}","page":"Input Data","title":"DSGE.loggrowthtopct_percapita","text":"loggrowthtopct_percapita(y, pop_growth)\n\nTransform from annualized quarter-over-quarter log per-capita growth rates to annualized quarter-over-quarter aggregate percent change.\n\nNote\n\nThis should only be used in Model 510, which has the output growth observable in annualized log per-capita growth rates.\n\nInputs\n\ny: the data we wish to transform to annualized percent change from annualized log growth rates. y is either a vector of length nperiods or an ndraws xnperiods` matrix.\npop_growth::Vector: the length nperiods vector of log population growth rates.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.logleveltopct_4q_approx","page":"Input Data","title":"DSGE.logleveltopct_4q_approx","text":"logleveltopct_4q_approx(y, data = fill(NaN, 4))\n\nTransform from log levels to approximate 4-quarter percent change.\n\nThis method should only be used to transform scenarios forecasts, which are in   deviations from baseline.\n\nInputs\n\ny: the data we wish to transform to 4-quarter percent change from log levels. y is either a vector of length nperiods or an ndraws xnperiods` matrix.\ndata: if y = [y_t, y_{t+1}, ..., y_{t+nperiods-1}], then data = [y_{t-4}, y_{t-3}, y_{t-2}, y_{t-1}]. This is necessary to compute 4-quarter percent changes for the first three periods.\n\n\n\n\n\n","category":"function"},{"location":"input_data/#DSGE.logleveltopct_annualized","page":"Input Data","title":"DSGE.logleveltopct_annualized","text":"logleveltopct_annualized(y, y0 = NaN)\n\nTransform from log levels to annualized quarter-over-quarter percent change.\n\nInputs\n\ny: the data we wish to transform to annualized quarter-over-quarter percent change from log levels. y is either a vector of length nperiods or an ndraws xnperiods` matrix.\ny0: the last data point in the history (of state or observable) corresponding to the y variable. This is required to compute a percent change for the first period.\n\n\n\n\n\n","category":"function"},{"location":"input_data/#DSGE.logleveltopct_annualized_approx","page":"Input Data","title":"DSGE.logleveltopct_annualized_approx","text":"logleveltopct_annualized_approx(y, y0 = NaN)\n\nTransform from log levels to approximate annualized quarter-over-quarter percent change.\n\nThis method should only be used to transform scenarios forecasts, which are in   deviations from baseline.\n\nInputs\n\ny: the data we wish to transform to annualized quarter-over-quarter percent change from log levels. y is either a vector of length nperiods or an ndraws xnperiods` matrix.\ny0: the last data point in the history (of state or observable) corresponding to the y variable. This is required to compute a percent change for the first period.\n\n\n\n\n\n","category":"function"},{"location":"input_data/#DSGE.logleveltopct_annualized_percapita","page":"Input Data","title":"DSGE.logleveltopct_annualized_percapita","text":"logleveltopct_annualized_percapita(y, pop_growth, y0 = NaN)\n\nTransform from per-capita log levels to annualized aggregate (not per-capita) quarter-over-quarter percent change.\n\nNote\n\nThis is usually applied to labor supply (hours worked per hour), and probably shouldn't be used for any other observables.\n\nInputs\n\ny: the data we wish to transform to annualized aggregate quarter-over-quarter percent change from per-capita log levels. y is either a vector of length nperiods or an ndraws xnperiods` matrix.\npop_growth::Vector: the length nperiods vector of log population growth rates.\ny0: The last data point in the history (of state or observable) corresponding to the y variable. This is required to compute a percent change for the first period.\n\n\n\n\n\n","category":"function"},{"location":"input_data/#DSGE.nominal_to_real-Tuple{Symbol,DataFrames.DataFrame}","page":"Input Data","title":"DSGE.nominal_to_real","text":"nominal_to_real(col, df; deflator_mnemonic = :GDPDEF)\n\nConverts nominal to real values using the specified deflator.\n\nArguments\n\ncol: Symbol indicating which column of df to transform\ndf: DataFrame containining series for proper population measure and col\n\nKeyword arguments\n\ndeflator_mnemonic: indicates which deflator to use to calculate real values. Default value is the FRED GDP Deflator mnemonic.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.oneqtrpctchange-Tuple{AbstractArray{T,1} where T}","page":"Input Data","title":"DSGE.oneqtrpctchange","text":"oneqtrpctchange(y)\n\nCalculates the quarter-to-quarter percentage change of a series.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.percapita-Tuple{AbstractDSGEModel,Symbol,DataFrames.DataFrame}","page":"Input Data","title":"DSGE.percapita","text":"percapita(m, col, df)\npercapita(col, df, population_mnemonic)\n\nConverts data column col of DataFrame df to a per-capita value.\n\nThe first method checks hpfilter_population(m). If true, then it divides by the filtered population series. Otherwise it divides by the result of parse_population_mnemonic(m)[1].\n\nArguments\n\ncol: Symbol indicating which column of data to transform\ndf: DataFrame containining series for proper population measure and col\npopulation_mnemonic: a mnemonic found in df for some population measure\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.quartertoannual-Tuple{Any}","page":"Input Data","title":"DSGE.quartertoannual","text":"quartertoannual(v)\n\nConvert from quarter to annual frequency... by multiplying by 4.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.quartertoannualpercent-Tuple{Any}","page":"Input Data","title":"DSGE.quartertoannualpercent","text":"quartertoannualpercent(v)\n\nConvert from quarter to annual frequency in percent... by multiplying by 400.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.get_data_filename-Tuple{AbstractDSGEModel,Symbol}","page":"Input Data","title":"DSGE.get_data_filename","text":"get_data_filename(m, cond_type)\n\nReturns the data file for m, which depends on data_vintage(m), and if cond_type in [:semi, :full], also on cond_vintage(m) and cond_id(m).\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.iterate_quarters-Tuple{Dates.Date,Int64}","page":"Input Data","title":"DSGE.iterate_quarters","text":"iterate_quarters(start::Date, quarters::Int)\n\nReturns the date corresponding to start + quarters quarters.\n\nInputs\n\nstart: starting date\nquarters: number of quarters to iterate forward or backward\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.quartertodate-Tuple{String}","page":"Input Data","title":"DSGE.quartertodate","text":"quartertodate(string::String)\n\nConvert string in the form \"YYqX\", \"YYYYqX\", or \"YYYY-qX\" to a Date of the end of the indicated quarter. \"X\" is in {1,2,3,4} and the case of \"q\" is ignored.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.subtract_quarters-Tuple{Dates.Date,Dates.Date}","page":"Input Data","title":"DSGE.subtract_quarters","text":"subtract_quarters(t1::Date, t0::Date)\n\nCompute the number of quarters between t1 and t0, including t0 and excluding t1.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.data_to_df-Union{Tuple{T}, Tuple{AbstractDSGEModel,Array{T,2},Dates.Date}} where T<:AbstractFloat","page":"Input Data","title":"DSGE.data_to_df","text":"data_to_df(m, data, start_date)\n\nCreate a DataFrame out of the matrix data, including a :date column beginning in start_date.  Variable names and indices are obtained from m.observables.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.has_saved_data-Tuple{AbstractDSGEModel}","page":"Input Data","title":"DSGE.has_saved_data","text":"has_saved_data(m::AbstractDSGEModel; cond_type::Symbol = :none)\n\nDetermine if there is a saved dataset on disk for the required vintage and conditional type.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.isvalid_data-Tuple{AbstractDSGEModel,DataFrames.DataFrame}","page":"Input Data","title":"DSGE.isvalid_data","text":"isvalid_data(m::AbstractDSGEModel, df::DataFrame; cond_type::Symbol = :none,\n    check_empty_columns::Bool = true)\n\nReturn if dataset is valid for this model, ensuring that all observables are contained and that all quarters between the beginning of the presample and the end of the mainsample are contained. Also checks to make sure that expected interest rate data is available if n_mon_anticipated_shocks(m) > 0.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.read_data-Tuple{AbstractDSGEModel}","page":"Input Data","title":"DSGE.read_data","text":"read_data(m::AbstractDSGEModel; cond_type::Symbol = :none)\n\nRead CSV from disk as DataFrame. File is located in inpath(m, \"data\").\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.read_population_data-Tuple{AbstractDSGEModel}","page":"Input Data","title":"DSGE.read_population_data","text":"read_population_data(m; verbose = :low)\n\nread_population_data(filename; verbose = :low)\n\nRead in population data stored in levels, either from inpath(m, \"raw\", \"population_data_levels_[vint].csv\") or filename.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.read_population_forecast-Tuple{AbstractDSGEModel}","page":"Input Data","title":"DSGE.read_population_forecast","text":"read_population_forecast(m; verbose = :low)\n\nread_population_forecast(filename, population_mnemonic, last_recorded_date; verbose = :low)\n\nRead in population forecast in levels, either from inpath(m, \"raw\", \"population_forecast_[vint].csv\") or filename. If that file does not exist, return an empty DataFrame.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.transform_population_data-Tuple{DataFrames.DataFrame,DataFrames.DataFrame,Symbol}","page":"Input Data","title":"DSGE.transform_population_data","text":"transform_population_data(population_data, population_forecast,\n    population_mnemonic; verbose = :low)\n\nLoad, HP-filter, and compute growth rates from population data in levels. Optionally do the same for forecasts.\n\nInputs\n\npopulation_data: pre-loaded DataFrame of historical population data containing the columns :date and population_mnemonic. Assumes this is sorted by date.\npopulation_forecast: pre-loaded DataFrame of population forecast containing the columns :date and population_mnemonic\npopulation_mnemonic: column name for population series in population_data and population_forecast\n\nKeyword Arguments\n\nverbose: one of :none, :low, or :high\nuse_hpfilter: whether to HP filter population data and forecast. See Output below.\npad_forecast_start::Bool: Whether you want to re-size\n\nthe populationforecast such that the first index is one quarter ahead of the last index of populationdata. Only set to false if you have manually constructed population_forecast to artificially start a quarter earlier, so as to avoid having an unnecessary missing first entry.\n\nOutput\n\nTwo dictionaries containing the following keys:\n\npopulation_data_out:\n:filtered_population_recorded: HP-filtered historical population series (levels)\n:dlfiltered_population_recorded: HP-filtered historical population series (growth rates)\n:dlpopulation_recorded: Non-filtered historical population series (growth rates)\npopulation_forecast_out:\n:filtered_population_forecast: HP-filtered population forecast series (levels)\n:dlfiltered_population_forecast: HP-filtered population forecast series (growth rates)\n:dlpopulation_forecast: Non-filtered historical population series (growth rates)\n\nIf population_forecast_file is not provided, the r\"forecast\" fields will be empty. If use_hpfilter = false, then the r\"filtered*\" fields will be empty.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.get_irf_transform-Tuple{Function}","page":"Input Data","title":"DSGE.get_irf_transform","text":"get_irf_transform(transform::Function)\n\nReturns the IRF-specific transformation, which doesn't add back population growth (since IRFs are given in deviations).\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.get_nopop_transform-Tuple{Function}","page":"Input Data","title":"DSGE.get_nopop_transform","text":"get_nopop_transform(transform::Function)\n\nReturns the corresponding transformation which doesn't add back population growth. Used for shock decompositions, deterministic trends, and IRFs, which are given in deviations.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.get_scenario_transform-Tuple{Function}","page":"Input Data","title":"DSGE.get_scenario_transform","text":"get_scenario_transform(transform::Function)\n\nGiven a transformation used for usual forecasting, return the transformation used for scenarios, which are forecasted in deviations from baseline.\n\nThe 1Q deviation from baseline should really be calculated by 1Q transforming the forecasts (in levels) under the baseline (call this y_b) and alternative scenario (y_s), then subtracting baseline from alternative scenario (since most of our 1Q transformations are nonlinear). Let y_d = y_s - y_b. Then, for example, the most correct loggrowthtopct_annualized transformation is:\n\ny_b_1q = 100*(exp(y_b/100)^4 - 1)\ny_s_1q = 100*(exp(y_s/100)^4 - 1)\ny_d_1q = y_b_1q - y_s_1q\n\nInstead, we approximate this by transforming the deviation directly:\n\ny_d_1q â‰ˆ 4*(y_b - y_s)\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.get_transform4q-Tuple{Function}","page":"Input Data","title":"DSGE.get_transform4q","text":"get_transform4q(transform::Function)\n\nReturns the 4-quarter transformation associated with the annualizing transformation.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.lag-Tuple{AbstractArray,Int64}","page":"Input Data","title":"DSGE.lag","text":"series_lag_n = lag(series, n)\n\nReturns a particular data series lagged by n periods\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.loggrowthtopct_4q","page":"Input Data","title":"DSGE.loggrowthtopct_4q","text":"loggrowthtopct_4q(y, data = fill(NaN, 3))\n\nTransform from log growth rates to 4-quarter percent change.\n\nInputs\n\ny: the data we wish to transform to aggregate 4-quarter percent change from log per-capita growth rates. y is either a vector of length nperiods or an ndraws xnperiods` matrix.\ndata: if y = [y_t, y_{t+1}, ..., y_{t+nperiods-1}], then data = [y_{t-3}, y_{t-2}, y_{t-1}]. This is necessary to compute 4-quarter percent changes for the first three periods.\n\n\n\n\n\n","category":"function"},{"location":"input_data/#DSGE.loggrowthtopct_4q_percapita","page":"Input Data","title":"DSGE.loggrowthtopct_4q_percapita","text":"loggrowthtopct_4q_percapita(y, pop_growth, data = fill(NaN, 3))\n\nTransform from log per-capita growth rates to aggregate 4-quarter percent change.\n\nNote\n\nThis should only be used for output, consumption, investment, and GDP deflator (inflation).\n\nInputs\n\ny: the data we wish to transform to aggregate 4-quarter percent change from log per-capita growth rates. y is either a vector of length nperiods or an ndraws xnperiods` matrix.\npop_growth::Vector: the length nperiods vector of log population growth rates.\ndata: if y = [y_t, y_{t+1}, ..., y_{t+nperiods-1}], then data = [y_{t-3}, y_{t-2}, y_{t-1}]. This is necessary to compute 4-quarter percent changes for the first three periods.\n\n\n\n\n\n","category":"function"},{"location":"input_data/#DSGE.logleveltopct_4q","page":"Input Data","title":"DSGE.logleveltopct_4q","text":"logleveltopct_4q(y, data = fill(NaN, 4))\n\nTransform from log levels to 4-quarter percent change.\n\nInputs\n\ny: the data we wish to transform to 4-quarter percent change from log levels. y is either a vector of length nperiods or an ndraws xnperiods` matrix.\ndata: if y = [y_t, y_{t+1}, ..., y_{t+nperiods-1}], then data = [y_{t-4}, y_{t-3}, y_{t-2}, y_{t-1}]. This is necessary to compute 4-quarter percent changes for the first three periods.\n\n\n\n\n\n","category":"function"},{"location":"input_data/#DSGE.logleveltopct_4q_percapita","page":"Input Data","title":"DSGE.logleveltopct_4q_percapita","text":"logleveltopct_4q_percapita(y, pop_growth, data = fill(NaN, 4))\n\nTransform from per-capita log levels to 4-quarter aggregate percent change.\n\nNote\n\nThis is usually applied to labor supply (hours worked), and probably shouldn't be used for any other observables.\n\nInputs\n\ny: the data we wish to transform to 4-quarter aggregate percent change from per-capita log levels. y is either a vector of length nperiods or an ndraws xnperiods` matrix.\npop_growth::Vector: the length nperiods vector of log population growth rates.\ndata: if y = [y_t, y_{t+1}, ..., y_{t+nperiods-1}], then data = [y_{t-4}, y_{t-3}, y_{t-2}, y_{t-1}]. This is necessary to compute 4-quarter percent changes for the first three periods.\n\n\n\n\n\n","category":"function"},{"location":"input_data/#DSGE.prepend_data-Tuple{AbstractArray,AbstractArray{T,1} where T}","page":"Input Data","title":"DSGE.prepend_data","text":"prepend_data(y, data)\n\nPrepends data necessary for running 4q transformations.\n\nInputs:\n\ny: ndraws x t array representing a timeseries for variable y\ndata: vector representing a timeseries to prepend to y\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.datetoquarter-Tuple{Dates.Date}","page":"Input Data","title":"DSGE.datetoquarter","text":"datetoquarter(date::Date)\n\nConvert string in the form \"YYqX\", \"YYYYqX\", or \"YYYY-qX\" to a Date of the end of the indicated quarter. \"X\" is in {1,2,3,4} and the case of \"q\" is ignored.\n\nReturn an integer from the set {1,2,3,4}, corresponding to one of the quarters in a year given a Date object.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.datetoymdvec-Tuple{Dates.Date}","page":"Input Data","title":"DSGE.datetoymdvec","text":"datetoymdvec(dt)\n\nconverts a Date to a vector/matrix holding the year, month, and date.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.format_dates!-Tuple{Symbol,DataFrames.DataFrame}","page":"Input Data","title":"DSGE.format_dates!","text":"format_dates!(col, df)\n\nChange column col of dates in df from String to Date, and map any dates given in the interior of a quarter to the last day of the quarter.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.get_quarter_ends-Tuple{Dates.Date,Dates.Date}","page":"Input Data","title":"DSGE.get_quarter_ends","text":"get_quarter_ends(start_date::Date,end_date::Date)\n\nReturns an Array of quarter end dates between start_date and end_date.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.missing2nan-Tuple{Array}","page":"Input Data","title":"DSGE.missing2nan","text":"missing2nan(a::Array)\n\nConvert all elements of Union{X, Missing.Missing} or Missing.Missing to type Float64.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.missing_cond_vars!-Tuple{AbstractDSGEModel,DataFrames.DataFrame}","page":"Input Data","title":"DSGE.missing_cond_vars!","text":"missing_cond_vars!(m, df; cond_type = :none, check_empty_columns = true)\n\nMake conditional period variables not in cond_semi_names(m) or cond_full_names(m) missing if necessary.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.na2nan!-Tuple{Array}","page":"Input Data","title":"DSGE.na2nan!","text":"na2nan!(df::Array)\n\nConvert all NAs in an Array to NaNs.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.na2nan!-Tuple{DataFrames.DataFrame}","page":"Input Data","title":"DSGE.na2nan!","text":"na2nan!(df::DataFrame)\n\nConvert all NAs in a DataFrame to NaNs.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.next_quarter","page":"Input Data","title":"DSGE.next_quarter","text":"next_quarter(q::TimeType = now())\n\nReturns Date identifying last day of the next quarter\n\n\n\n\n\n","category":"function"},{"location":"input_data/#DSGE.prev_quarter","page":"Input Data","title":"DSGE.prev_quarter","text":"prev_quarter(q::TimeType = now())\n\nReturns Date identifying last day of the previous quarter\n\n\n\n\n\n","category":"function"},{"location":"input_data/#DSGE.quartertofloats-Tuple{Dates.Date}","page":"Input Data","title":"DSGE.quartertofloats","text":"quartertofloats(dt)\n\nconverts a Date to a floating point number based on the quarter\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.reconcile_column_names-Tuple{DataFrames.DataFrame,DataFrames.DataFrame}","page":"Input Data","title":"DSGE.reconcile_column_names","text":"reconcile_column_names(a::DataFrame, b::DataFrame)\n\nadds columns of missings to a and b so that both have the same set of column names.\n\n\n\n\n\n","category":"method"},{"location":"input_data/#DSGE.vinttodate-Tuple{String}","page":"Input Data","title":"DSGE.vinttodate","text":"function vinttodate(vint)\n\nReturn the string given by data_vintage(m), which is in the format YYYYMMDD, to a Date object.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#Standard-Algorithms-1","page":"Algorithms","title":"Standard Algorithms","text":"","category":"section"},{"location":"algorithms/#","page":"Algorithms","title":"Algorithms","text":"CurrentModule = DSGE","category":"page"},{"location":"algorithms/#Solving-the-Model-1","page":"Algorithms","title":"Solving the Model","text":"","category":"section"},{"location":"algorithms/#","page":"Algorithms","title":"Algorithms","text":"gensys\ngensys2","category":"page"},{"location":"algorithms/#DSGE.gensys","page":"Algorithms","title":"DSGE.gensys","text":"gensys(Î“0, Î“1, c, Î¨, Î )\ngensys(Î“0, Î“1, c, Î¨, Î , div)\ngensys(F::LinearAlgebra.GeneralizedSchur, c, Î¨, Î )\ngensys(F::LinearAlgebra.GeneralizedSchur, c, Î¨, Î , div)\n\nGenerate state-space solution to canonical-form DSGE model.\n\nSystem given as\n\nÎ“0*y(t) = Î“1*y(t-1) + c + Î¨*z(t) + Î *Î·(t),\n\nwith z an exogenous variable process and Î· being endogenously determined one-step-ahead expectational errors.\n\nReturned system is\n\ny(t) = G1*y(t-1) + C + impact*z(t) + ywt*inv(I-fmat*inv(L))*fwt*z(t+1)\n\nReturned values are\n\nG1, C, impact, fmat, fwt, ywt, gev, eu, loose\n\nIf z(t) is i.i.d., the last term drops out.\n\nIf div is omitted from argument list, a div>1 is calculated.\n\nReturn codes\n\neu[1] = 1 for existence\neu[2] = 1 for uniqueness\neu[1] = -1 for existence only with not-s.c. z\neu = [-2, -2] for coincident zeros\neu = [-3, -3] if a LAPACKException is thrown while computing the Schur decomposition\n\nNotes\n\nWe constrain Julia to use the complex version of the schurfact routine regardless of the types of Î“0 and Î“1, to match the behavior of Matlab.  Matlab always uses the complex version of the Schur decomposition, even if the inputs are real numbers.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#DSGE.gensys2","page":"Algorithms","title":"DSGE.gensys2","text":"gensys2(m::AbstractDSGEModel, Î“0::Matrix{Float64}, Î“1::Matrix{Float64}, C::Vector{Float64},\n        Î¨::Matrix{Float64}, Î ::Matrix{Float64}, TTT::Matrix{Float64}, RRR::Matrix{Float64},\n        CCC::Vector{Float64}, T_switch::Int)\n\ncalculates the state space transition matrices when a temporary alternative policy applies. This function is not the same as the gensys2 written by Chris Sims, which computes a second-order perturbation.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#algs-optimization-1","page":"Algorithms","title":"Optimization","text":"","category":"section"},{"location":"algorithms/#","page":"Algorithms","title":"Algorithms","text":"csminwel\noptimize!","category":"page"},{"location":"algorithms/#DSGE.csminwel","page":"Algorithms","title":"DSGE.csminwel","text":"csminwel(fcn::Function, grad::Function, x0::Vector, H0::Matrix=1e-5.*eye(length(x0)), args...;\n         xtol::Real=1e-32, ftol::Float64=1e-14, grtol::Real=1e-8, iterations::Int=1000,\n         store_trace::Bool = false, show_trace::Bool = false, extended_trace::Bool = false,\n         verbose::Symbol = :none, rng::AbstractRNG = MersenneTwister(0), kwargs...)\n\nMinimizes fcn using the csminwel algorithm.\n\nArguments\n\nfcn::Function : The objective function\ngrad::Function : The gradient of the objective function. This argument can be omitted if\n\nan analytical gradient is not available, which will cause a numerical gradient to be calculated.\n\nx0::Vector: The starting guess for the optimizer\n\nOptional Arguments\n\nH0::Matrix: An initial guess for the Hessian matrix â€“ must be\n\npositive definite. If none is given, then a scaled down identity matrix is used.\n\nargs...:  Other positional arguments to be passed to f on each\n\nfunction call\n\nKeyword Arguments\n\nftol::{T<:Real}=1e-14: Threshold for convergence in terms of change\n\nin function value across iterations.\n\niterations::Int=100: Maximum number of iterations\nkwargs...: Other keyword arguments to be passed to f on each\n\nfunction call\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#DSGE.optimize!","page":"Algorithms","title":"DSGE.optimize!","text":"optimize!(m::Union{AbstractDSGEModel,AbstractVARModel}, data::Matrix;\n          method::Symbol       = :csminwel,\n          xtol::Real           = 1e-32,  # default from Optim.jl\n          ftol::Float64        = 1e-14,  # Default from csminwel\n          grtol::Real          = 1e-8,   # default from Optim.jl\n          iterations::Int      = 1000,\n          store_trace::Bool    = false,\n          show_trace::Bool     = false,\n          extended_trace::Bool = false,\n          mle::Bool            = false, # default from estimate.jl\n          step_size::Float64   = .01,\n          toggle::Bool         = true,  # default from estimate.jl\n          verbose::Symbol      = :none)\n\nWrapper function to send a model to csminwel (or another optimization routine).\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#Hessian-Approximation-1","page":"Algorithms","title":"Hessian Approximation","text":"","category":"section"},{"location":"algorithms/#","page":"Algorithms","title":"Algorithms","text":"Modules = [DSGE]\nPages   = [\"hessian.jl\", \"hessizero.jl\"]\nOrder   = [:function, :type]","category":"page"},{"location":"algorithms/#DSGE.hessian!-Union{Tuple{T}, Tuple{Union{AbstractDSGEModel, AbstractVARModel},Array{T,1},AbstractArray}} where T<:AbstractFloat","page":"Algorithms","title":"DSGE.hessian!","text":"hessian!(m::Union{AbstractDSGEModel,AbstractVARModel}, x::Vector{T}, data::AbstractArray;\n    check_neg_diag::Bool = true, toggle::Bool = false,\n    verbose::Symbol = :none) where {T<:AbstractFloat}\n\nCompute Hessian of DSGE/VAR posterior function evaluated at x.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#DSGE.hessizero-Union{Tuple{T}, Tuple{Function,Array{T,1}}} where T<:AbstractFloat","page":"Algorithms","title":"DSGE.hessizero","text":"hessizero(fcn::Function, x::Vector{T};\n          check_neg_diag::Bool=false,\n          verbose::Symbol=:none,\n          distr::Bool=true) where T<:AbstractFloat\n\nCompute Hessian of function fcn evaluated at x.\n\nArguments\n\ncheck_neg_diag: Throw an error if any negative diagonal elements are detected.\nverbose: Print verbose output\ndistr: Use available parallel workers to increase performance.\n\n\n\n\n\n","category":"method"},{"location":"algorithms/#Sampling-1","page":"Algorithms","title":"Sampling","text":"","category":"section"},{"location":"algorithms/#","page":"Algorithms","title":"Algorithms","text":"metropolis_hastings","category":"page"},{"location":"algorithms/#DSGE.metropolis_hastings","page":"Algorithms","title":"DSGE.metropolis_hastings","text":"function metropolis_hastings(propdist::Distribution,\n                             loglikelihood::Function,\n                             parameters::ParameterVector{S},\n                             data::Matrix{T},\n                             cc0::T,\n                             cc::T;\n                             n_blocks::Int64        = 1,\n                             n_param_blocks::Int64  = 1,\n                             n_sim::Int64           = 100,\n                             n_burn::Int64          = 0,\n                             mhthin::Int64          = 1,\n                             adaptive_accept::Bool  = false,\n                             target_accept::T       = 0.25,\n                             Î±::T                   = 1.0,\n                             c::T                   = 0.5,\n                             verbose::Symbol        = :low,\n                             savepath::String       = \"mhsave.h5\",\n                             rng::MersenneTwister   = MersenneTwister(0),\n                             regime_switching::Bool = false,\n                             toggle::Bool           = true,\n                             testing::Bool          = false) where {S<:Number, T<:AbstractFloat}\n\nImplements the Metropolis-Hastings MCMC algorithm for sampling from the posterior distribution of the parameters.\n\nArguments\n\nproposal_dist: The proposal distribution that Metropolis-Hastings begins sampling from.\nm: The model object\ndata: Data matrix for observables\ncc0: Jump size for initializing Metropolis-Hastings.\ncc: Jump size for the rest of Metropolis-Hastings.\n\nOptional Arguments\n\nn_blocks::Int = 1: Number of blocks of draws (for memory-management purposes)\nn_param_blocks::Int = 1: Number of parameter blocks (this is the \"blocking\" people normally think about with MH)\nn_sim::Int    = 100: Number of simulations per save block. Note: # saved observations will be   n_sim * n_param_blocks * (n_blocks - b_burn). The # of total simulations will be   n_sim * n_param_blocks * n_blocks * mhthin.\nn_burn::Int   = 0: Length of burn-in period\nmhthin::Int   = 1: Thinning parameter (for mhthin = d, keep only every dth draw)\nadaptive_accept::Bool = false: Whether or not to adaptively adjust acceptance prob. after every memory block.\ntarget_accept::T = 0.25: target accept rate when adaptively adjusting acceptance prob.\nÎ±::T = 1.0: Tuning parameter (step size) for proposal density computation in adaptive case\nc::T = 0.5: Tuning parameter (mixture proportion) for proposal density computation in   adaptive case\nregime_switching::Bool = false: do the parameters involve regime-switching?\ntoggle: if true, toggle the fields of any regime-switching parameters to regime 1.\nverbose::Bool: The desired frequency of function progress messages printed to standard out. One of:\n\n   - `:none`: No status updates will be reported.\n   - `:low`: Status updates provided at each block.\n   - `:high`: Status updates provided at each draw.\n\nsavepath::String = \"mhsave.h5\": String specifying path to output file\nrng::MersenneTwister = MersenneTwister(0): Chosen seed (overridden if testing = true)\ntesting::Bool = false: Conditional for use when testing (determines fixed seeding)\n\n\n\n\n\nmetropolis_hastings(propdist::Distribution, m::Union{AbstractDSGEModel,AbstractVARModel},\n    data::Matrix{T}, cc0::T, cc::T; filestring_addl::Vector{String} = [],\n    regime_switching::Bool = false, toggle::Bool = false,\n    verbose::Symbol = :low) where {T<:AbstractFloat}\n\nWrapper function for DSGE models which calls Metropolis-Hastings MCMC algorithm for sampling from the posterior distribution of the parameters.\n\nArguments\n\npropdist: The proposal distribution that Metropolis-Hastings begins sampling from.\nm: The model object\ndata: Data matrix for observables\ncc0: Jump size for initializing Metropolis-Hastings.\ncc: Jump size for the rest of Metropolis-Hastings.\n\nEstimation Settings\n\nPlease see the section on 'Metropolis-Hastings Settings' on the 'Advaned Usage' page of the online documentation or src/defaults.jl for a full description of all the estimation settings for MH. Most of the settings for MH are stored in the model object. The keyword arguments described below are not directly related to the behavior of the algorithm (e.g. tuning, number of samples).\n\nKeyword Arguments\n\nverbose: The desired frequency of function progress messages printed to standard out. One of:\n\n   - `:none`: No status updates will be reported.\n   - `:low`: Status updates provided at each block.\n   - `:high`: Status updates provided at each draw.\n\nfilestring_addl: additional strings to add to the names of output files\nregime_switching: do the parameters involve regime-switching?\ntoggle: if true, toggle the fields of any regime-switching parameters to regime 1.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/#State-Space-Filters-and-Smoothers-1","page":"Algorithms","title":"State Space Filters and Smoothers","text":"","category":"section"},{"location":"algorithms/#","page":"Algorithms","title":"Algorithms","text":"See StateSpaceRoutines.jl.","category":"page"},{"location":"algorithms/#Sequential-Monte-Carlo-1","page":"Algorithms","title":"Sequential Monte Carlo","text":"","category":"section"},{"location":"algorithms/#","page":"Algorithms","title":"Algorithms","text":"See SMC.jl.","category":"page"},{"location":"forecast/#forecast-step-1","page":"Forecasting","title":"Forecasting","text":"","category":"section"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"This page describes forecasting without regime-switching. Click here to learn about forecasting with regime-switching.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"CurrentModule = DSGE","category":"page"},{"location":"forecast/#Procedure-1","page":"Forecasting","title":"Procedure","text":"","category":"section"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"In the forecast step, we compute smoothed histories, forecast, compute shock decompositions, and compute impulse response functions (IRFs) for states, observables, shocks, and pseudo-observables. To run a forecast on one combination of input parameter type (e.g. modal parameters or full-distribution) and conditional type, call forecast_one. The forecast output is written to the saveroot specified by the model object and can be loaded with the function read_forecast_output.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Main Steps:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Prepare forecast inputs: Add required output types, load data, and load draws of parameter vectors saved from the estimation step.\nCompute forecast outputs: Carry out desired combination of smoothing, forecasting, computing shock decompositions, and computing IRFs. See Forecast Outputs for a list of possible forecast outputs.\nSave forecast outputs: Save each forecast output as an array to its own file, along with some metadata.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"DSGE.forecast_one","category":"page"},{"location":"forecast/#DSGE.forecast_one","page":"Forecasting","title":"DSGE.forecast_one","text":"forecast_one(m, input_type, cond_type, output_vars; df = DataFrame(),\n    subset_inds = 1:0, forecast_string = \"\", verbose = :low, ...)\n\nCompute and save output_vars for input draws given by input_type and conditional data case given by cond_type.\n\nInputs\n\nm::AbstractDSGEModel: model object\ninput_type::Symbol: one of:\n\n  - `:mode`: forecast using the modal parameters only\n  - `:mean`: forecast using the mean parameters only\n  - `:init`: forecast using the initial parameter values only\n  - `:full`: forecast using all parameters (full distribution)\n  - `:subset`: forecast using a well-defined user-specified subset of draws\n\ncond_type::Symbol: one of:\n\n  - `:none`: no conditional data\n  - `:semi`: use \"semiconditional data\" - average of quarter-to-date\n    observations for high frequency series\n  - `:full`: use \"conditional data\" - semiconditional plus nowcasts for\n    desired observables\n\noutput_vars::Vector{Symbol}: vector of desired output variables. See ?forecast_one_draw.\n\nKeyword Arguments\n\ndf::DataFrame: Historical data. If cond_type in [:semi, :full], then the  final row of df should be the period containing conditional data. If not  provided, will be loaded using load_data with the appropriate cond_type\nsubset_inds::AbstractRange{Int64}: indices specifying the draws we want to use. If a more sophisticated selection criterion is desired, the user is responsible for determining the indices corresponding to that criterion. If input_type is not subset, subset_inds will be ignored\nforecast_string::String: short string identifying the subset to be appended to the output filenames. If input_type = :subset and forecast_string is empty, an error is thrown.\nonly_filter::Bool: do not run the smoother and only run the filter. This limits the number of output variables which can be calculated.\nverbose::Symbol: desired frequency of function progress messages printed to standard out. One of :none, :low, or :high.\ncheck_empty_columns::Bool = true: check empty columns or not when loading data (if df is empty)\nbdd_fcast::Bool = true: are we computing the bounded forecasts or not?\nparams::AbstractArray{Float64} = Vector{Float64}(undef, 0): parameter draws for the forecast.    If empty, then we load draws from estimation files implied by the settings in m.\nzlb_method::Symbol: method for enforcing the zero lower bound. Defaults to :shock,   meaning we use a monetary policy shock to enforce the ZLB.\nOther available methods:\n:temporary_altpolicy -> use a temporary alternative policy to enforce the ZLB.\nrerun_smoother::Bool = false: if true, rerun the conditional forecast when automatically enforcing   the ZLB as a temporary alternative policy.\nnan_endozlb_failures::Bool = false: if true, failures of an endogenous ZLB (when implemented   as a temporary policy) will be handled by throwing NaNs instead of using   unanticipated monetary policy shocks.\nset_regime_vals_altpolicy::Function: Function that adds new regimes to parameters when   using temporary alternative policies (if needed). Defaults to identity (which does nothing)   This function should take as inputs the model object m and the total number of regimes   (after adding the required temporary regimes), i.e. set_regime_vals_altpolicy(m, n). It should then   set up regime-switching parameters for these new additional regimes.\nset_info_sets_altpolicy::Function = auto_temp_altpolicy_info_set: Function that automatically updates   the tvis_information_set, e.g. when zlb_method = :temporary_altpolicy.\nupdate_regime_eqcond_info!::Function = (x1, x2, x3, x4) ->   default_update_regime_eqcond_info(x1, x2, x3, x4, alternative_policy(m): Function that automatically   updates the setting :regime_eqcond_info. The arguments of update_regime_eqcond_info! should be (in order)   m::AbstractDSGEModel, eqcond_dict::AbstractDict{Int64, EqcondEntry}, zlb_start_regime::Int64,   and liftoff_regime::Int64. The last two arguments are the regime numbers of the first regime for which   the ZLB applies and the regime after the ZLB ends, respectively.   The eqcond_dict argument should specify the EqcondEntry during the historical/conditional horizon regime   (if it is desired) but can otherwise be empty. This function should then update eqcond_dict   in place to implement a temporary ZLB and any other permanent alternative policies/regime-switching   in the forecast horizon (after the conditional horizon).   The user should also be careful and make sure update_regime_eqcond_info! handles imperfect awareness properly   if they want to implement an imperfectly credible ZLB. For an example, see ?default_update_regime_eqcond_info.\nshow_failed_percent::Bool = false: prints out the number of failed forecasts, which are returned as NaNs.   These may occur when the ZLB is not enforced, for example.\npegFFR::Bool = false: peg the nominal FFR at the value specified by FFRpeg\nFFRpeg::Float64 = -0.25/4: value of the FFR peg\nH::Int = 4: number of horizons for which the FFR is pegged\ntesting_carer_kohn::Bool = false: whether to create a file storing some property of Î£ in Carter Kohn\n\nOutputs\n\nNone. Output is saved to files returned by get_forecast_output_files(m, input_type, cond_type, output_vars).\n\n\n\n\n\n","category":"function"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"For example, to do an unconditional forecast of states and observables using the modal parameters, call:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"m = AnSchorfheide()\nforecast_one(m, :mode, :none, [:forecaststates, forecastobs])","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Full-Distribution Forecasts:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Full-distribution forecasts are computed in blocks. The size of each block defaults to 5000 draws (before thinning by get_setting(m, :forecast_jstep)), but can be set using the :forecast_block_size Setting. For each block, draws are read in on the originator process, then computation proceeds in parallel using pmap. When all draws in the block are finished, the forecast outputs are reassembled on the originator process and appended to the HDF5 dataset in their respective output files.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"To fully take advantage of the parallelization, the user is responsible for adding processes before calling forecast_one, either by calling addprocs or using one of the functions defined in ClusterManagers.jl. For example, to run a full-distribution unconditional forecast using 10 processes:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"my_procs = addprocs(10)\n@everywhere using DSGE\n\nm = AnSchorfheide()\nforecast_one(m, :full, :none, [:forecaststates, forecastobs])\n\nrmprocs(my_procs)","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Notice that it is necessary to load DSGE on all processes using @everywhere using DSGE before calling forecast_one. It is also sometimes necessary to load OrderedCollections on all processes using @everywhere using OrderedCollections.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"By default, full-distribution forecasts start from the first block. However, if you want to start the forecast from a later block, you can also do so. For example:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"m <= Setting(:forecast_start_block, 2,\n    \"Block at which to resume forecasting (possibly null)\")","category":"page"},{"location":"forecast/#Forecast-Outputs-1","page":"Forecasting","title":"Forecast Outputs","text":"","category":"section"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"A forecast output (i.e. an output_var) is a combination of what we call a \"product\" and a \"class\". The possible classes are states (:states), observables (:obs), pseudo-observables (:pseudo), and standardized (:stdshocks) and unstandardized shocks (:shocks). The possible forecast products are:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Smoothed histories (:hist): use the smoother specified by forecast_smoother(m) to get smoothed histories of each class.\nForecasts (:forecast): iterate the state space forward from the last filtered state, either using a specified set of shock innovations or by drawing these from a distribution. Forecasts in which we enforce the zero lower bound are denoted as :bddforecast.\nShock decompositions (:shockdec): decompose a forecast into the contributions from each individual shock (e.g. TFP or monetary policy) or from groups of shocks by exploiting the linearity of the state space system. Starting from an initial state of zero, iterate the state space forward from the first historical period up through the last forecast horizon. To infer the contributions of shocks, use the smoothed historical shocks for one shock at a time during the historical periods. If a modal shock decomposition is computed, then we assume no shocks occur during the forecast periods. If a full-distribution shock decomposition is computed, then we allow shocks to occur during the forecast periods.\nDeterministic trends (:dettrend): iterate the state space forward from the first historical state up through the last forecast horizon without any shocks.\nTrends (:trend): for each class, just the constant term in that class's equation, i.e. the CCC vector from the transition equation for states, the DD vector from the measurement equation for observables, and the DD_pseudo vector from the pseuodo-measurement equation for pseudo-observables.\nIRFs (:irf): see Impulse response. Our IRFs are in response to a shock of size -1 standard deviation.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"An output_var is then just a Symbol with a product and class concatenated, e.g. :histstates for smoothed historical states.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"It is not necessary to compute all forecast outputs in one call to forecast_one. Which steps are run depends on which output_vars are passed in. Most users will just want to calculate :forecastobs, :histobs, :forecastpseudo, and :histpseudo.","category":"page"},{"location":"forecast/#calc-shock-dec-1","page":"Forecasting","title":"Calculating Shock Decompositions","text":"","category":"section"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"The user should note that shock decompositions are not the same thing as forecast decompositions in DSGE.jl. The former decomposes a forecast into the contributions of individual or groups of shocks. The latter decomposes the change between two different forecasts into \"data revision\", \"news\" and \"re-estimation\" components.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"If the user wants to plot shock decompositions to decompose a forecast's deviations from trend into the contributions of individual or groups of shocks, then the user needs to calculate the shockdec, detttrend, and trend output variables. Otherwise, the plotting script plot_shock_decompositions will fail.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Finally, note that full-distribution shock decompositions are very memory intensive. For Model1002, we typically need 30GB-40GB using the default settings. To avoid memory problems, the user should decrease the setting :forecast_block_size to a smaller number than the default 5000. A smaller block size means that fewer draws from the posterior are loaded into memory at any one time, hence the size of the matrices associated with shock decompositions will also be smaller.","category":"page"},{"location":"forecast/#Preparing-Forecast-Inputs-1","page":"Forecasting","title":"Preparing Forecast Inputs","text":"","category":"section"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Adding Required output_vars:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"The user specifies what output to compute by passing a Vector{Symbol} of correctly named output variables into forecast_one. Underneath the hood, we will add any additional output variables that are required to complete a forecast using add_requisite_output_vars:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"If :forecast<class> is in output_vars, then :bddforecast<class> is also added. Hence we always forecast both with and without enforcing the ZLB.\nIf :shockdec<class> is in output_vars, then :dettrend<class> and :trend<class> are also added. This is because to plot shock decompositions, we also need the trend and the deterministic trend.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Loading Data:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"This is done the usual way, using load_data with the appropriate cond_type.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Note that if you are running a conditional forecast, then you should check that the appropriate observables are found in cond_full_names(m) and/or cond_semi_names(m). If the observables on which you are conditioning do not match the ones found in these settings exactly, then conditional forecasting will not generate the results you want. To change these observables to, for example, condition on custom_obs1 and custom_obs2, add the line","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"m <= Setting(:cond_full_names, [custom_obs1, custom_obs2])","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"to your script for full conditional forecasts. The syntax is similar for semi-conditional forecasts. If you have already created a conditional dataset successfully, then you should be sure to re-create the data set by running","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"load_data(m; try_disk = false, cond_type = cond_type)","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"If you do not have try_disk = false, then the code may load a saved data set that does not have the conditional observables you want to use.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Loading Draws:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"By default, the draws are loaded from the file whose path is given by get_forecast_input_file. However, you can directly pass a matrix of posterior parameter draws or a vector of the modal parameters via the keyword argument params for forecast_one, or you can override the default input file for a given input type by adding entries to the Dict{Symbol, ASCIIString} returned from forecast_input_file_overrides(m). For example:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"overrides = forecast_input_file_overrides(m)\noverrides[:mode] = \"path/to/input/file.h5\"","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Note that load_draws expects an HDF5 dataset called either params (for input_type in [:mode, :mean]) or mhparams (for input_type in [:full, :subset]) if the sampling method is :MH. If the sampling method is :SMC, then load_draws expects a jld2 file which has a variable named cloud.","category":"page"},{"location":"forecast/#Computing-Forecast-Outputs-1","page":"Forecasting","title":"Computing Forecast Outputs","text":"","category":"section"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"For each draw of parameters, the forecast calculations are run by the lower-level function forecast_one_draw.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"This function is also useful on its own when the user wants to run a single-draw forecast without writing the output to data. A common use case is running experiments with different forecast specifications and/or alternative policy rules. Given the appropriate inputs, forecast_one_draw will return a Dict whose keys are the names of output variables (e.g. :forecastobs) and values are the corresponding matrices. This function does not perform transformations, so the units of the output are all model units, which are typically at the quarterly frequency, such as quarterly per-capita GDP growth.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"The computations that forecast_one_draw can run are:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Smoothing:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Smoothing is necessary if either:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"You explicitly want the smoothed histories, or\nYou want to compute shock decompositions or deterministic trends, which use the smoothed historical shocks","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"It is not necessary to keep track of these cases, however - forecast_one will deduce from the specified output_vars whether or not it is necessary to filter and smooth in order to produce your output_vars.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Forecasting:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Forecasting begins from the last filtered historical state, which is obtained from the Kalman filter. forecast accepts a keyword argument enforce_zlb, which indicates whether to enforce the zero lower bound. If enforce_zlb = true, then if in a given period, the forecasted interest rate goes below forecast_zlb_value(m), we solve for the interest rate shock necessary to push it up to the ZLB. A forecast in which the ZLB is enforced corresponds to the product :bddforecast.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Shock Decompositions, Deterministic Trends, and Trends:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Since shock decompositions have an additional dimension (e.g. nstates x nperiods x nshocks for a single draw of state shock decompositions, compared to nstates x nperiods for a single draw of forecasted states), we usually wish to truncate some periods before returning. This behavior is governed by the Settings :shockdec_starttdate and :shockdec_enddate, which are of type Nullable{Date}.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Deterministic trends are also saved only for date_shockdec_start(m) and date_shockdec_end(m). Trends are not time-dependent.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Note that shock decompositions are memory intensive. For a typical forecast of Model1002 without shock decompositions, only 1-2GB of memory are needed. For a forecast with shock decompositions, roughtly 14-16GB will be needed.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Impulse Response Functions:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Like shock decompositions, IRFs have three dimensions (e.g. nstates x nperiods x nshocks) for each draw.","category":"page"},{"location":"forecast/#Saving-Forecast-Outputs-1","page":"Forecasting","title":"Saving Forecast Outputs","text":"","category":"section"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Forecast outputs are saved in the location specified by get_forecast_output_files(m), which is typically a subdirectory of saveroot(m). Each output_var is saved in its own JLD file, which contains the following datasets:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"arr::Array: actual array of forecast outputs. For trends, this array is of size ndraws x nvars. For histories, forecasts, and deterministic trends, it is ndraws x nvars x nperiods. For shock decompositions and IRFs, it is ndraws x nvars x nperiods x nshocks. (In all of these, nvars refers to the number of variables of the output class.)\ndate_indices::Dict{Date, Int}: maps Dates to their indices along the nperiods dimension of arr. Not saved for IRFs.\n<class>_names::Dict{Symbol, Int}: maps names of variables of the output class (e.g. :OutputGap) into their indices along the nvars dimension of arr.\n<class>_revtransforms::Dict{Symbol, Symbol}: maps names of variables to the names of the reverse transforms (from model units into plotting units) associated with those variables. For example, pseudoobservable_revtransforms[:Ï€_t] = :quartertoannual.\nshock_names::Dict{Symbol, Int}: for shock decompositions and IRFs only, maps names of shocks into their indices along the nshocks dimension of arr.","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Some helpful functions for getting file names, as well as reading and writing forecast outputs, include:","category":"page"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"get_forecast_input_file\nget_forecast_filename\nget_forecast_output_files\nwrite_forecast_outputs\nwrite_forecast_block\nwrite_forecast_metadata\nread_forecast_metadata\nread_forecast_output","category":"page"},{"location":"forecast/#Forecasting-Functions-1","page":"Forecasting","title":"Forecasting Functions","text":"","category":"section"},{"location":"forecast/#","page":"Forecasting","title":"Forecasting","text":"Modules = [DSGE]\nPages   = [\"drivers.jl\", \"forecast.jl\", \"smooth.jl\", \"shock_decompositions.jl\", \"io.jl\"]\nOrder   = [:function]","category":"page"},{"location":"forecast/#DSGE.decompose_forecast-Union{Tuple{M}, Tuple{M,M,DataFrames.DataFrame,DataFrames.DataFrame,Symbol,Symbol,Symbol,Array{Symbol,1}}} where M<:AbstractDSGEModel","page":"Forecasting","title":"DSGE.decompose_forecast","text":"decompose_forecast(m_new, m_old, df_new, df_old, input_type, cond_new, cond_old,\n    classes; verbose = :low, kwargs...)\n\ndecompose_forecast(m_new, m_old, df_new, df_old, params_new, params_old,\n    cond_new, cond_old, classes; check = false)\n\nexplains the differences between an old forecast and a new forecast by decomposing the differences into three sources:\n\n(1) Data revisions, (2) News (e.g. new data that has become available since the old forecast), (3) Re-estimation (i.e. changes in model parameters).\n\nThis function does not compute which shocks explain a forecast. For example, if you want to know whether TFP or financial shocks drive a given forecast, then you want to compute the shock decomposition output variable (see ?shock_decompositions, forecast_one, and compute_meansbands).\n\nNote that this function currently does not work for a model in which there are changes in the degree of \"regime-switching\" in the TTT, RRR, CCC, ZZ, and DD matrices, e.g. decomposing the changes in the forecast when the monetary policy rule changes or if a temporary policy is implemented that did not occur in the old forecast.\n\nInputs\n\nm_new::M and m_old::M where M<:AbstractDSGEModel\ndf_new::DataFrame and df_old::DataFrame\ncond_new::Symbol and cond_old::Symbol\nclasses::Vector{Symbol}: some subset of [:states, :obs, :pseudo]\n\nMethod 1 only:\n\ninput_type::Symbol: estimation type to use. Parameters will be loaded using load_draws(m_new, input_type) and load_draws(m_old, input_type) in this method\n\nMethod 2 only:\n\nparams_new::Vector{Float64} and params_old::Vector{Float64}: single parameter draws to use\n\nKeyword Arguments\n\ncheck::Bool: whether to check that the individual components add up to the correct total difference in forecasts. This roughly doubles the runtime\n\nMethod 1 only:\n\nverbose::Symbol\n\nOutputs\n\nThe first method returns nothing. The second method returns decomp::Dict{Symbol, Matrix{Float64}}, which has keys of the form :decomp<component><class> and values of size Ny x Nh, where\n\nNy is the number of variables in the given class\nNh is the number of common forecast periods, i.e. periods between date_forecast_start(m_new) and date_forecast_end(m_old)\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.forecast_one-Tuple{AbstractDSGEModel{Float64},Symbol,Symbol,Array{Symbol,1}}","page":"Forecasting","title":"DSGE.forecast_one","text":"forecast_one(m, input_type, cond_type, output_vars; df = DataFrame(),\n    subset_inds = 1:0, forecast_string = \"\", verbose = :low, ...)\n\nCompute and save output_vars for input draws given by input_type and conditional data case given by cond_type.\n\nInputs\n\nm::AbstractDSGEModel: model object\ninput_type::Symbol: one of:\n\n  - `:mode`: forecast using the modal parameters only\n  - `:mean`: forecast using the mean parameters only\n  - `:init`: forecast using the initial parameter values only\n  - `:full`: forecast using all parameters (full distribution)\n  - `:subset`: forecast using a well-defined user-specified subset of draws\n\ncond_type::Symbol: one of:\n\n  - `:none`: no conditional data\n  - `:semi`: use \"semiconditional data\" - average of quarter-to-date\n    observations for high frequency series\n  - `:full`: use \"conditional data\" - semiconditional plus nowcasts for\n    desired observables\n\noutput_vars::Vector{Symbol}: vector of desired output variables. See ?forecast_one_draw.\n\nKeyword Arguments\n\ndf::DataFrame: Historical data. If cond_type in [:semi, :full], then the  final row of df should be the period containing conditional data. If not  provided, will be loaded using load_data with the appropriate cond_type\nsubset_inds::AbstractRange{Int64}: indices specifying the draws we want to use. If a more sophisticated selection criterion is desired, the user is responsible for determining the indices corresponding to that criterion. If input_type is not subset, subset_inds will be ignored\nforecast_string::String: short string identifying the subset to be appended to the output filenames. If input_type = :subset and forecast_string is empty, an error is thrown.\nonly_filter::Bool: do not run the smoother and only run the filter. This limits the number of output variables which can be calculated.\nverbose::Symbol: desired frequency of function progress messages printed to standard out. One of :none, :low, or :high.\ncheck_empty_columns::Bool = true: check empty columns or not when loading data (if df is empty)\nbdd_fcast::Bool = true: are we computing the bounded forecasts or not?\nparams::AbstractArray{Float64} = Vector{Float64}(undef, 0): parameter draws for the forecast.    If empty, then we load draws from estimation files implied by the settings in m.\nzlb_method::Symbol: method for enforcing the zero lower bound. Defaults to :shock,   meaning we use a monetary policy shock to enforce the ZLB.\nOther available methods:\n:temporary_altpolicy -> use a temporary alternative policy to enforce the ZLB.\nrerun_smoother::Bool = false: if true, rerun the conditional forecast when automatically enforcing   the ZLB as a temporary alternative policy.\nnan_endozlb_failures::Bool = false: if true, failures of an endogenous ZLB (when implemented   as a temporary policy) will be handled by throwing NaNs instead of using   unanticipated monetary policy shocks.\nset_regime_vals_altpolicy::Function: Function that adds new regimes to parameters when   using temporary alternative policies (if needed). Defaults to identity (which does nothing)   This function should take as inputs the model object m and the total number of regimes   (after adding the required temporary regimes), i.e. set_regime_vals_altpolicy(m, n). It should then   set up regime-switching parameters for these new additional regimes.\nset_info_sets_altpolicy::Function = auto_temp_altpolicy_info_set: Function that automatically updates   the tvis_information_set, e.g. when zlb_method = :temporary_altpolicy.\nupdate_regime_eqcond_info!::Function = (x1, x2, x3, x4) ->   default_update_regime_eqcond_info(x1, x2, x3, x4, alternative_policy(m): Function that automatically   updates the setting :regime_eqcond_info. The arguments of update_regime_eqcond_info! should be (in order)   m::AbstractDSGEModel, eqcond_dict::AbstractDict{Int64, EqcondEntry}, zlb_start_regime::Int64,   and liftoff_regime::Int64. The last two arguments are the regime numbers of the first regime for which   the ZLB applies and the regime after the ZLB ends, respectively.   The eqcond_dict argument should specify the EqcondEntry during the historical/conditional horizon regime   (if it is desired) but can otherwise be empty. This function should then update eqcond_dict   in place to implement a temporary ZLB and any other permanent alternative policies/regime-switching   in the forecast horizon (after the conditional horizon).   The user should also be careful and make sure update_regime_eqcond_info! handles imperfect awareness properly   if they want to implement an imperfectly credible ZLB. For an example, see ?default_update_regime_eqcond_info.\nshow_failed_percent::Bool = false: prints out the number of failed forecasts, which are returned as NaNs.   These may occur when the ZLB is not enforced, for example.\npegFFR::Bool = false: peg the nominal FFR at the value specified by FFRpeg\nFFRpeg::Float64 = -0.25/4: value of the FFR peg\nH::Int = 4: number of horizons for which the FFR is pegged\ntesting_carer_kohn::Bool = false: whether to create a file storing some property of Î£ in Carter Kohn\n\nOutputs\n\nNone. Output is saved to files returned by get_forecast_output_files(m, input_type, cond_type, output_vars).\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.load_draws-Tuple{AbstractDSGEModel,Symbol}","page":"Forecasting","title":"DSGE.load_draws","text":"load_draws(m, input_type; subset_inds = 1:0, verbose = :low)\n\nload_draws(m, input_type, block_inds; verbose = :low)\n\nLoad and return parameter draws from Metropolis-Hastings or SMC.\n\nInputs\n\nm::AbstractDSGEModel: model object\ninput_type::Symbol: one of the options for input_type described in the documentation for forecast_one\nblock_inds::AbstractRange{Int64}: indices of the current block (already indexed by jstep) to be read in. Only used in second method\n\nKeyword Arguments\n\nsubset_inds::AbstractRange{Int64}: indices specifying the subset of draws to be read in. Only used in first method\nverbose::Symbol: desired frequency of function progress messages printed to standard out. One of :none, :low, or :high. If :low or greater, prints location of input file.\n\nOutputs\n\nparams: first method returns a single parameter draw of type Vector{Float64}. Second method returns a Vector{Vector{Float64}} of parameter draws for this block.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.usual_model_forecast","page":"Forecasting","title":"DSGE.usual_model_forecast","text":"usual_model_forecast(m, input_type, cond_type,\n    output_vars = [:histobs, :histpseudo, :forecastobs, :forecastpseudo];\n    est_override = \"\", forecast_string = \"\",\n    density_bands = [0.5, 0.6, 0.7, 0.8, 0.9],\n    mb_matrix = false, check_empty_columns = true, params = [])\n\nForecast, compute means and bands, and optionally (if mb_matrix) convert MeansBands to matrices. If the path est_override is provided, it will be added to forecast_input_file_overrides(m).\n\nSee ?forecast_one for descriptions of the keywords.\n\n\n\n\n\n","category":"function"},{"location":"forecast/#DSGE.usual_model_settings!-Tuple{AbstractDSGEModel,String}","page":"Forecasting","title":"DSGE.usual_model_settings!","text":"usual_model_settings!(m, vint; cdvt = vint, dsid = data_id(m), cdid = cond_id(m),\n    fcast_date = Dates.lastdayofquarter(Dates.today()),\n    altpolicy = AltPolicy(:historical, eqcond, solve))\n\nApply usual defaults for the following settings:\n\ndata_vintage and cond_vintage: given by input argument vint\ndate_forecast_start and date_conditional_end: given by kwarg fcast_date\nuse_population_forecast: true\nalternative_policy: given by input argument altpolicy. If this argument is specified, then altpolicy_settings! and altpolicy.setup are also called.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.compute_scenario_system-Tuple{AbstractDSGEModel,Scenario}","page":"Forecasting","title":"DSGE.compute_scenario_system","text":"compute_scenario_system(m, scen::Scenario; apply_altpolicy = false)\n\nGiven the current model parameters, compute the state-space system corresponding to model m and alternative scenario scen. This function differs from compute_system in that the CCC, DD, and DD_pseudo vectors are set to zero (since we forecast in deviations from baseline) and shocks that are not in scen.instrument_names are zeroed out in the QQ matrix.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.filter_shocks!","page":"Forecasting","title":"DSGE.filter_shocks!","text":"filter_shocks!(m, scen, system::Scenario)\n\nGiven a scenario draw scen, back out the shocks necessary to hit scen.targets and put them into scen.instruments. This function returns forecastshocks, an nshocks x horizon matrix of filtered and smoothed shocks.\n\nThis function checks forecast_uncertainty_override(m) for whether to smooth shocks using the simulation smoother.\n\n\n\n\n\n","category":"function"},{"location":"forecast/#DSGE.forecast-Union{Tuple{S}, Tuple{AbstractDSGEModel,Union{RegimeSwitchingSystem{S}, System{S}},Array{S,1}}} where S<:AbstractFloat","page":"Forecasting","title":"DSGE.forecast","text":"forecast(m, system, z0; cond_type = :none,\n    enforce_zlb = false, shocks = Matrix{S}(undef, 0,0))\n\nforecast(m, altpolicy, z0, states, obs, pseudo, shocks)\n\nforecast(system, z0, shocks; enforce_zlb = false)\n\nforecast(m, system, z0, shocks; cond_type = :none, enforce_zlb = false)\n\nThe first method produces a forecast, given a state space system, initial state, and shocks, using information about the desired forecast contained in m. It enforces the ZLB by using monetary policy shocks.\n\nThe second method is similar but differs in two ways. First, it produces forecasts specifically when an alternative policy is used. Second, it enforces the ZLB by treating it as a temporary alternative policy.\n\nThe third and fourth methods are internal functions used by the first two methods.\n\nInputs\n\nsystem::System{S}: state-space system matrices\nz0::Vector{S}: state vector in the final historical period\nshocks::Matrix{S}: nshocks x nperiods matrix of shocks to use when forecasting. Note that in the first method, nperiods doesn't necessarily have to equal forecast_horizons(m); it will be truncated or padded with zeros appropriately\n\nMethod 1 and 2 only:\n\nm::AbstractDSGEModel\n\nMethod 2 only:\n\naltpolicy::Symbol: Which alternative policy is being used\nobs::Matrix{S <: Real}: matrix of forecasted observables\n\nwhere S<:AbstractFloat.\n\nKeyword Arguments\n\ncond_type::Symbol: one of :none, :semi, or :full, used to determine how many periods to forecast ahead. If cond_type in [:semi, :full], the forecast horizon is reduced by the number of periods of conditional data. Defaults to :none.\nenforce_zlb::Bool: whether to enforce the zero lower bound. Defaults to false.\nshocks::Matrix{S}: matrix of size nshocks x shock_horizon of shock innovations under which to forecast. If shock_horizon > horizon, the extra periods of shocks will be ignored; if shock_horizon < horizon, zeros will be filled in for the shocks hitting the remaining forecasted periods.\ndraw_shocks::Bool: if isempty(shocks), indicates whether to draw shocks according to:\nIf forecast_tdist_shocks(m), draw horizons many shocks from a Distributions.TDist(forecast_tdist_df_val(m))\nOtherwise, draw horizons many shocks from a DegenerateMvNormal(zeros(nshocks), sqrt(system[:QQ]))\nor to set shocks to a nshocks x horizon matrix of zeros. Defaults to false. If shocks is provided as a keyword argument, this flag has no effect.\n\nMethod 2 only:\n\nset_zlb_regime_vals::Function: user-provided function that adds additional regimes to   regime-switching parameters if not enough regimes exist to impose the ZLB   as a temporary alternative policy. Defaults to identity, and nothing will happen   if this is the case.\ntol::{<: Real}: Tolerance for the smallest permissible value for the nominal interest rate.   Defaults to -1e-14.\n\nOutputs\n\nstates::Matrix{S}: matrix of size nstates x horizon of forecasted states\nobs::Matrix{S}: matrix of size nobs x horizon of forecasted observables\npseudo::Matrix{S}: matrix of size npseudo x horizon of forecasted pseudo-observables\nshocks::Matrix{S}: matrix of size nshocks x horizon of shock innovations\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.forecast_scenario-Tuple{AbstractDSGEModel,Scenario}","page":"Forecasting","title":"DSGE.forecast_scenario","text":"forecast_scenario(m, scen::Scenario; verbose = :low)\n\nSimulate all draws of scen using the modal parameters of the model m. This function returns a Dict{Symbol, Array{Float64}.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.histforecast","page":"Forecasting","title":"DSGE.histforecast","text":"histforecast(var, hist, forecast;\n    start_date = hist.means[1, :date], end_date = forecast.means[end, :date],\n    names = Dict{Symbol, String}(), colors = Dict{Symbol, Any}(),\n    alphas = Dict{Symbol, Float64}(), styles = Dict{Symbol, Symbol}(),\n    bands_pcts = union(which_density_bands(hist, uniquify = true),\n                       which_density_bands(forecast, uniquify = true)),\n    bands_style = :fan, label_bands = false, transparent_bands = true,\n    tick_size = 2)\n\nUser recipe called by plot_history_and_forecast.\n\nInputs\n\nvar::Symbol: e.g. obs_gdp\nhist::MeansBands\nforecast::MeansBands\n\nKeyword Arguments\n\nstart_date::Date\nend_date::Date\nnames::Dict{Symbol, String}: maps keys [:hist, :forecast, :bands] to labels. If a key is missing from names, a default value will be used\ncolors::Dict{Symbol, Any}: maps keys [:hist, :forecast, :bands] to colors\nalphas::Dict{Symbol, Float64}: maps keys [:hist, :forecast, :bands] to transparency values (between 0.0 and 1.0)\nstyles::Dict{Symbol, Symbol}: maps keys [:hist, :forecast, :bands] to linestyles\nbands_pcts::Vector{String}: which bands percentiles to plot\nbands_style::Symbol: either :fan or :line\nlabel_bands::Bool\ntransparent_bands::Bool\ntick_size::Int: x-axis (time) tick size in units of years\nadd_new_model::Bool: Adding history from another model?\nnew_data::Array{Flaot64,1}: The new history to plot\n\nAdditionally, all Plots attributes (see docs.juliaplots.org/latest/attributes) are supported as keyword arguments.\n\n\n\n\n\n","category":"function"},{"location":"forecast/#DSGE.histforecast_vector","page":"Forecasting","title":"DSGE.histforecast_vector","text":"histforecast_vector(var, hist, forecast;\n    start_date::Date = hf.args[2][1].means[1, :date],\n    end_date::Date = hf.args[3][1].means[end, :date],\n    names = Dict{Symbol, Vector{String}}(),\n    colors = Dict{Symbol, Any}(),\n    alphas = Dict{Symbol, Float64}(),\n    styles = Dict{Symbol, Symbol}(),\n    add_new_model::Bool = false, new_data::Array{Float64,1} = [],\n    bands_pcts = union(which_density_bands(hf.args[2][1], uniquify = true),\n        which_density_bands(hf.args[3][1], uniquify = true)),\n    bands_style = :fan,\n    label_bands = false,\n    transparent_bands = true,\n    add_trendline::Bool = false, trend_vals::Vector{Float64} = [1.0],\n    tick_size = 2)\n\nUser recipe called by plot_history_and_forecast.\n\nInputs\n\nvar::Symbol: e.g. obs_gdp\nhist::Vector{MeansBands}\nforecast::Vector{MeansBands}\n\nKeyword Arguments\n\nstart_date::Date\nend_date::Date\nnames::Dict{Symbol, String}: maps keys [:hist, :forecast, :bands] to labels. If a key is missing from names, a default value will be used\ncolors::Dict{Symbol, Any}: maps keys [:hist, :forecast, :bands] to colors\nalphas::Dict{Symbol, Float64}: maps keys [:hist, :forecast, :bands] to transparency values (between 0.0 and 1.0)\nstyles::Dict{Symbol, Symbol}: maps keys [:hist, :forecast, :bands] to linestyles\nbands_pcts::Vector{String}: which bands percentiles to plot\nbands_style::Symbol: either :fan or :line\nlabel_bands::Bool\ntransparent_bands::Bool\ntick_size::Int: x-axis (time) tick size in units of years\nadd_new_model::Bool: Adding history from another model?\nnew_data::Array{Float64,1}: The new history to plot\nadd_trendline::Bool: Whether add a trendline or not\ntrend_vals::Vector{Float64}: The values to multiply last historical value by   for the trendline (should start with 0.0 to keep last historical value the same)\nplot_all_histories::Bool: Whether to plot histories for each model (generally used   for pseudo observables like Natural Rate.\n\nAdditionally, all Plots attributes (see docs.juliaplots.org/latest/attributes) are supported as keyword arguments.\n\n\n\n\n\n","category":"function"},{"location":"forecast/#DSGE.plot_history_and_forecast-Tuple{AbstractDSGEModel,Symbol,Symbol,Symbol,Symbol}","page":"Forecasting","title":"DSGE.plot_history_and_forecast","text":"plot_history_and_forecast(m, var, class, input_type, cond_type;\n    title = \"\", plot_handle = plot(), kwargs...)\n\nplot_history_and_forecast(m, vars, class, input_type, cond_type;\n    forecast_string = \"\", use_bdd = :unbdd,\n    plotroot = figurespath(m, \"forecast\"), titles = [],\n    plot_handles = fill(plot(), length(vars)), verbose = :low,\n    add_trendline::Bool = false, trend_vals::Vector{Float64} = [1.0],\n    kwargs...)\n\nplot_history_and_forecast(ms::Vector, vars::Vector{Symbol}, class::Symbol,\n    input_type::Symbol, cond_type::Symbol;\n    forecast_string::String = \"\",\n    use_bdd::Symbol = :bdd,\n    modal_line::Bool = false, untrans::Bool = false,\n    fourquarter::Bool = false,\n    plotroot::String = figurespath(ms[1], \"forecast\"),\n    titles::Vector{String} = String[],\n    plot_handles::Vector{Plots.Plot} = Plots.Plot[plot() for i = 1:length(vars)],\n    verbose::Symbol = :low, names = Dict{Symbol, Vector{String}}(),\n    start_date::Date = Date(2019,3,31), end_date::Date = iterate_quarters(date_forecast_start(m), 12),\n    add_new_model::Bool = false, new_model::AbstractDSGEModel = Model1002(),\n    new_cond_type::Symbol = :full, outfile_end::String =  \"\",\n    new_forecast_string::String = forecast_string,\n    add_trendline::Bool = false, trend_vals::Vector{Float64} = [1.0],\n    forecast_strings::Vector{String} = repeat([forecast_string], length(ms)),\n    kwargs...)\n\nPlot history and forecast for var or vars. If these correspond to a full-distribution forecast, you can specify the bands_style and bands_pcts.\n\nInputs\n\nm::AbstractDSGEModel\nvar::Symbol or vars::Vector{Symbol}: variable(s) to be plotted, e.g. :obs_gdp or [:obs_gdp, :obs_nominalrate]\nclass::Symbol\ninput_type::Symbol\ncond_type::Symbol\n\nKeyword Arguments\n\nforecast_string::String = \"\"\nuse_bdd::Symbol = :unbdd: specifies which combination of means and bands to use   a. :bdd -> bounded bands and bounded means (from :bddforecastobs, etc.)   b. :bdd_and_unbdd -> bounded bands (from :bddforecastobs, etc.) and unbounded means (from :forecastobs, etc.)   c. :unbdd -> unbounded bands and unbounded means (from :forecastobs, etc.)\nmodal_line::Bool = false: if true, the modal line is plotted instead of the mean.\nuntrans::Bool = false: whether to plot untransformed (model units) history and forecast\nfourquarter::Bool = false: whether to plot four-quarter history and forecast\nplotroot::String = figurespath(m, \"forecast\"): if nonempty, plots will be saved in that directory\ntitle::String = \"\" or titles::Vector{String} = []\nplot_handle::Plot or plot_handles::Vector{Plot}: existing plot(s) on which to overlay new forecast plot(s)\nverbose::Symbol = :low\nnames::Dict{Symbol, Vector{String}}: Legend names for lines\nstart_date::Date = Date(2019,3,31)`: Date plot should start at\nend_date::Date = iteratequarters(dateforecast_start(m), 12)`: Date plot should end at\nadd_new_model::Bool = false: Whether history should be plotted using a new model\nnew_model::AbstractDSGEModel = Model1002(): The new model to use to plot history\nnew_cond_type::Symbol = :full: Cond_type of new model\noutfile_end::String = \"\": String to append to the end of file name of plot\nnew_forecast_string::String = forecast_string: Forecast string for new model\nadd_trendline::Bool: Whether add a trendline or not\ntrend_vals::Vector{Float64}: The values to multiply last historical value by   for the trendline (should start with 0.0 to keep last historical value the same)\nforecast_strings::Vector{String}: Forecast string to use for each give model.\n\nSee ?histforecast or ?histforecast_vector' for additional keyword arguments, all of which can be passed intoplothistoryand_forecast`.\n\nOutput\n\np::Plot or plots::OrderedDict{Symbol, Plot}\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.smooth-Union{Tuple{S}, Tuple{AbstractDSGEModel,DataFrames.DataFrame,System{S}}, Tuple{AbstractDSGEModel,DataFrames.DataFrame,System{S},Array{S,1}}, Tuple{AbstractDSGEModel,DataFrames.DataFrame,System{S},Array{S,1},Array{S,2}}} where S<:AbstractFloat","page":"Forecasting","title":"DSGE.smooth","text":"smooth(m, df, system, s_0, P_0; cond_type = :none, draw_states = true,\n    include_presample = false)\n\nComputes and returns the smoothed values of states and shocks for the system system.\n\nInputs\n\nm::AbstractDSGEModel: model object\ndf::DataFrame: data for observables. This should include the conditional period if cond_type in [:semi, :full]\nsystem::System: System object representing the state-space system\ns_0::Vector{S}: optional initial state vector\nP_0::Matrix{S}: optional initial state covariance matrix\n\nKeyword Arguments\n\ncond_type: conditional case. See forecast_one for documentation of all cond_type options\ndraw_states: if using a simulation smoother (i.e. forecast_smoother(m) in [:carter_kohn, :durbin_koopman]), indicates whether  to draw smoothed states from the distribution N(z_{t|T}, P_{t|T}) or to use  the mean z_{t|T}. Defaults to false. If not using a simulation smoother,  this flag has no effect (though the user will be warned if  draw_states = true)\ninclude_presample::Bool: indicates whether to include presample periods in the returned matrices. Defaults to false.\nin_sample::Bool: indicates whether or not to discard out of sample rows in df_to_matrix call.\n\nOutputs\n\nstates::Matrix{S}: array of size nstates x hist_periods of smoothed states (not including the presample)\nshocks::Matrix{S}: array of size nshocks x hist_nperiods of smoothed shocks\npseudo::Matrix{S}: matrix of size npseudo x hist_periods of pseudo-observables computed from the smoothed states\ninitial_states::Vector{S}: vector of length nstates of the smoothed states in the last presample period. This is used as the initial state for computing the deterministic trend\n\nNotes\n\nstates and shocks are returned from the smoother specified by forecast_smoother(m), which defaults to :durbin_koopman. This can be overridden by calling\n\nm <= Setting(:forecast_smoother, :koopman_smoother))\n\nbefore calling smooth.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.deterministic_trends-Union{Tuple{S}, Tuple{AbstractDSGEModel{S},System{S},Array{S,1}}} where S<:AbstractFloat","page":"Forecasting","title":"DSGE.deterministic_trends","text":"deterministic_trends(m, system, z0)\n\ndeterministic_trends(system, z0, nperiods, start_index, end_index)\n\ndeterministic_trends(m, system, z0, start_date, end_date)\n\ndeterministic_trends(m, system, z0, nperiods, start_index, end_index,\n    regime_inds, regimes, cond_type)\n\ndeterministic_trends(m, system, old_system, z0, start_date, end_date)\n\ndeterministic_trends(m, system, old_system, z0, nperiods, start_index, end_index,\n    regime_inds, regimes, cond_type)\n\nCompute deterministic trend values of states, observables, and pseudo-observables, given a model object and system matrices. The deterministic trend for a single draw is simply the series that would be obtained by iterating the state-space system forward, beginning from a state vector z0 in the last presample period.\n\nInputs\n\nm::AbstractDSGEModel: model object\nsystem::System{S} or RegimeSwitchingSystem: state-space system matrices\nz0::Vector{S}: initial state vector\nstart_date::Date: initial date for deterministic trends\nend_date::Date: final date for deterministic trends\nregime_inds::Vector{UnitRange}: indices of the data corresponding to each regime.\nregimes::UnitRange: which regimes are involved in the date range for which   we want to compute the deterministic trends\nold_system::RegimeSwitchingSystem`: state-space system matrices for old model\n\nwhere S<:AbstractFloat.\n\nOutputs\n\nstates::Matrix{S}: matrix of size nstates x nperiods of state steady-state values\nobs::Matrix{S}: matrix of size nobs x nperiods of observable steady-state values\npseudo::Matrix{S}: matrix of size npseudo x nperiods of pseudo-observable steady-state values\n\nwhere nperiods is the number of quarters between date_shockdec_start(m) and date_shockdec_end(m), inclusive.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.shock_decompositions-Union{Tuple{S}, Tuple{AbstractDSGEModel,System{S},Array{S,2}}} where S<:AbstractFloat","page":"Forecasting","title":"DSGE.shock_decompositions","text":"shock_decompositions(m, system, histshocks)\n\nshock_decompositions(system, forecast_horizons, histshocks, start_index,\n    end_index)\n\nshock_decompositions(m, system, histshocks, start_date, end_date)\n\nshock_decompositions(m, system, forecast_horizons, histshocks, start_index,\n    end_index, regime_inds, cond_type)\n\nshock_decompositions(m, system, old_system,\n                              histshocks, old_histshocks, start_date, end_date,\n                              cond_type; full_shock_decomp)\n\nshock_decompositions(m, system, old_system,\n                              forecast_horizons, histshocks, old_histshocks,\n                              start_index, end_index,\n                              regime_inds, cond_type; full_shock_decomp)\n\nInputs\n\nsystem::System{S} or RegimeSwitchingSystem{S}: state-space system matrices\nforecast_horizons::Int: number of periods ahead to forecast\nhistshocks::Matrix{S}: matrix of size nshocks x hist_periods of historical smoothed shocks\nstart_index::Int: first index from which to return computed shock decompositions\nend_index::Int: last index for which to return computed shock decompositions\nstart_date::Date: initial date for deterministic trends\nend_date::Date: final date for deterministic trends\nregime_inds::Vector{UnitRange}: indices of the data corresponding to each regime.\nold_system::RegimeSwitchingSystem{S}: state-space system matrices for the old model\nold_histshocks::Matrix{S}: matrix of size nshocks x hist_periods of historical smoothed shocks using the old system\nfull_shock_decomp::Bool: If true for old_system case, return difference in shockdecs   between all shocks for the new and old systems. Else, return old system's shocks   with 1 cumulative AIT shock added on.\n\nwhere S<:AbstractFloat.\n\nOutputs\n\nstates::Array{S, 3}: matrix of size nstates x nperiods x nshocks of state shock decompositions\nobs::Array{S, 3}: matrix of size nobs x nperiods x nshocks of observable shock decompositions\npseudo::Array{S, 3}: matrix of size npseudo x nperiods x nshocks of pseudo-observable shock decompositions\n\nwhere nperiods =endindex - startindex + 1`.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.trends-Union{Tuple{System{S}}, Tuple{S}} where S<:AbstractFloat","page":"Forecasting","title":"DSGE.trends","text":"trends(system::System{S}) where {S<:AbstractFloat}\ntrends(system::RegimeSwitchingSystem{S}) where {S<:AbstractFloat}\ntrends(m::AbstractDSGEModel, system::RegimeSwitchingSystem{S},\n                start_date::Dates.Date = date_presample_start(m),\n                end_date::Dates.Date = prev_quarter(date_forecast_start(m)),\n                cond_type::Symbol) where {S<:AbstractFloat}\n\nCompute trend (steady-state) states, observables, and pseudo-observables. The trend is used for plotting shock decompositions. The first method applies to non-regime switching systems, the second to regime-switching systems that do not involve time variation in the CCC or DD vectors, and the third to regime-switching systems with time variation in CCC or DD.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.get_forecast_filename-Tuple{AbstractDSGEModel,Symbol,Symbol,Symbol}","page":"Forecasting","title":"DSGE.get_forecast_filename","text":"get_forecast_filename(m, input_type, cond_type, output_var;\n    pathfcn = rawpath, forecast_string = \"\", fileformat = :jld2)\n\nget_forecast_filename(directory, filestring_base, input_type, cond_type,\n    output_var; forecast_string = \"\", fileformat = :jld2)\n\nNotes\n\nIf input_type == :subset, then the forecast_string is also appended to the\n\nfilenames. If in this case forecast_string is empty, get_forecast_filename throws an error.\n\nIn the second method, directory should be a string of the form \"$saveroot/m990/ss2/forecast/raw/\". (Note that a pathfcn is therefore not required.) filestring_base should be equivalent to the result of filestring_base(m).\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.get_forecast_input_file-Tuple{Any,Any}","page":"Forecasting","title":"DSGE.get_forecast_input_file","text":"get_forecast_input_file(m, input_type)\n\nCompute the appropriate forecast input filenames for model m and forecast input type input_type.\n\nThe default input files for each input_type can be overriden by adding entries to the Dict{Symbol, String} returned from forecast_input_file_overrides(m). For example:\n\noverrides = forecast_input_file_overrides(m)\noverrides[:mode] = \"path/to/input/file.h5\"\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.get_forecast_output_files-Tuple{AbstractDSGEModel,Symbol,Symbol,Array{Symbol,1}}","page":"Forecasting","title":"DSGE.get_forecast_output_files","text":"get_forecast_output_files(m, input_type, cond_type, output_vars;\n    forecast_string = \"\", fileformat = :jld2)\n\nget_forecast_output_files(directory, filestring_base, input_type, cond_type,\n    output_vars; forecast_string = \"\", fileformat = :jld2)\n\nCompute the appropriate output filenames for model m, forecast input type input_type, and conditional type cond_type, for each output variable in output_vars. Returns a dictionary of file names with one entry for each output_var.\n\nArguments\n\nSee forecast_one for descriptions of other non-keyword arguments.\n\nKeyword Arguments\n\nforecast_string::String: subset identifier for when input_type = :subset\nfileformat::Symbol: file extension, without a period. Defaults to :jld2, though :h5 is another common option.\n\nNotes\n\nSee get_forecast_filename for more information.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.get_meansbands_input_file-Tuple{Union{AbstractDSGEModel, AbstractVARModel},Symbol,Symbol,Symbol}","page":"Forecasting","title":"DSGE.get_meansbands_input_file","text":"get_meansbands_input_file(m, input_type, cond_type, output_var;\n    forecast_string = \"\", fileformat = :jld2)\n\nget_meansbands_input_file(directory, filestring_base, input_type, cond_type, output_var;\n    forecast_string = \"\", fileformat = :jld2)\n\nReturns a dictionary of raw forecast output files to read in to compute means and bands.\n\nInputs\n\nMethod 1:\n\nm::AbstractDSGEModel\n\nMethod 2:\n\ndirectory::String: directory location of input files to read\nfilestring_base::Vector{String}: a vector of strings to be added as a suffix. These usually come from model settings for which print = true. It should not include entries for cond_type and input_type (these will be added automatically).\n\nBoth methods:\n\ninput_type::Symbol: See ?forecast_one\ncond_type::Symbol: See ?forecast_one\noutput_var::Symbol: See ?forecast_one\nforecast_string::String: See ?forecast_one\nfileformat: file extension of saved files\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.get_meansbands_output_file-Tuple{Union{AbstractDSGEModel, AbstractVARModel},Symbol,Symbol,Symbol}","page":"Forecasting","title":"DSGE.get_meansbands_output_file","text":"get_meansbands_output_file(m, input_type, cond_type, output_var;\n    forecast_string = \"\", fileformat = :jld2)\n\nget_meansbands_output_file(directory, filestring_base, input_type, cond_type, output_var;\n    forecast_string = \"\", fileformat = :jld2)\n\nReturns a dictionary of raw forecast output files in which to save computed means and bands.\n\nInputs\n\nMethod 1:\n\nm::AbstractDSGEModel: Model object\n\nMethod 2:\n\ndirectory::String: directory location of input files to read\nfilestring_base::Vector{String}: a vector of strings to be added as a suffix. These usually come from model settings for which print=true. It should not include entries for cond_type and input_type (these will be added automatically).\n\nBoth methods:\n\ninput_type::Symbol: See ?forecast_one\ncond_type::Symbol: See ?forecast_one\noutput_vars::Symbol: See ?forecast_one\nforecast_string::String: See ?forecast_one\nfileformat: file extension of saved files\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.get_scenario_filename-Tuple{AbstractDSGEModel,AbstractScenario,Symbol}","page":"Forecasting","title":"DSGE.get_scenario_filename","text":"get_scenario_filename(m, scen::AbstractScenario, output_var;\n    pathfcn = rawpath, fileformat = :jld2, directory = \"\")\n\nGet scenario file name of the form pathfcn(m, \"scenarios\", output_var * filestring * string(fileformat)). If directory is provided (nonempty), then the same file name in that directory will be returned instead.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.get_scenario_input_file-Tuple{AbstractDSGEModel,Scenario}","page":"Forecasting","title":"DSGE.get_scenario_input_file","text":"get_scenario_input_file(m, scen::Scenario)\n\nGet file name of raw scenario targets from inpath(m, \"scenarios\").\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.get_scenario_mb_input_file-Tuple{AbstractDSGEModel,AbstractScenario,Symbol}","page":"Forecasting","title":"DSGE.get_scenario_mb_input_file","text":"get_scenario_mb_input_file(m, scen::AbstractScenario, output_var)\n\nCall get_scenario_filename while replacing forecastut and forecast4q in output_var with forecast.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.get_scenario_mb_output_file-Tuple{AbstractDSGEModel,AbstractScenario,Symbol}","page":"Forecasting","title":"DSGE.get_scenario_mb_output_file","text":"get_scenario_mb_output_file(m, scen::AbstractScenario, output_var;\n    directory = \"\")\n\nCall get_scenario_filename while tacking on \"mb\" to the front of the base file name.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.get_scenario_output_files-Tuple{AbstractDSGEModel,SingleScenario,Array{Symbol,1}}","page":"Forecasting","title":"DSGE.get_scenario_output_files","text":"get_scenario_output_files(m, scen::SingleScenario, output_vars)\n\nReturn a Dict{Symbol, String} mapping output_vars to the raw simulated scenario outputs for scen.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.plot_scenario-Tuple{AbstractDSGEModel,Symbol,Symbol,AbstractScenario}","page":"Forecasting","title":"DSGE.plot_scenario","text":"plot_scenario(m, var, class, scen; title = \"\", kwargs...)\n\nplot_scenario(m, vars, class, scen; untrans = false, fourquarter = false,\n    plotroot = figurespath(m, \"scenarios\"), titles = [], tick_size = 1,\n    kwargs...)\n\nPlot var or vars in deviations from baseline for the alternative scenario specified by key and vint.\n\nInputs\n\nvar::Symbol or vars::Vector{Symbol}: variable(s) to be plotted, e.g. :obs_gdp or [:obs_gdp, :obs_nominalrate]\nclass::Symbol\nscen::AbstractScenario: scenario\n\nKeyword Arguments\n\nuntrans::Bool: whether to plot untransformed (model units) forecast\nfourquarter::Bool: whether to plot four-quarter forecast\nplotroot::String: if nonempty, plots will be saved in that directory\ntitle::String or titles::Vector{String}\ntick_size::Int: x-axis (time) tick size in units of years\nlegend\n\nSee ?histforecast for additional keyword arguments, all of which can be passed into plot_scenario.\n\nOutput\n\np::Plot or plots::OrderedDict{Symbol, Plot}\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.read_bdd_and_unbdd_mb-Tuple{String,String}","page":"Forecasting","title":"DSGE.read_bdd_and_unbdd_mb","text":"read_bdd_and_unbdd_mb(bdd_fn::String, unbdd_fn::String; modal_line::Bool = false)\n\nRead in the bounded and unbounded forecast MeansBands from bdd_fn and unbdd_fn. Create and return a MeansBands with the unbounded means and bounded bands. If modal_line is true, then the unbdd_fn is known to load in a modal forecast but should be treated as having the same input_type as the bounded forecast.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.read_mb-Tuple{String}","page":"Forecasting","title":"DSGE.read_mb","text":"read_mb(fn::String)\n\nread_mb(fn1::String, fn2::String)\n\nread_mb(m, input_type, cond_type, output_var; forecast_string = \"\",\n    use_bdd = :unbdd, modal_line = false, directory = workpath(m, \"forecast\"))\n\nRead in a MeansBands object saved in fn, or use the model object m to determine the file location.\n\nThe second method construct a MeansBands object with means from the modal object and bands, where fn1 is the file location of the bands and fn2 is the file location of the means.\n\nIf bdd_and_unbdd, then output_var must be either :forecast or :forecast4q. Then this function calls read_bdd_and_unbdd to return a MeansBands with unbounded means and bounded bands. If modal line is set to true, then the modal mean rather than the full-distribution mean is returned.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.read_scenario_mb-Tuple{AbstractDSGEModel,AbstractScenario,Symbol}","page":"Forecasting","title":"DSGE.read_scenario_mb","text":"read_scenario_mb(m, scen::AbstractScenario, output_var; directory = \"\")\n\nRead in an alternative scenario MeansBands object.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.read_scenario_output-Tuple{AbstractDSGEModel,SingleScenario,Symbol,Symbol,Symbol}","page":"Forecasting","title":"DSGE.read_scenario_output","text":"read_scenario_output(m, scen::SingleScenario, class, product, var_name)\n\nread_scenario_output(m, agg::ScenarioAggregate, class, product, var_name)\n\nGiven either scen or agg, read in and return all draws of and the appropriate reverse transform for var_name.\n\nThe third function that takes in two models is used for when we have scenarios from two different models.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.write_means_tables_shockdec-Tuple{AbstractDSGEModel,Symbol,Symbol,Symbol}","page":"Forecasting","title":"DSGE.write_means_tables_shockdec","text":"write_means_tables_shockdec(m, input_type, cond_type, class;\n    forecast_string = \"\",\n    read_dirname = workpath(m, \"forecast\"),\n    write_dirname = tablespath(m, \"forecast\"),\n    kwargs...)\n\nwrite_means_tables_shockdec(write_dirname, filestring_base, mb_shockdec,\n    mb_trend, mb_dettrend, mb_hist, mb_forecast; tablevars = get_variables(mb),\n    columnvars = get_shocks(mb), groups = [])\n\nInputs\n\nMethod 1 only:\n\nm::AbstractDSGEModel\ninput_type::Symbol\ncond_type::Symbol\nclass::Symbol\n\nMethod 2 only:\n\nwrite_dirname::String: directory to which tables are saved\nfilestring_base::Vector{String}: the result of filestring_base(m), typically [\"vint=yymmdd\"]`\nmb_shockdec::MeansBands\nmb_trend::MeansBands\nmb_dettrend::MeansBands\nmb_hist::MeansBands: optional\nmb_forecast::MeansBands: optional\n\nKeyword Arguments\n\ntablevars::Vector{Symbol}: which series to write tables for\ncolumnvars::Vector{Symbol}: which shocks to include as columns in the tables\ngroups::Vector{ShockGroup}: if provided, shocks will be grouped accordingly\n\nMethod 1 only:\n\nforecast_string::String\nuse_bdd::Symbol: whether to use unbounded means and bounded bands. Applies only for class(output_var) in [:forecast, :forecast4q]\nread_dirname::String: directory from which MeansBands are read in\nwrite_dirname::String: directory to which tables are saved\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.write_meansbands_tables_all-Tuple{AbstractDSGEModel,Symbol,Symbol,Array{Symbol,1}}","page":"Forecasting","title":"DSGE.write_meansbands_tables_all","text":"write_meansbands_tables_all(m, input_type, cond_type, output_vars;\n    forecast_string = \"\", dirname = tablespath(m, \"forecast\"),\n    vars = [], shocks = [], shock_groups = [])\n\nWrite all output_vars corresponding to model m to tables in dirname.\n\nInputs\n\nm::AbstractDSGEModel\ninput_type::Symbol: See ?forecast_one\ncond_type::Symbol: See ?forecast_one\noutput_vars::Symbol: See ?forecast_one\n\nKeyword Arguments\n\nforecast_string::String: See ?forecast_one\nvars::Vector{Symbol}: Vector of economic variables for which to print output_vars to tables. If omitted, all shocks will be printed.\nshocks::Vector{Symbol}: Vector of shocks to print if output_vars contains a shock decomposition. If omitted, all shocks will be printed.\nshock_groups::Vector{ShockGroup}: if provided, shocks will be grouped accordingly in shockdec tables\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.write_meansbands_tables_timeseries-Tuple{AbstractDSGEModel,Symbol,Symbol,Symbol}","page":"Forecasting","title":"DSGE.write_meansbands_tables_timeseries","text":"write_meansbands_tables_timeseries(m, input_type, cond_type, output_var;\n    forecast_string = \"\", bdd_and_unbdd = false,\n    read_dirname = workpath(m, \"forecast\"),\n    write_dirname = tablespath(m, \"forecast\"), kwargs...)\n\nwrite_meansbands_tables_timeseries(dirname, filestring_base, mb;\n    tablevars = get_variables(mb))\n\nInputs\n\nMethod 1 only:\n\nm::AbstractDSGEModel\ninput_type::Symbol\ncond_type::Symbol\noutput_var::Symbol: class(output_var) must be one of [:hist, :histut, :hist4q, :forecast, :forecastut, :forecast4q, :bddforecast, :bddforecastut, :bddforecast4q, :trend, :dettrend, :histforecast, :histforecastut, :histforecast4q]\nread_dirname::String: directory to which meansbands objects are read from\n\nMethod 2 only:\n\nread_dirname::String: directory from which MeansBands are read in\nwrite_dirname::String: directory to which tables are saved\nfilestring_base::Vector{String}: the result of filestring_base(m), typically [\"vint=yymmdd\"]`\n\nKeyword Arguments\n\ntablevars::Vector{Symbol}: which series to write tables for\n\nMethod 1 only:\n\nforecast_string::String\nbdd_and_unbdd::Bool: whether to use unbounded means and bounded bands. Applies only for class(output_var) in [:forecast, :forecast4q]\ndirname::String: directory to which tables are saved\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.write_ref_trial-Tuple{BenchmarkTools.Trial,String}","page":"Forecasting","title":"DSGE.write_ref_trial","text":"write_ref_trial(trial, trial_name)\n\nWrite a reference trial to a JLD file, to act as the standard that new trials are benchmarked against.\n\nArguments\n\ntrial::BenchmarkTools.Trial: The trial object that is being written.\ntrial_name::String: The name of the trial being written.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.decomposition_forecast-Tuple{AbstractDSGEModel,DataFrames.DataFrame,Array{Float64,1},Symbol,Int64,Int64,Int64}","page":"Forecasting","title":"DSGE.decomposition_forecast","text":"decomposition_forecast(m, df, params, cond_type, keep_startdate, keep_enddate, shockdec_splitdate;\n    outputs = [:forecast, :shockdec], check = false)\n\nEquivalent of forecast_one_draw for forecast decomposition. keep_startdate = date_forecast_start(m_new) corresponds to time T+1, keep_enddate = date_forecast_end(m_old) to time T+H, and shockdec_splitdate = date_mainsample_end(m_old) to time T-k.\n\nReturns out::Dict{Symbol, Array{Float64}}, which has keys determined as follows:\n\nIf :forecast in outputs or check = true:\n:forecast<class>\nIf :shockdec in outputs:\n:trend<class>\n:dettrend<class>\n:data<class>: like a shockdec, but only applying smoothed shocks up to shockdec_splitdate\n:news<class>: like a shockdec, but only applying smoothed shocks after shockdec_splitdate\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.decomposition_periods-Union{Tuple{M}, Tuple{M,M,DataFrames.DataFrame,DataFrames.DataFrame,Symbol,Symbol}} where M<:AbstractDSGEModel","page":"Forecasting","title":"DSGE.decomposition_periods","text":"decomposition_periods(m_new, m_old, df_new, df_old, cond_new, cond_old)\n\nReturns T, k, and H, where:\n\nNew model has T periods of data\nOld model has T-k periods of data\nOld and new models both forecast up to T+H\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.forecast_one_draw-Tuple{AbstractDSGEModel{Float64},Symbol,Symbol,Array{Symbol,1},Array{Float64,1},DataFrames.DataFrame}","page":"Forecasting","title":"DSGE.forecast_one_draw","text":"forecast_one_draw(m, input_type, cond_type, output_vars, params, df;\n    verbose = :low, only_filter = false)\n\nCompute output_vars for a single parameter draw, params. Called by forecast_one.\n\nInputs\n\nm::AbstractDSGEModel{Float64}: model object\ninput_type::Symbol: See ?forecast_one.\ncond_type::Symbol: See ?forecast_one.\noutput_vars::Vector{Symbol}: vector of desired output variables. See Outputs section\nparams::Vector{Float64}: parameter vector\ndf::DataFrame: historical data.\nverbose::Symbol: desired frequency of function progress messages printed to standard out. One of :none, :low, or :high.\n\nOutput\n\nforecast_outputs::Dict{Symbol, Array{Float64}}: dictionary of forecast outputs. Keys are output_vars, which is some subset of:\n\n  - `:histstates`: `Matrix{Float64}` of smoothed historical states\n  - `:histobs`: `Matrix{Float64}` of smoothed historical data\n  - `:histpseudo`: `Matrix{Float64}` of smoothed historical\n    pseudo-observables\n  - `:histshocks`: `Matrix{Float64}` of smoothed historical shocks\n  - `:forecaststates`: `Matrix{Float64}` of forecasted states\n  - `:forecastobs`: `Matrix{Float64}` of forecasted observables\n  - `:forecastpseudo`: `Matrix{Float64}` of forecasted pseudo-observables\n  - `:forecastshocks`: `Matrix{Float64}` of forecasted shocks\n  - `:bddforecaststates`, `:bddforecastobs`, `:bddforecastpseudo`, and\n    `:bddforecastshocks`: `Matrix{Float64}`s of forecasts where we enforce\n    the zero lower bound to be `forecast_zlb_value(m)`\n  - `:shockdecstates`: `Array{Float64, 3}` of state shock decompositions\n  - `:shockdecobs`: `Array{Float64, 3}` of observable shock decompositions\n  - `:shockdecpseudo`: `Array{Float64, 3}` of pseudo-observable shock\n    decompositions\n  - `:dettrendstates`: `Matrix{Float64}` of state deterministic trends\n  - `:dettrendobs`: `Matrix{Float64}` of observable deterministic trends\n  - `:dettrendpseudo`: `Matrix{Float64}` of pseudo-observable deterministic\n    trends\n  - `:trendstates`: `Vector{Float64}` of state trends, i.e. the `CCC` vector\n  - `:trendobs`: `Vector{Float64}` of observable trends, i.e. the `DD` vector\n  - `:trendpseudo`: `Vector{Float64}` of pseudo-observable trends, i.e. the\n    `DD_pseudo` vector\n  - `:irfstates`: `Array{Float64, 3}` of state impulse responses\n  - `:irfobs`: `Array{Float64, 3}` of observable impulse responses\n  - `:irfpseudo`: `Array{Float64, 3}` of pseudo-observable impulse responses\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.prepare_forecast_inputs!-Union{Tuple{S}, Tuple{AbstractDSGEModel{S},Symbol,Symbol,Array{Symbol,1}}} where S<:AbstractFloat","page":"Forecasting","title":"DSGE.prepare_forecast_inputs!","text":"prepare_forecast_inputs!(m, input_type, cond_type, output_vars;\n    df = DataFrame(), verbose = :none)\n\nAdd required outputs using add_requisite_output_vars and load data if necessary.\n\nInputs\n\nm::AbstractDSGEModel: model object\ninput_type::Symbol: See ?forecast_one.\ncond_type::Symbol: See ?forecast_one.\noutput_vars::Vector{Symbol}: vector of desired output variables. See ?forecast_one_draw\n\nKeyword Arguments\n\ndf::DataFrame: historical data. If cond_type in [:semi, :full], then the  final row of df should be the period containing conditional data. If not  provided, then df will be loaded using load_data with the appropriate  cond_type\nonly_filter::Bool: do not run the smoother and only run the filter. This limits the number of output variables which can be calculated.\nverbose::Symbol: desired frequency of function progress messages printed to standard out. One of :none, :low, or :high\n\nOutputs\n\noutput_vars\ndf\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.default_update_regime_eqcond_info!-Tuple{AbstractDSGEModel,AbstractDict{Int64,EqcondEntry},Int64,Int64,AltPolicy}","page":"Forecasting","title":"DSGE.default_update_regime_eqcond_info!","text":"default_update_regime_eqcond_info!(m::AbstractDSGEModel, eqcond_dict::AbstractDict{Int64, EqcondEntry},\n                                   zlb_start_regime::Int64, liftoff_regime::Int64, liftoff_policy::AltPolicy)\n\nis the default method for updating the setting regime_eqcond_info during the automatic endogenous ZLB enforcement as a temporary policy.\n\nThe input eqcond_dict should be a dictionary whose historical/conditional horizon regimes should already be set (and won't be affected by this function. The regimes which will be altered are those for which the temporary ZLB will apply (according to zlb_start_regime and liftoff_regime), and if there is time-varying credibility, forecast regimes past the ZLB.\n\nIn general, other implementations of the update_regime_eqcond_info! function should not change the EqcondEntry during historical/conditional horizon regimes, but any other regimes in the forecast horizon should be/can be set.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.forecast_scenario_draw-Tuple{AbstractDSGEModel,Scenario,System,Int64}","page":"Forecasting","title":"DSGE.forecast_scenario_draw","text":"forecast_scenario_draw(m, scen::Scenario, system, draw_index)\n\nFilter shocks and use them to forecast the draw_indexth draw of scen.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.write_scenario_forecasts-Tuple{AbstractDSGEModel,Dict{Symbol,String},Dict{Symbol,Array{Float64,N} where N}}","page":"Forecasting","title":"DSGE.write_scenario_forecasts","text":"write_scenario_forecasts(m, scenario_output_files, forecast_output;\n    verbose = :low)\n\nWrite scenario outputs in forecast_output to values(scenario_output_files).\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.shock_decompositions_sequence-Union{Tuple{S}, Tuple{AbstractDSGEModel,System{S},Array{S,2}}} where S<:AbstractFloat","page":"Forecasting","title":"DSGE.shock_decompositions_sequence","text":"shock_decompositions_sequence(m, system, histshocks, n_back, back_shocks)\n\nshock_decompositions_sequence(system, forecast_horizons, histshocks, start_index,\n    end_index, n_back, back_shocks)\n\nshock_decompositions_sequence(m, system, histshocks, start_date, end_date, n_back, back_shocks)\n\nshock_decompositions_sequence(m, system, forecast_horizons, histshocks, start_index,\n    end_index, regime_inds, cond_type, n_back, back_shocks)\n\nshock_decompositions_sequence(m, system, old_system,\n                              histshocks, old_histshocks, start_date, end_date,\n                              cond_type; full_shock_decomp, n_back, back_shocks)\n\nshock_decompositions_sequence(m, system, old_system,\n                              forecast_horizons, histshocks, old_histshocks,\n                              start_index, end_index,\n                              regime_inds, cond_type; full_shock_decomp, n_back, back_shocks)\n\nInputs\n\nsystem::System{S} or RegimeSwitchingSystem{S}: state-space system matrices\nforecast_horizons::Int: number of periods ahead to forecast\nhistshocks::Matrix{S}: matrix of size nshocks x hist_periods of historical smoothed shocks\nstart_index::Int: first index from which to return computed shock decompositions\nend_index::Int: last index for which to return computed shock decompositions\nstart_date::Date: initial date for deterministic trends\nend_date::Date: final date for deterministic trends\nregime_inds::Vector{UnitRange}: indices of the data corresponding to each regime.\nold_system::RegimeSwitchingSystem{S}: state-space system matrices for the old model\nold_histshocks::Matrix{S}: matrix of size nshocks x hist_periods of historical smoothed shocks using the old system\nfull_shock_decomp::Bool: If true for old_system case, return difference in shockdecs   between all shocks for the new and old systems. Else, return old system's shocks   with 1 cumulative AIT shock added on.\n\nwhere S<:AbstractFloat.\n\nOutputs\n\nstates::Array{S, 4}: matrix of size nhistperiods x nstates x nperiods x nshocks of state shock decompositions\nobs::Array{S, 4}: matrix of size nhistperiods x nobs x nperiods x nshocks of observable shock decompositions\npseudo::Array{S, 4}: matrix of size nhistperiods x npseudo x nperiods x nshocks of pseudo-observable shock decompositions\n\nwhere nperiods =endindex - startindex + 1andnhistperiods=size(histshocks,2)`\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.combine_raw_forecast_output_and_metadata-Tuple{AbstractDSGEModel,Dict{Symbol,String}}","page":"Forecasting","title":"DSGE.combine_raw_forecast_output_and_metadata","text":"combine_raw_forecast_output_and_metadata(m, forecast_output_files; verbose = :low)\n\nWrites the raw forecast output data (arr) saved in the temporary h5 file to the jld2 file containing the rest of the forecast metadata. The intermediary h5 step exists because jld2 does not support chunked memory assignment in the same way that jld and h5 permitted previously.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.count_scenario_draws!-Tuple{AbstractDSGEModel,Scenario}","page":"Forecasting","title":"DSGE.count_scenario_draws!","text":"count_scenario_draws!(m, scen::Scenario)\n\nReturn the number of draws for scen, determined using get_scenario_input_file(m, scen), and update the n_draws field of scen with this count.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.get_scenario_mb_metadata-Tuple{AbstractDSGEModel,SingleScenario,Symbol}","page":"Forecasting","title":"DSGE.get_scenario_mb_metadata","text":"get_scenario_mb_metadata(m, scen::SingleScenario, output_var)\n\nget_scenario_mb_metadata(m, agg::ScenarioAggregate, output_var)\n\nReturn the MeansBands metadata dictionary for scen.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.load_scenario_targets!-Tuple{AbstractDSGEModel,Scenario,Int64}","page":"Forecasting","title":"DSGE.load_scenario_targets!","text":"load_scenario_targets!(m, scen::Scenario, draw_index)\n\nAdd the targets from the draw_indexth draw of the raw scenario targets to scen.targets.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.read_forecast_metadata-Tuple{JLD2.JLDFile}","page":"Forecasting","title":"DSGE.read_forecast_metadata","text":"read_forecast_metadata(file::JLDFile)\n\nRead metadata from forecast output files. This includes dictionaries mapping dates, as well as state, observable, pseudo-observable, and shock names, to their respective indices in the saved forecast output array. Depending on the output_var, the saved dictionaries might include:\n\ndate_indices::Dict{Date, Int}: not saved for IRFs\nstate_indices::Dict{Symbol, Int}\nobservable_indices::Dict{Symbol, Int}\npseudoobservable_indices::Dict{Symbol, Int}\nshock_indices::Dict{Symbol, Int}\nstate_revtransforms::Dict{Symbol, Symbol}: states are not transformed, so all values are :identity\nobservable_revtransforms::Dict{Symbol, Symbol}\npseudoobservable_revtransforms::Dict{Symbol, Symbol}\nshock_revtransforms::Dict{Symbol, Symbol}: shocks are not transformed, so all values are :identity\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.read_forecast_series-Tuple{String,Symbol,Int64}","page":"Forecasting","title":"DSGE.read_forecast_series","text":"read_forecast_series(filepath, product, var_ind)\nread_forecast_series(filepath, var_ind, shock_ind)\n\nRead only the forecast output for a particular variable (e.g. for a particular observable) and possibly a particular shock. Result should be a matrix of size ndraws x nperiods.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.read_regime_switching_trend-Tuple{String,Int64}","page":"Forecasting","title":"DSGE.read_regime_switching_trend","text":"read_regime_switching_trend(filepath, var_ind)\n\nRead only the trend output for a particular variable (e.g. for a particular observable). Result should be a matrix of size ndraws Ã— n_regimes or ndraws Ã— n_data_periods, depending on whether the state space system was time-varying or not.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.write_forecast_block-Tuple{Any,Array,AbstractRange{Int64}}","page":"Forecasting","title":"DSGE.write_forecast_block","text":"write_forecast_block(file::JLDFile, arr::Array, block_number::Int,\n    block_inds::AbstractRange{Int64})\n\nWrites arr to the subarray of file indicated by block_inds.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.write_forecast_metadata-Tuple{AbstractDSGEModel,JLD2.JLDFile,Symbol}","page":"Forecasting","title":"DSGE.write_forecast_metadata","text":"write_forecast_metadata(m::AbstractDSGEModel, file::JLDFile, var::Symbol)\n\nWrite metadata about the saved forecast output var to filepath.\n\nSpecifically, we save dictionaries mapping dates, as well as state, observable, pseudo-observable, and shock names, to their respective indices in the saved forecast output array. The saved dictionaries include:\n\ndate_indices::Dict{Date, Int}: saved for all forecast outputs except IRFs\nstate_names::Dict{Symbol, Int}: saved for var in [:histstates, :forecaststates, :shockdecstates]\nobservable_names::Dict{Symbol, Int}: saved for var in [:forecastobs, :shockdecobs]\nobservable_revtransforms::Dict{Symbol, Symbol}: saved identifiers for reverse transforms used for observables\npseudoobservable_names::Dict{Symbol, Int}: saved for var in [:histpseudo, :forecastpseudo, :shockdecpseudo]\npseudoobservable_revtransforms::Dict{Symbol, Symbol}: saved identifiers for reverse transforms used for pseudoobservables\nshock_names::Dict{Symbol, Int}: saved for var in [:histshocks, :forecastshocks, :shockdecstates, :shockdecobs, :shockdecpseudo]\n\nNote that we don't save dates or transformations for impulse response functions.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.write_forecast_outputs-Tuple{AbstractDSGEModel,Symbol,Array{Symbol,1},Dict{Symbol,String},Dict{Symbol,Array{Float64,N} where N}}","page":"Forecasting","title":"DSGE.write_forecast_outputs","text":"write_forecast_outputs(m, output_vars, forecast_output_files, forecast_output;\n    df = DataFrame(), block_number = Nullable{Int64}(), block_inds = 1:0,\n    verbose = :low)\n\nWrites the elements of forecast_output indexed by output_vars to file, given forecast_output_files, which maps output_vars to file names.\n\nIf output_vars contains :histobs, data must be passed in as df.\n\n\n\n\n\n","category":"method"},{"location":"forecast/#DSGE.write_meansbands_table-Tuple{String,Array{String,1},MeansBands,DataFrames.DataFrame,Symbol}","page":"Forecasting","title":"DSGE.write_meansbands_table","text":"write_meansbands_table(dirname, filestring_base, mb, df, tablevar)\n\nInputs\n\ndirname::String: directory to which tables are saved. Defaults to tablespath(m, \"forecast\")\nfilestring_base::Vector{String}: the result of filestring_base(m), typically [\"vint=yymmdd\"]`\nmb::MeansBands: used for computing the output file name\ndf::DataFrame: the result of calling one of prepare_meansbands_table_timeseries, prepare_means_table_shockdec, or prepare_means_table, irf\ntablevar::Symbol: used for computing the base output file name\n\n\n\n\n\n","category":"method"},{"location":"license/#License-1","page":"License","title":"License","text":"","category":"section"},{"location":"license/#","page":"License","title":"License","text":"Copyright (c) 2015, Federal Reserve Bank of New York All rights reserved.","category":"page"},{"location":"license/#","page":"License","title":"License","text":"Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:","category":"page"},{"location":"license/#","page":"License","title":"License","text":"Redistributions of source code must retain the above copyright notice, this list of","category":"page"},{"location":"license/#","page":"License","title":"License","text":"conditions and the following disclaimer.","category":"page"},{"location":"license/#","page":"License","title":"License","text":"Redistributions in binary form must reproduce the above copyright notice, this list of","category":"page"},{"location":"license/#","page":"License","title":"License","text":"conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.","category":"page"},{"location":"license/#","page":"License","title":"License","text":"Neither the name of the copyright holder nor the names of its contributors may be used to","category":"page"},{"location":"license/#","page":"License","title":"License","text":"endorse or promote products derived from this software without specific prior written permission.","category":"page"},{"location":"license/#","page":"License","title":"License","text":"THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","category":"page"},{"location":"solving/#solving-dsge-doc-1","page":"Solving the Model","title":"Solving the Model","text":"","category":"section"},{"location":"solving/#The-gensys-routine-1","page":"Solving the Model","title":"The gensys routine","text":"","category":"section"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"The DSGE model is written down in its canonical representation:","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"Gamma_0 s_t = Gamma_1 s_t-1 + C + Psi epsilon_t + Pi eta_t","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"where Gamma_0, Gamma_1, C, Psi, and Pi are matrices of coefficients for s_t (states at time t), s_t-1 (lagged states), epsilon_t (exogenous shocks) and eta_t (expectational shocks).","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"DSGE.jl solves the model to obtain its state-space form:","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"beginaligned\ns_t = T s_t-1 + R epsilon_t + C  epsilon_t sim N(0 Q)  mathrm(transition) \ny_t = Z s_t + D + u_t  u_t sim N(0 E)  mathrm(measurement)\nendaligned","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"using the gensys routine of Chris Sims, introduced in this paper. This algorithm can be easily extended to (exogenous) regime switching. For each regime i, define the canonical matrices Gamma_0 i, Gamma_1 i, C_i, Psi_i, and Pi_i. Calling gensys on each regime and constructing the relevant easurement matrix yields the matrices T_i, R_i, C_i, Q_i, Z_i, D_i, and E_i, which define the state-space form of a DSGE with multiple regimes.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"We provide a standalone native Julia implementation of the routine (gensys) as well as a wrapper for AbstractDSGEModel subtypes (solve). When the Gensys.jl package becomes ready for use, we intend to deprecate our gensys code and substitute the gensysdt method for our code.","category":"page"},{"location":"solving/#solveregswitch-1","page":"Solving the Model","title":"Regime-Switching","text":"","category":"section"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"We allow solving the model with regime-switching in two cases.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"Exogenous and unanticipated regimes\nAlternative policies (permanent and temporary)","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"The first is straightforward to implement because the regimes are exogenous and unanticipated. We simply need to specify the equilibrium conditions in each regime, run gensys for each regime, and return multiple transition equations. The required steps to solve a model with exogenous and unanticipated regime-switching are","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"Write eqcond to accept a second argument specifying the regime, e.g. eqcond(m::MyDSGEModel, reg::Int).","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"To allow no regime-switching, we recommend also writing the wrapper eqcond(m) = eqcond(m, 1) or whatever default regime is desired.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"Add additional keyword arguments to measurement so that it is defined as","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"function measurement(m::MyDSGEModel, TTT::AbstractMatrix{T}, RRR::AbstractMatrix{T}, CCC::AbstractVector{T};\n                     reg::Int = 1, TTTs::Vector{<: AbstractMatrix{T}} = Matrix{T}[],\n                     CCCs::Vector{<: AbstractVector{T}} = Vector{T}[],\n                     information_set::UnitRange = reg:reg,\n                     memo::Union{ForwardMultipleExpectationsMemo, Nothing} = nothing) where {T <: Real}","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"The type assertions for the arrays and keywords are not strictly necessary but are advised. Alternatively, the user could simply set","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"function measurement(m::MyDSGEModel, TTT::AbstractMatrix{T}, RRR::AbstractMatrix{T}, CCC::AbstractVector{T};\n                     kwargs...) where {T <: Real}","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"to avoid problems with forgetting certain kwargs.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"Add the settings and indices required to ensure regime-switching is properly handled.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"See Regime-Switching Forecasts for guidance on how to do this.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"For 1 and 2, we recommend conferring with the implementation of regime-switching for Model 1002. See the equilibrium conditions here and the measurement equation here.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"Temporary alternative policies are slightly more complicated. They leverage the same machinery as exogenous and unanticipated regime-switching, so steps 1 and 2 above are required still. But in addition, we need to specify in which regimes policies should be different than those specified by eqcond, which assumes all policies are permanent ones. Once we have specified these policies, we use the algorithm from Calgiarini and Kulish to calculate the rational expectations solution to a model with `predicted structural changes'', which allows us to specify temporary alternative policies like a temporary ZLB or a temporary switch to average inflation targeting. The function implementing this algorithm isgensys2`.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"DSGE.gensys2","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"See Alternative Policies and the regime-switching example script for guidance on how to use temporary alternative policies.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"DSGE.solve","category":"page"},{"location":"solving/#DSGE.solve","page":"Solving the Model","title":"DSGE.solve","text":"solve(m::AbstractDSGEModel)\n\nDriver to compute the model solution and augment transition matrices.\n\nInputs\n\nm: the model object\n\nKeyword Arguments\n\nregime_switching::Bool: true if the state space system features regime switching\nregimes::Union{Int, Vector{Int}, UnitRange{Int}}: specifies the specific regime to solve for.\n\nOutputs\n\nTTT, RRR, and CCC matrices of the state transition equation:\n\nS_t = TTT*S_{t-1} + RRR*Ïµ_t + CCC\n\n\n\n\n\nsolve(m::PoolModel) ```\n\nDriver to compute the model solution when using the PoolModel type\n\nInputs\n\nm: the PoolModel object\n\nOutputs\n\nÎ¦: transition function\nF_Ïµ: distribution of structural shock\nFÎ»: prior on the initial Î»0\n\n\n\n\n\nsolvect(m::AbstractCTModel; reduction_settings_check::Bool = false)\n\nDriver to compute the model solution and augment transition matrices.\n\nInputs\n\nm: the model object\n\nOutputs\n\nTTT, RRR, and CCC matrices of the state transition equation:  S_t = TTT*S_{t-1} + RRR*Ïµ_t + CCC\n\n\n\n\n\n","category":"function"},{"location":"solving/#The-System-Type-1","page":"Solving the Model","title":"The System Type","text":"","category":"section"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"The solve function only returns the TTT, RRR, and CCC matrices. To obtain the other matrices in the state-space representation of the DSGE, we provide a wrapper function compute_system, which returns an object of type System, whose fields are also special types we have implemented to faciltiate use of the state-space form.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"System\nTransition\nMeasurement\nPseudoMeasurement\ncompute_system","category":"page"},{"location":"solving/#DSGE.System","page":"Solving the Model","title":"DSGE.System","text":"System{T <: Real}\n\nA mutable struct containing the transition and measurement equations for a state-space model. The matrices may be directly indexed: sys[:TTT] returns sys.transition.TTT, sys[:ZZ] returns sys.measurement.ZZ, etc.\n\n\n\n\n\n","category":"type"},{"location":"solving/#DSGE.Transition","page":"Solving the Model","title":"DSGE.Transition","text":"Transition{T<:Real}\n\nThe transition equation of the state-space model takes the form\n\n`s_t = TTT*s_{t-1} + RRR*Ïµ_t + CCC`\n\nThe Transition type stores the coefficient Matrix{T}s (TTT, RRR) and constant Vector{T} CCC.\n\n\n\n\n\n","category":"type"},{"location":"solving/#DSGE.Measurement","page":"Solving the Model","title":"DSGE.Measurement","text":"Measurement{T<:Real}\n\nThe measurement equation of the state-space model takes the form\n\ny_t = ZZ*s_t + DD + u_t\n\nwhere the error u_t is the measurement error, which is uncorrelated with the shocks in the transition equation Ïµ_t.\n\nFields\n\nIf Ns is the number of states s_t, Ny is the number of observables y_t, and Ne is the number of shocks Ïµ_t:\n\nZZ: the Ny x Ns  measurement matrix\nDD: the Ny x 1 constant vector\nQQ: the Ne x Ne covariance matrix for the shocks Ïµ_t\nEE: the Ny x Ny covariance matrix for the measurement error Î·_t\n\n\n\n\n\n","category":"type"},{"location":"solving/#DSGE.PseudoMeasurement","page":"Solving the Model","title":"DSGE.PseudoMeasurement","text":"PseudoMeasurement{T<:Real}\n\nThe pseudo-measurement equation of the state-space model takes the form\n\nx_t = ZZ_pseudo*s_t + DD_pseudo\n\nFields\n\nLet Ns be the number of states s_t and Nx be the number of pseudo-observables x_t:\n\nZZ_pseudo: the Nx x Ns pseudo-measurement matrix\nDD_pseudo: the Nx x 1 constant vector\n\n\n\n\n\n","category":"type"},{"location":"solving/#DSGE.compute_system","page":"Solving the Model","title":"DSGE.compute_system","text":"compute_system(m; tvis::Bool = false, verbose = :high)\ncompute_system_helper(m; tvis::Bool = false, verbose = :high)\n\nGiven the current model parameters, compute the state-space system corresponding to model m. Returns a System or RegimeSwitchingSystem object. The keyword apply_altpolicy indicates whether the state-space system should reflect an alternative policy, and the keyword tvis indicates whether the state-space system involves time-varying information sets. To use tvis = true, at least the setting :tvis_information_set must exist. See ?DSGE.compute_tvis_system for more information about computing state-space systems with time-varying information sets.\n\ncomputesystem just runs computesystem_helper (which actually computes the system) and then in the case of imperfect but positive credibility, adjusts the anticipated observables and pseudo-observables' measurement equations.\n\n\n\n\n\ncompute_system(m::PoolModel{T})\n\nGiven the current model parameters, compute the state-space system corresponding to the PoolModel model m.\n\nOutputs\n\n``` Î¦: state transition function Î¨: likelihood function, given weights on underlying models (the states) and predictive densities FÏµ: structural shock distribution Fu: likelihood function measurement error distribution F_Î»: initial distribution of Î» for state transition function\n\n\n\n\n\ncompute_system(m; apply_altpolicy = false,\n            check_system = false, get_system = false,\n            get_population_moments = false, use_intercept = false,\n            tvis::Bool = false, verbose = :high)\n            compute_system(m, data; apply_altpolicy = false,\n            check_system = false, get_system = false,\n            get_population_moments = false,\n            tvis::Bool = false, verbose = :high)\n\nGiven the current model parameters, compute the DSGE-VAR or DSGE-VECM system corresponding to model m. If a matrix data is also passed, then the VAR is estimated on data using the DSGE m as a prior with weight Î».\n\nKeyword Arguments\n\ncheck_system::Bool: see ?compute_system that takes the input m::AbstractDSGEModel  and system::System.\nget_system::Bool: see Outputs\nget_population_moments::Bool: see Outputs\nuse_intercept::Bool: use an intercept term when computing the OLS estimate of the VAR system.\ntvis::Bool indicates whether the state-space system involves time-varying information sets.\n\nOutputs\n\nIf get_system = true: Returns the updated system whose measurement matrices ZZ, DD, and QQ correspond to the VAR or VECM specified by m. If m is an AbstractDSGEVECMModel, then the system and the vector implied by additional cointegrating relationships are returned as a 2-element tuple.\nIf get_population_moments = true: Returns the limit cross product matrices that describe the DSGE implied   population moments between the observables and their lags. If data is   also passed as an input, then the sample population moments are also returned.\nOtherwise:\n\nReturns Î² and Î£, the coefficients and observables covariance matrix of the VAR or VECM. If data is passed in, then Î² and Î£ are estimated from the data using m as a prior with weight Î». Otherwise, Î² and Î£ comprise the VECM approximation of the DSGE m.\n\n\n\n\n\ncompute_system(m::AbstractDSGEModel, system::System;\nobservables::Vector{Symbol} = collect(keys(m.observables)),\npseudo_observables::Vector{Symbol} = collect(keys(m.pseudo_observables)),\nstates::Vector{Symbol} = vcat(collect(keys(m.endogenou_states)),\ncollect(keys(m.endogenous_states_augmented)))\nshocks::Vector{Symbol} = collect(keys(m.exogenous_shocks)),\nzero_DD = false, zero_DD_pseudo = false)\ncompute_system(m::AbstractDSGEVECMModel, system::System;\nobservables::Vector{Symbol} = collect(keys(m.observables)),\npseudo_observables::Vector{Symbol} = collect(keys(m.pseudo_observables)),\ncointegrating::Vector{Symbol} = collect(keys(m.cointegrating)),\nstates::Vector{Symbol} = vcat(collect(keys(m.endogenou_states)),\ncollect(keys(m.endogenous_states_augmented)))\nshocks::Vector{Symbol} = collect(keys(m.exogenous_shocks)),\nzero_DD = false, zero_DD_pseudo = false)\n\ncomputes the corresponding transition and measurement equations specified by the keywords (e.g. states, pseudo_observables) using the existing ZZ, ZZ_pseudo, and TTT matrices in system.\n\nNote that this function does not update the EE matrix, which is set to all zeros. To incorporate measurement errors, the user must specify the EE matrix after applying compute_system.\n\nKeywords\n\nobservables: variables that should be\n\nentered into the new ZZ and DD matrices. The observables can be both Observables and PseudoObservables, but they must be an element of the system already.\n\npseudo_observables: variables that should be\n\nentered into the new ZZ_pseudo and DD_pseudo matrices. The observables can be both Observables and PseudoObservables, but they must be an element of the system already.\n\ncointegrating: variables that should be\n\nentered into the new ZZ and DD matrices as cointegrating relationships. The observables can be both Observables and PseudoObservables, but they must be an element of the system already.\n\nstates: variables that should be\n\nentered into the new TTT and RRR matrices as states. They must be existing states.\n\nshocks: variables that should be\n\nentered into the new RRR and QQ matrices as shocks. They must be existing exogenous shocks.\n\n\n\n\n\n","category":"function"},{"location":"solving/#The-RegimeSwitchingSystem-Type-1","page":"Solving the Model","title":"The RegimeSwitchingSystem Type","text":"","category":"section"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"When there are multiple (exogenous) regimes in the state-space representation of the DSGE, it is useful to treat the system as one type rather than a vector of individual System objects. The RegimeSwitchingSystem type implements this idea, and via multiple dispatch, most commands that work on a System object also work on a RegimeSwitchingSystem object.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"RegimeSwitchingSystem","category":"page"},{"location":"solving/#DSGE.RegimeSwitchingSystem","page":"Solving the Model","title":"DSGE.RegimeSwitchingSystem","text":"RegimeSwitchingSystem{T <: Real}\n\nA mutable struct containing the transition and measurement equations for a state-space model with regime-switching. The matrices may be directly indexed: sys[1, :TTT] returns sys.regime[1].transition.TTT, etc.\n\n\n\n\n\n","category":"type"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"To get the number of regimes, one can call n_regimes(regime_switch_system) or regime_switch_system[:regimes]. Like a System object, the fields of a RegimeSwitchingSystem can be accessed by","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"regime_switch_system[:transitions]\nregime_switch_system[:measurements]\nregime_switch_system[:pseudo_measurements]","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"A System can be formed from a specific regime by calling","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"sys_reg2 = regime_switch_system[2]","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"and specific matrices/types in a given regime can be accessed by","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"regime_switch_system[2, :TTT]\nregime_switch_system[2, :transition]\nregime_switch_system[2, :measurement]\nregime_switch_system[2, :pseudo_measurement]","category":"page"},{"location":"solving/#tvistype-1","page":"Solving the Model","title":"The TimeVaryingInformationSetSystem Type","text":"","category":"section"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"This type implements a state space system with time-varying information sets. We alter two parts of the RegimeSwitchingSystem.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"First, the transitions field is now a Vector{Vector{Transition}}` because we may need to calculate the transition equations under different information sets. For example, the time-varying transition equations implied by expecting a temporary ZLB to 2023:Q4 in 2020:Q4 will be different than those implied by expecting a temporary ZLB to 2024:Q4. Thus, if the Federal Reserve announced a ZLB to 2023:Q4 in 2020:Q4, and then in 2021:Q1, they announced an extension of the ZLB to 2024:Q4, then the measurement equation needs to calculate two sets of time-varying transition equations.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"Second, we add two new fields, information_set and select. The first specifies which regimes are part of the information set in a given regime. The second specifies which transition equation to use in each regime. Continuing the example of the change in the ZLB length, the regime in the select field for 2020:Q4 would point to the set of transition equations associated with a temporary ZLB to 20203:Q4, while the regime in select for 2021:Q1 would point to the set of transition equations associated with a temporary ZLB to 20204:Q4.","category":"page"},{"location":"solving/#","page":"Solving the Model","title":"Solving the Model","text":"For more guidance, see Time-Varying Information Sets and the example tvis_system.jl, which shows how to work with this type.","category":"page"},{"location":"estimation/#estimation-step-1","page":"Estimation","title":"Estimation","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"CurrentModule = DSGE","category":"page"},{"location":"estimation/#Procedure-1","page":"Estimation","title":"Procedure","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"The goal of the estimation step is to sample from the posterior distribution of the model parameters. DSGE.jl provides two estimation routines. The default is a Metropolis-Hastings sampler to do this, which requires as a proposal covariance matrix and the Hessian matrix corresponding to the posterior mode. The second routine is a Sequential Monte Carlo sampler, which is called from the SMC.jl package. Both routines implement adaptive proposal densities and parameter blocking.[1]","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"The function estimate implements the entire procedure for either routine. Below, we explain the MH algorithm. For documentation of the SMC algorithm, see here.","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"Main Steps:","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"Initialization: Read in and transform raw data from save/input_data/. See Input Data for more details.\nReoptimize parameter vector: The main program will call the csminwel optimization routine (located in csminwel.jl) to find modal parameter estimates.\nCompute Hessian matrix: Computing the Hessian matrix to scale the proposal distribution in the Metropolis-Hastings algorithm.\nSample from Posterior: Posterior sampling is performed using the Metropolis-Hastings algorithm. A proposal distribution is constructed centered at the posterior mode and with proposal covariance scaled by the inverse of the Hessian matrix. Settings for the number of sampling blocks and the size of those blocks can be altered as described in Editing or Extending a Model.","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"Remark: For the MH sampler, in addition to saving each mh_thin-th draw of the parameter vector, the estimation program also saves the resulting posterior value and transition equation matrices implied by each draw of the parameter vector. This is to save time in the forecasting step since that code can avoid recomputing those matrices.","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"For the SMC sampler, we save a jld2 file containing a Cloud object which holds any relevant information about the particles approximating the posterior, the normalized weights of the particles, and the unnormalized weights of particles. We also save a draw of parameters to an h5 file.","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"To run the entire procedure, the user simply calls the estimate routine:","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"DSGE.estimate","category":"page"},{"location":"estimation/#DSGE.estimate","page":"Estimation","title":"DSGE.estimate","text":"estimate(m, data; verbose=:low, proposal_covariance=Matrix())\n\nEstimate the DSGE parameter posterior distribution.\n\nArguments:\n\nm::AbstractDSGEModel or m::AbstractVARModel: model object\n\nEstimation Settings\n\nPlease see the section on 'Estimation Settings' on the 'Advanced Usage' page of the online documentation or src/defaults.jl for a full description of all the estimation settings for both the Metropolis-Hastings (MH) and Sequential Monte Carlo (SMC) algorithms. For the latter, also see ?DSGE.smc2. Most of the optional and keyword arguments described below are not directly related to the behavior of the sampling algorithms (e.g. tuning, number of samples).\n\nOptional Arguments:\n\ndata: well-formed data as Matrix or DataFrame. If this is not provided, the load_data routine will be executed.\n\nKeyword Arguments:\n\nverbose::Symbol: The desired frequency of function progress messages printed to standard out.\n:none: No status updates will be reported.\n:low (default): Status updates will be provided in csminwel and at each block in Metropolis-Hastings. For SMC's verbosity settings, see ?smc2.\n:high: Status updates provided at each iteration in Metropolis-Hastings.\nproposal_covariance::Matrix = []: Used to test the metropolis_hastings algorithm with a precomputed covariance matrix for the proposal distribution. When the Hessian is singular, eigenvectors corresponding to zero eigenvectors are not well defined, so eigenvalue decomposition can cause problems. Passing a precomputed matrix allows us to ensure that the rest of the routine has not broken.\nmethod::Symbol: The method to use when sampling from the posterior distribution. Can   be either :MH for standard Metropolis Hastings Markov Chain Monte Carlo, or :SMC   for Sequential Monte Carlo. This should be specified by the setting sampling_method in m.\nmle = false: Set to true if parameters should be estimated by maximum likelihood directly.   If this is set to true, this function will return after estimating parameters.\nsampling = true: Set to false to disable sampling from the posterior.\nold_data::Matrix{Float64} = []: A matrix containing the time series of observables of previous data   (with data being the new data) for the purposes of a time tempered estimation   (that is, using the posterior draws from a previous estimation as the initial set   of draws for an estimation with new data). Running a bridge estimation   requires both old_data and old_cloud.\nold_cloud::Union{DSGE.ParticleCloud, DSGE.Cloud, SMC.Cloud} = DSGE.Cloud(m, 0): old Cloud object   used to describe particles from a previous estimation with old data. Running a bridge estimation   requires both old_data and old_cloud. If running a bridge estimation and   no old_cloud is provided, then it will be loaded using   the filepaths in m. If no old_cloud exists, then the bridge estimation will not run.\nold_model::Union{AbstractDSGEModel, AbstractVARModel} = m: model object from which we can build   the old log-likelihood function for a time tempered SMC estimation. It should be possible   to evaluate the old log-likelihood given old_data and the current draw of parameters.   This may be nontrivial if, for example, new parameters have been added to m since the old   estimation. In this case, old_model should include the new parameters but still return   the old log-likelihood as the original estimation if given the same old parameters.   By default, we assume the log-likelihood function has not changed   and therefore coincides with the current one.\nfilestring_addl::Vector{String} = []: Additional strings to add to the file name   of estimation output as a way to distinguish output from each other.\ncontinue_intermediate::Bool = false: set to true if the estimation is starting   from an intermediate stage that has been previously saved.\nintermediate_stage_start::Int = 0: number of the stage from which the user wants   to continue the estimation (see continue_intermediate)\nsave_intermediate::Bool = true: set to true to save intermediate stages when using SMC\nintermediate_stage_increment::Int = 10: number of stages that must pass before saving   another intermediate stage.\nrun_csminwel::Bool = true: by default, csminwel is run after a SMC estimation finishes   to recover the true mode of the posterior. Set to false to avoid this step   (csminwel can take hours for medium-scale DSGE models).\ntoggle::Bool = true: when regime-switching, several functions assume regimes   are toggled to regime 1. If the likelihood function is not   written to toggle to regime 1 when done, then regime-switching estimation   will not work properly. Set to false to reduce computation time if the   user is certain that the likelihood is written properly.\nlog_prob_old_data::Float64 = 0.0:Log p(\tilde y) which is the log marginal data density   of the bridge estimation.\n\n\n\n\n\n","category":"function"},{"location":"estimation/#Metropolis-Hastings-Sampler-1","page":"Estimation","title":"Metropolis-Hastings Sampler","text":"","category":"section"},{"location":"estimation/#Computing-the-Posterior-1","page":"Estimation","title":"Computing the Posterior","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"In DSGE.jl, the function posterior computes the value of the posterior distribution at a given parameter vector. It calls the likelihood function, which in turn calls the filter routine. See Estimation routines for more details on these functions.","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"We implement the Kalman Filter via the filter function to compute the log-likelihood, and add this to the log prior to obtain the log posterior. See StateSpaceRoutines.jl for a model-independent implementation of the Kalman filter.","category":"page"},{"location":"estimation/#estimation-reoptimizing-1","page":"Estimation","title":"Optimizing or Reoptimizing","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"Generally, the user will want to reoptimize the parameter vector (and consequently, calculate the Hessian at this new mode) every time they conduct posterior sampling; that is, when:","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"the input data are updated with a new quarter of observations or revised\nthe model sub-specification is changed\nthe model is derived from an existing model with different equilibrium conditions or measurement equation.","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"This behavior can be controlled more finely.","category":"page"},{"location":"estimation/#Reoptimize-from-a-Specified-Starting-Vector-1","page":"Estimation","title":"Reoptimize from a Specified Starting Vector","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"Reoptimize the model starting from the parameter values supplied in a specified file. Ensure that you supply an HDF5 file with a variable named params that is the correct dimension and data type.","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"m = Model990()\nparams = load_parameters_from_file(m, \"path/to/parameter/file.h5\")\nupdate!(m, params)\nestimate(m)","category":"page"},{"location":"estimation/#Skip-Reoptimization-Entirely-1","page":"Estimation","title":"Skip Reoptimization Entirely","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"You can provide a modal parameter vector and optionally a Hessian matrix calculated at that mode to skip the reoptimization entirely. These values are usually computed by the user previously.","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"You can skip reoptimization of the parameter vector entirely.","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"m = Model990()\nspecify_mode!(m, \"path/to/parameter/mode/file.h5\")\nestimate(m)","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"The specify_mode! function will update the parameter vector to the mode and skip reoptimization by setting the reoptimize model setting. Ensure that you supply an HDF5 file with a variable named params that is the correct dimension and data type. (See also the utility function load_parameters_from_file.)","category":"page"},{"location":"estimation/#Random-Walk-Metropolis-Hastings-1","page":"Estimation","title":"Random Walk Metropolis-Hastings","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"For relatively simple problems, a random walk MH sampler is sufficient and avoids unnecessary computations like calculating the Hessian. Suppose we want to estimate all the parameters of a DSGE model m. The following code implements RWMH for m.","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"m = Model990()\nm <= Setting(:hessian_path, \"path/to//matrix/with/right/dimensions/saved/as/mh_hessian.h5\")\nestimate(m; proposal_covariance = Matrix{Float64}(I,size(m.parameters)))","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"The saved Hessian needs to have the same dimensions as the number of parameters. The simplest option is save an identity matrix. The proposal covariance also needs to have the same dimensions as the number of parameters. If the user does not want to estimate every parameter (i.e. some parameters are fixed), then the user needs to zero out the rows of the proposal covariance that correspond to fixed parameters.","category":"page"},{"location":"estimation/#Calculating-the-Hessian-1","page":"Estimation","title":"Calculating the Hessian","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"By default, estimate will recompute the Hessian matrix. You can skip calculation of the Hessian matrix entirely if you provide a file with a Hessian that has been pre-computed.","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"m = Model990()\nspecify_mode!(m, \"path/to/parameter/mode/file.h5\")\nspecify_hessian(m, \"path/to/Hessian/matrix/file.h5\")\nestimate(m)","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"The specify_hessian function will cause estimate to read in the Hessian matrix rather than calculating it directly.  Ensure that you supply an HDF5 file with a variable named hessian that is the correct dimension and data type. Specifying the Hessian matrix but not the parameter mode results in undefined behavior.","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"See [Hessian Approximation] for more details on the Hessian computation.","category":"page"},{"location":"estimation/#Estimation-routines-1","page":"Estimation","title":"Estimation routines","text":"","category":"section"},{"location":"estimation/#Prior,-Likelihood-and-Posterior-calculations-1","page":"Estimation","title":"Prior, Likelihood and Posterior calculations","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"DSGE.prior\nDSGE.likelihood\nDSGE.posterior\nDSGE.posterior!","category":"page"},{"location":"estimation/#ModelConstructors.prior","page":"Estimation","title":"ModelConstructors.prior","text":"prior(m::AbstractDSGEModel{T})\n\nCalculates log joint prior density of m.parameters.\n\n\n\n\n\n","category":"function"},{"location":"estimation/#DSGE.likelihood","page":"Estimation","title":"DSGE.likelihood","text":"likelihood(m::AbstractDSGEModel, data::Matrix{T};\n           sampler::Bool = false, catch_errors::Bool = false) where {T<:AbstractFloat}\n\nEvaluate the DSGE log-likelihood function. Can handle two-part estimation where the observed sample contains both a normal stretch of time (in which interest rates are positive) and a stretch of time in which interest rates reach the zero lower bound. If there is a zero-lower-bound period, then we filter over the 2 periods separately. Otherwise, we filter over the main sample all at once.\n\nArguments\n\nm: The model object\ndata: matrix of data for observables\n\nOptional Arguments\n\nsampler: Whether metropolis_hastings or smc is the caller. If sampler=true, the   transition matrices for the zero-lower-bound period are returned in a dictionary.\ncatch_errors: If sampler = true, GensysErrors should always be caught.\n\n\n\n\n\nlikelihood(m::AbstractVARModel, data::Matrix{T};\n           sampler::Bool = false, catch_errors::Bool = false,\n           verbose::Symbol = :high) where {T<:AbstractFloat}\n\nEvaluate a VAR likelihood function.\n\nArguments\n\nm: The model object\ndata: matrix of data for observables\n\nOptional Arguments\n\nsampler: Whether metropolis_hastings or smc is the caller. If sampler=true, the   transition matrices for the zero-lower-bound period are returned in a dictionary.\ncatch_errors: If sampler = true, GensysErrors should always be caught.\n\n\n\n\n\n","category":"function"},{"location":"estimation/#ModelConstructors.posterior","page":"Estimation","title":"ModelConstructors.posterior","text":"posterior(m::Union{AbstractDSGEModel{T},AbstractVARModel{T}}, data::Matrix{T};\n          sampler::Bool = false, catch_errors::Bool = false,\n          Ï†_smc::Float64 = 1) where {T<:AbstractFloat}\n\nCalculates and returns the log of the posterior distribution for m.parameters:\n\nlog posterior  = log likelihood + log prior + const\nlog Pr(Î˜|data) = log Pr(data|Î˜) + log Pr(Î˜) + const\n\nArguments\n\nm: the model object\ndata: matrix of data for observables\n\nOptional Arguments\n\n-sampler: Whether metropolishastings or smc is the caller. If sampler=true,     the log likelihood and the transition matrices for the zero-lower-bound     period are also returned. -`catcherrors: Whether to catch errors of typeGensysErrororParamBoundsError`\n\nÏ†_smc: a tempering factor to change the relative weighting of the prior and    the likelihood when calculating the posterior. It is used primarily in SMC.\n\n\n\n\n\n","category":"function"},{"location":"estimation/#ModelConstructors.posterior!","page":"Estimation","title":"ModelConstructors.posterior!","text":"posterior!(m::Union{AbstractDSGEModel{T},AbstractVARModel{T}},\n           parameters::Vector{T}, data::Matrix{T};\n           sampler::Bool = false, catch_errors::Bool = false,\n           Ï•_smc::Float64 = 1., toggle::Bool = true) where {T<:AbstractFloat}\n\nEvaluates the log posterior density at parameters.\n\nArguments\n\nm: The model object\nparameters: New values for the model parameters\ndata: Matrix of input data for observables\n\nOptional Arguments\n\nsampler: Whether metropolis_hastings or smc is the caller. If sampler=true,    the log likelihood and the transition matrices for the zero-lower-bound    period are also returned.\ncatch_errors: Whether to catch errors of type GensysError or ParamBoundsError    If sampler = true, both should always be caught.\nÏ•_smc: a tempering factor to change the relative weighting of the prior and    the likelihood when calculating the posterior. It is used primarily in SMC.\ntoggle: if true, we call ModelConstructors.toggle_regime!(values) before   updating any values to ensure the value field of the parameters in values   correspond to regime 1 values.\n\n\n\n\n\n","category":"function"},{"location":"estimation/#Optimization-1","page":"Estimation","title":"Optimization","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"See Optimization","category":"page"},{"location":"estimation/#Full-Estimation-Routine-1","page":"Estimation","title":"Full Estimation Routine","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"See estimate","category":"page"},{"location":"estimation/#Output-Analysis-1","page":"Estimation","title":"Output Analysis","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"Modules = [DSGE]\nPages   = [\"moments.jl\"]\nOrder   = [:function, :type]","category":"page"},{"location":"estimation/#DSGE.compute_EÎ»-Union{Tuple{T}, Tuple{PoolModel{T},Int64,Array{T,1}}, Tuple{PoolModel{T},Int64,Array{T,1},Array{T,2}}, Tuple{PoolModel{T},Int64,Array{T,1},Array{T,2},Array{T,1}}} where T<:AbstractFloat","page":"Estimation","title":"DSGE.compute_EÎ»","text":"compute_EÎ»(m, h, Î»vec, Î¸mat = [], weights = [];\n    current_period = true, parallel = true) where T<:AbstractFloat\n\nComputes and samples from the conditional density p(Î»t|Î¸, It, P) for particle in Î¸s, which represents the posterior distribution.\n\nInputs\n\nm::PoolModel{T}: PoolModel object\nh::Int64: forecast horizon\nÎ»vec::Vector{T}: vector of particles of Î» samples from (Î¸,Î») joint distribution\n`Î¸mat::Matrix{T}': matrix of posterior parameter samples\nweights::Vector{T}: weights of Î» particles, defaults to equal weights\n\nKeyword Argument\n\ncurrent_period::Bool: compute EÎ» for current period t\nparallel::Bool: use parallel computing to compute and sample Î»\nget_dpp_pred_dens::Bool: compute predictive densities according to dynamic prediction pools\n\nOutputs\n\nÎ»hat_tplush::Float64: E[Î»{t+h|t} | It^P, P]\nÎ»hat_t::Float64: E[Î»{t|t} | It^P, P]\n\n```\n\n\n\n\n\n","category":"method"},{"location":"estimation/#DSGE.find_density_bands-Union{Tuple{T}, Tuple{AbstractArray,Array{T,1}}} where T<:AbstractFloat","page":"Estimation","title":"DSGE.find_density_bands","text":"find_density_bands(draws::Matrix, percents::Vector{T}; minimize::Bool=true) where T<:AbstractFloat\n\nReturns a 2 x cols(draws) matrix bands such that percent of the mass of draws[:,i] is above bands[1,i] and below bands[2,i].\n\nArguments\n\ndraws: Matrix of parameter draws (from Metropolis-Hastings, for example)\npercent: percent of data within bands (e.g. .9 to get 90% of mass within bands)\n\nOptional Arguments\n\nminimize: if true, choose shortest interval, otherwise just chop off lowest and highest (percent/2)\n\n\n\n\n\n","category":"method"},{"location":"estimation/#DSGE.find_density_bands-Union{Tuple{T}, Tuple{AbstractArray,T}} where T<:AbstractFloat","page":"Estimation","title":"DSGE.find_density_bands","text":"find_density_bands(draws::Matrix, percent::AbstractFloat; minimize::Bool=true)\n\nReturns a 2 x cols(draws) matrix bands such that percent of the mass of draws[:,i] is above bands[1,i] and below bands[2,i].\n\nArguments\n\ndraws: ndraws by nperiods matrix of parameter draws (from Metropolis-Hastings, for example)\npercent: percent of data within bands (e.g. .9 to get 90% of mass within bands)\n\nOptional Arguments\n\nminimize: if true, choose shortest interval, otherwise just chop off lowest and highest (percent/2)\n\n\n\n\n\n","category":"method"},{"location":"estimation/#DSGE.load_posterior_moments-Tuple{AbstractDSGEModel}","page":"Estimation","title":"DSGE.load_posterior_moments","text":"function load_posterior_moments(m; load_bands = true, include_fixed = false)\n\nLoad posterior moments (mean, std) of parameters for a particular sample, and optionally also load 5% and 95% lower and upper bands.\n\nKeyword Arguments\n\ncloud::ParticleCloud: Optionally pass in a cloud that you want to load the sample from. If the cloud is non-empty then the model object will only be used to find fixed indices and parameter tex labels\nload_bands::Bool: Optionally include the 5% and 95% percentiles for the sample of parameters in the returned df\ninclude_fixed::Bool: Optionally include the fixed parameters in the returned df\nexcl_list::Vector{Symbol}: List parameters by their key that you want to exclude from\n\nloading\n\nOutputs\n\ndf: A dataframe containing the aforementioned moments/bands\n\n\n\n\n\n","category":"method"},{"location":"estimation/#DSGE.moment_tables-Tuple{AbstractDSGEModel}","page":"Estimation","title":"DSGE.moment_tables","text":"moment_tables(m; percent = 0.90, subset_inds = 1:0, subset_string = \"\",\n    groupings = Dict{String, Vector{Parameter}}(), use_mode = false,\n    tables = [:prior_posterior_means, :moments, :prior, :posterior],\n    caption = true, outdir = \"\", verbose = :none)\n\nComputes prior and posterior parameter moments. Tabulates prior mean, posterior mean, and bands in various LaTeX tables. These tables will be saved in outdir if it is nonempty, or else in tablespath(m, \"estimate\").\n\nInputs\n\nm::AbstractDSGEModel: model object\n\nKeyword Arguments\n\npercent::AbstractFloat: the percentage of the mass of draws from Metropolis-Hastings included between the bands displayed in output tables.\nsubset_inds::AbstractRange{Int64}: indices specifying the draws we want to use\nsubset_string::String: short string identifying the subset to be appended to the output filenames. If subset_inds is nonempty but subset_string is empty, an error is thrown\ngroupings::Dict{String, Vector{Parameter}}: see ?parameter_groupings\nuse_mode::Bool: use the modal parameters instead of the mean in the priorposteriormeans table\ntables::Vector{Symbol}: which tables to produce\ncaption::Bool: whether to include table captions\noutdir::String: where to save output tables\nverbose::Symbol: desired frequency of function progress messages printed to standard out. One of :none, :low, or :high\n\n\n\n\n\n","category":"method"},{"location":"estimation/#DSGE.sample_Î»-Union{Tuple{S}, Tuple{PoolModel{S},Array{S,2},Array{S,2}}, Tuple{PoolModel{S},Array{S,2},Array{S,2},Int64}} where S<:AbstractFloat","page":"Estimation","title":"DSGE.sample_Î»","text":"sample_Î»(m, pred_dens, Î¸s, T = -1; parallel = true) where S<:AbstractFloat\nsample_Î»(m, pred_dens, T = -1; parallel = true) where S<:AbstractFloat\n\nComputes and samples from the conditional density p(Î»t|Î¸, It, P) for particle in Î¸s, which represents the posterior distribution. The sampled Î» particles represent the posterior distribution p(Î»{t|t} | It, P).\n\nIf no posterior distribution is passed in, then the function computes the distribution of Î»_{t|t} for a static pool.\n\nInputs\n\nm::PoolModel{S}: PoolModel object\npred_dens::Matrix{S}: matrix of predictive densities\nÎ¸s::Matrix{S}: matrix of particles representing posterior distribution of Î¸\nT::Int64: final period for tempered particle filter\n\nwhere S<:AbstractFloat.\n\nKeyword Argument\n\nparallel::Bool: use parallel computing to compute and sample draws of Î»\n\nOutputs\n\nÎ»_sample::Vector{Float64}: sample of draws of Î»s; together with (Î¸,Î») represents a joint density\n\n```\n\n\n\n\n\n","category":"method"},{"location":"estimation/#DSGE.moments-Tuple{ModelConstructors.Parameter}","page":"Estimation","title":"DSGE.moments","text":"moments(Î¸::Parameter)\n\nIf Î¸'s prior is a RootInverseGamma, Ï„ and Î½. Otherwise, returns the mean and standard deviation of the prior. If Î¸ is fixed, returns (Î¸.value, 0.0).\n\n\n\n\n\n","category":"method"},{"location":"estimation/#DSGE.posterior_table-Tuple{AbstractDSGEModel,Array{T,1} where T,Array{T,2} where T}","page":"Estimation","title":"DSGE.posterior_table","text":"posterior_table(m, post_means, post_bands; percent = 0.9, subset_string = \"\",\n    groupings = Dict{String, Vector{Parameter}}(), caption = true, outdir = \"\")\n\n\n\n\n\n","category":"method"},{"location":"estimation/#DSGE.prior_posterior_moments_table-Tuple{AbstractDSGEModel,Array{T,1} where T,Array{T,2} where T}","page":"Estimation","title":"DSGE.prior_posterior_moments_table","text":"prior_posterior_moments_table(m, post_means, post_bands; percent = 0.9,\n    subset_string = \"\", groupings = Dict{String, Vector{Parameter}}(),\n    caption = true, outdir = \"\")\n\nProduces a table of prior means, prior standard deviations, posterior means, and 90% bands for posterior draws.\n\n\n\n\n\n","category":"method"},{"location":"estimation/#DSGE.prior_posterior_table-Tuple{AbstractDSGEModel,Array{T,1} where T}","page":"Estimation","title":"DSGE.prior_posterior_table","text":"prior_posterior_table(m, post_values; subset_string = \"\",\n    groupings = Dict{String, Vector{Parameter}}(), use_mode = false,\n    caption = true, outdir = \"\")\n\nProduce a table of prior means and posterior means or mode.\n\n\n\n\n\n","category":"method"},{"location":"estimation/#DSGE.prior_table-Tuple{AbstractDSGEModel}","page":"Estimation","title":"DSGE.prior_table","text":"prior_table(m; subset_string = \"\", groupings = Dict{String, Vector{Parameter}}(),\n    caption = true, outdir = \"\")\n\n\n\n\n\n","category":"method"},{"location":"estimation/#DSGE.propagate_Î»-Union{Tuple{T}, Tuple{T,Int64,PoolModel}, Tuple{T,Int64,PoolModel,Any}} where T<:AbstractFloat","page":"Estimation","title":"DSGE.propagate_Î»","text":"propgate_Î»(Î»vec, h, m, Î¸vec) where T<:AbstractFloat\n\nPropagates a Î» particle h periods forward.\n\nInputs\n\nÎ»::T: Î» sample from (Î¸,Î») joint distribution\nh::Int64: forecast horizon\nm::PoolModel: PoolModel object\nÎ¸vec::Vector{T}: optional vector of parameters to update PoolModel\n\n```\n\n\n\n\n\n","category":"method"},{"location":"estimation/#SMC-Sampler-1","page":"Estimation","title":"SMC Sampler","text":"","category":"section"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"See here for the settings adjusting the SMC algorithm. To use these with a DSGE model object, either add them after the definition of a model object as a Setting or add them directly in the definition of the model type. For example, the following code sets the sampler as SMC and the number of particles used by SMC as 10,000:","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"m = Model990()\nm <= Setting(:sampling_method, :SMC)\nm <= Setting(:n_particles, 10000)","category":"page"},{"location":"estimation/#","page":"Estimation","title":"Estimation","text":"[1]: We document the details of implementing adaptive proposal densities and   parameter blocking in SMC.jl.","category":"page"},{"location":"plotting/#plotting-doc-1","page":"Plotting","title":"Plotting","text":"","category":"section"},{"location":"plotting/#","page":"Plotting","title":"Plotting","text":"CurrentModule = DSGE","category":"page"},{"location":"plotting/#","page":"Plotting","title":"Plotting","text":"The DSGE plotting code uses Plots. We typically use GR and Plotly as backends; however, the goal of Plots is that all backends should be supported interchangeably. In each of the functions listed below, there are methods which take in an AbstractModel and those which take in some lower-level input arguments (typically one or more MeansBands). See the individual function docstring for details.","category":"page"},{"location":"plotting/#Plotting-Estimation-Results-1","page":"Plotting","title":"Plotting Estimation Results","text":"","category":"section"},{"location":"plotting/#","page":"Plotting","title":"Plotting","text":"plot_prior_posterior: plot the prior distribution overlaid on a histogram of posterior draws","category":"page"},{"location":"plotting/#Plotting-Forecasts-1","page":"Plotting","title":"Plotting Forecasts","text":"","category":"section"},{"location":"plotting/#","page":"Plotting","title":"Plotting","text":"plot_history_and_forecast: plot a historical and forecasted series, possibly with uncertainty bands (if for a full-distribution forecast)\nplot_forecast_comparison: plot two sets of histories and forecasts in one plot\nhair_plot: plot many forecasts as \"hairs\" coming out of some realized data series\nplot_shock_decomposition: plot the contributions of individual shocks as a bar plot, with a line for the detrended mean forecast\nplot_impulse_response: plot impulse response functions","category":"page"},{"location":"plotting/#Other-Plots-1","page":"Plotting","title":"Other Plots","text":"","category":"section"},{"location":"plotting/#","page":"Plotting","title":"Plotting","text":"plot_altpolicies: plot forecasts under several alternative policies in one plot\nplot_scenario: plot a forecast conditional on some alternative scenario, in deviations from some baseline","category":"page"},{"location":"frbny_data/#frbny-data-1","page":"FRBNY Model Input Data","title":"New York Fed DSGE Model 990 Data","text":"","category":"section"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"CurrentModule = DSGE","category":"page"},{"location":"frbny_data/#Data-Series-1","page":"FRBNY Model Input Data","title":"Data Series","text":"","category":"section"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"The New York Fed DSGE Model takes an CSV file containing a matrix of data as input. The columns of this file contain transformations of the following series (the number corresponds to the column of data matrix):","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Output Growth (Bureau of Economic Analysis)\nHours Worked (Bureau of Labor Statistics)\nReal Wage Growth (Bureau of Labor Statistics)\nInflation (GDP Deflator) (Bureau of Economic Analysis)\nInflation (Core PCE) (Bureau of Economic Analysis)\nFederal Funds Rate (Board of Governors of the Federal Reserve System)\nConsumption Growth (Bureau of Economic Analysis)\nInvestment Growth (Bureau of Economic Analysis)\nSpread (Baa) (Board of Governors of the Federal Reserve System)\n10-year Inflation Expectations (Federal Reserve Bank of Philadelphia)\n10-year Interest Rate (Board of Governors of the Federal Reserve System)\nTotal Factor Productivity (Federal Reserve Bank of San Francisco)","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"The following series are used to transform some series into per capita terms:","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Civilian Noninstitutional Population 16 Years and Over (Bureau of Labor Statistics)","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Most data series used to construct the above are retrieved from FRED (Federal Reserve Bank of St. Louis). Other data sources include:","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"The Total Factor Productivity series components are made available by the Federal Reserve   Bank of San Francisco, and can be found   here (series   alpha and dtfp from the linked spreadsheet). Alternatively, they can be   found as series TFPJQ@USECON (alpha) and TFPKQ@USECON (dtfp) via Haver Analytics. For more details on the series, see","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Fernald, John. \"A Quarterly, Utilization-Adjusted Series on Total Factor Productivity.\"\nFederal Reserve Bank of San Francisco Working Paper 19 (2012): 20912.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"The 10-year Inflation Expectations series from the Survey of Professional   Forecasters is made available by the Federal Reserve Bank of Philadelphia, and   can be found   here   (series INFCPI10YR from the linked spreadsheet). Alternatively, it can be found as series   ASACX10@SURVEYS via Haver Analytics.\nThe 10-year Treasury Yield (zero-coupon, continuously compounded) series is made   available by the Board of Governors of the Federal Reserve System, and can be found   here (series SVENY10   from the linked spreadsheet). Alternatively, it can be found as series FYCCZA@DAILY via Haver   Analytics. For more details on the series, see","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Gurkaynak, Refet S., Brian Sack, and Jonathan H. Wright. \"The U.S. Treasury Yield Curve:\n1961 to the Present.\" Journal of Monetary Economics 54.8 (2007): 2291-2304.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"For additional details on the series, including mnemonics and transformations used, please see Appendix A.I of","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Del Negro, Marco, Marc P. Giannoni, and Frank Schorfheide. \"Inflation in the\nGreat Recession and New Keynesian Models.\" American Economic Journal:\nMacroeconomics 7.1 (2015): 168-196.","category":"page"},{"location":"frbny_data/#Interest-Rate-Expectations-Data-1","page":"FRBNY Model Input Data","title":"Interest Rate Expectations Data","text":"","category":"section"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"In our model (as used to compute the forecasts referenced in Liberty Street Economics posts), we treat the zero lower bound by adding anticipated policy shocks and data on the market-implied Federal Funds rate path. We do this by giving the model the market-implied Federal Funds rate path for the next n_anticipated_shocks quarters and forcing the model's interest rate path to hit those values in those quarters. Afterwards, the path is unconstrained. The model is trained on data that includes six quarters of interest rate expectations. The user is responsible for procuring interest rate expectations and appending it to the provided sample data set, as discussed in this documentation.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"To use anticipated policy shocks during a forecast, a conditional forecast has to be run, and interest rate expectations must be added as conditional observables to the setting :cond_full_names for full-conditional forecasts and :cond_semi_names for semi-conditional forecasts. The reason is that if the forecast is unconditional, only data up to the last period before the first forecast period will be used. Since the current quarter is typically part of the forecast horizon (e.g. current quarter GDP is not known yet), interest rate expectations in the current quarter have to be treated as conditional data.","category":"page"},{"location":"frbny_data/#Implementation-1","page":"FRBNY Model Input Data","title":"Implementation","text":"","category":"section"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"If you are able to access data on the market-implied FFR path (or another form of interest rate expectations), you can augment the sample dataset or your own dataset to enable the anticipated policy shocks feature. We use internal data from the Federal Reserve Board on the implied Federal Funds Rate derived from OIS quotes. (One could also use interest rate expectations from Blue Chip Financial Forecasts or Survey of Professional Forecasters.)","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Step 1. Choose a value for n_anticipated_shocks (we suggest 6):","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"m <= Setting(:n_anticipated_shocks, 6, true, \"nant\", \"Number of ant. pol. shocks\")","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Step 2. Add implied FFR data to the data matrix:","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"2a. Append n_anticipated_shocks columns of NaN values to the end of the        data matrix.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"2b. Construct a matrix of data, say ImpliedFFR, on anticipated policy        shocks. Define","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"For t from first quarter ZLB binds to last quarter ZLB binds\n   For h from 1 quarter ahead to n_anticipated_shocks quarters ahead\n       ImpliedFFR[t,h] := FFR at horizon h quarters ahead implied as of quarter t.\n   End\nEnd","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"2c. Fill in the data matrix with the ImpliedFFR matrix. The first    row of the ImpliedFFR matrix should go in the row of the data matrix in    which the ZLB first bound and the last row of the ImpliedFFR matrix should    go in the row of the data matrix in which the ZLB last bound.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Step 3. With your updated input data matrix, the code will add the appropriate   number of states, shocks, equilibrium condition equations, and measurement   equations.","category":"page"},{"location":"frbny_data/#Discussion-1","page":"FRBNY Model Input Data","title":"Discussion","text":"","category":"section"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"The implementation of anticipated policy shocks may not be immediately clear. Consider the following made-up data matrix:","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"t GDP FFR Inf ... Spread ImpFFR_1 ... ImpFFR_H\n1960Q1 2.5 5.0 2.5 ... 1.5 NaN ... NaN\n1960Q2 2.2 5.2 1.5 ... 1.3 NaN ... NaN\n... ... ... ... ... ... ... ... ...\n2008Q3 1.1 2.2 1.0 ... 1.5 NaN ... NaN\n2008Q4 -4.5 2.0 2.0 ... 1.3 1.0 ... 1.5\n... ... ... ... ... ... ... ... ...\n2013Q1 2.2 0.2 1.7 ... 1.7 0.2 ... 1.5\n2013Q2 2.3 0.2 1.8 ... 1.6 0.2 ... 1.4","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Interpret this as follows:","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"For periods before 2008Q4, there was no forward guidance or ZLB to enforce, and we have no implied FFR values to enter.\nIn 2008Q4, actual FFR (made-up) was 2.2. Market prices implied that markets expected an interest rate of 1.0 in 2009Q1 â€“ 1 period from now â€“ and 1.5 n_anticipated_shocks periods from 2008Q4.\nIn 2013Q2, actual FFR (made-up) was 0.2. Markets expected FFR to remain at 0.2 in 2013Q3, ..., and expected FFR of 1.4 n_anticipated_shocks periods from 2013Q2.","category":"page"},{"location":"frbny_data/#References-1","page":"FRBNY Model Input Data","title":"References","text":"","category":"section"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"For a more comprehensive treatment of anticipated policy shocks, see NY Fed Staff Report The FRBNY DSGE Model","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"page 12, for how the anticipated policy shocks are incorporated into the monetary policy rule,\npage 16, for how the anticipated policy shocks entered the log-linear equilibrium conditions,\npage 18, for how the anticipated policy shocks and data on market expectations enter the measurement equation,\npage 23, for how the anticipated policy shocks propagate through the model.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"For more in depth discussion of anticipated policy shocks/forward guidance and the impact on the macroeconomy, see NY Fed Working Paper The Forward Guidance Puzzle by Marco Del Negro, Marc Giannoni, and Christina Patterson.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Thanks to Matthew Cocci for the Discussion.","category":"page"},{"location":"frbny_data/#Disclaimer-1","page":"FRBNY Model Input Data","title":"Disclaimer","text":"","category":"section"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"The sample input data provided with DSGE.jl is made available for purposes of demonstrating the function of the model only. By using the data you acknowledge and agree to the following terms and conditions. If you do not agree to these terms and conditions, do not use the data provided with the model.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Some data provided with DSGE.jl may be copyrighted by its owner, and permission to use such copyrighted materials other than to demonstrate the functioning of DSGE.jl for your personal use must be obtained from the owner. The Federal Reserve Bank of New York cannot provide permission to use the data other than as permitted in this agreement.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"You may not use the name of the Federal Reserve Bank of New York to endorse or promote products derived from the use of the data provided with DSGE.jl, nor for any other commercial purpose.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"The Federal Reserve Bank of New York does not guarantee the completeness or accuracy of the data and does not provide updates or corrections to the data provided with the model. By downloading and using the data, you acknowledge and agree that your use of the data is at your own risk and that none of the parties involved in creating, producing or delivering DSGE.jl is liable for any loss, injury, claim, liability or damage of any kind resulting in any way from: (a) any errors in or omissions from the data; (b) your use of the data or any conclusions you draw from it, regardless of whether you received any assistance from the Federal Reserve Bank of New York or its employees with regard to the data; or (c) the files containing the data or use of the website from which the data files were downloaded, including anything caused by any viruses, bugs or malfunctions.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"ALL DATA AND MATERIALS ARE PROVIDED ON AN \"AS IS\", \"AS AVAILABLE\" BASIS WITHOUT WARRANTY OF ANY KIND. THE FEDERAL RESERVE BANK OF NEW YORK EXPRESSLY DISCLAIMS ALL WARRANTIES EXPRESS AND IMPLIED, INCLUDING WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE, QUALITY AND NON-INFRINGEMENT. NEITHER THE FEDERAL RESERVE BANK OF NEW YORK NOR ANY EMPLOYEE OR AFFILIATE SHALL BE LIABLE FOR ANY DIRECT, INDIRECT, SPECIAL OR CONSEQUENTIAL DAMAGES OF ANY KIND WHATSOEVER (INCLUDING, WITHOUT LIMITATION, DAMAGES FOR LOSS OF PROFITS, BUSINESS INTERRUPTION, LOSS OF INFORMATION, OR ATTORNEYS' FEES) IN ANY WAY DUE TO, RESULTING FROM OR ARISING IN CONNECTION WITH THE USE OR PERFORMANCE OF, OR INABILITY TO USE DATA OR MATERIALS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, AND REGARDLESS OF THE NEGLIGENCE OF THE BANK OR ANY EMPLOYEE OR AFFILIATE, EVEN IF THE FEDERAL RESERVE BANK OF NEW YORK HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Reference to any specific commercial product, process or service does not constitute or imply its endorsement, recommendation or favoring by the Federal Reserve Bank of New York.","category":"page"},{"location":"frbny_data/#","page":"FRBNY Model Input Data","title":"FRBNY Model Input Data","text":"Company and product names mentioned in connection with the data remain the trademark and property of their respective owners.","category":"page"},{"location":"#DSGE.jl-1","page":"Home","title":"DSGE.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"CurrentModule = DSGE","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The DSGE.jl package implements the New York Fed DSGE model and provides general code to estimate many user-specified DSGE models. The package is introduced in the Liberty Street Economics blog post The FRBNY DSGE Model Meets Julia.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"This Julia-language implementation mirrors the MATLAB code included in the Liberty Street Economics blog post The FRBNY DSGE Model Forecast.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The New York Fed DSGE team is currently working on adding methods to solve nonlinear and heterogeneous agent DSGE models. Extensions of the DSGE model code may be released in the future at the discretion of the New York Fed.","category":"page"},{"location":"#Table-of-Contents-1","page":"Home","title":"Table of Contents","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Pages = [\n  \"learning_how_to_use_dsgejl.md\",\n  \"model_design.md\",\n  \"special_model_types.md\",\n  \"model_implementation_details.md\",\n  \"running_existing_model.md\",\n  \"input_data.md\",\n  \"frbny_data.md\",\n  \"solving.md\",\n  \"estimation.md\",\n  \"forecast.md\",\n  \"irf.md\",\n  \"means_bands.md\",\n  \"altpolicy.md\",\n  \"scenarios.md\",\n  \"forecast_decomposition.md\",\n  \"plotting.md\",\n  \"algorithms.md\",\n  \"advanced_usage.md\",\n  \"contributing.md\",\n  \"MatlabToJuliaTransition.md\",\n  \"julia_forecasting.md\",\n  \"license.md\"\n]","category":"page"},{"location":"#Acknowledgments-1","page":"Home","title":"Acknowledgments","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Developers of this package at the New York Fed include","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Michael Cai\nWilliam Chen\nShlok Goyal\nAbhi Gupta\nAlissa Johnson\nPearl Li\nEthan Matlin\nErica Moszkowski\nReca Sarfati\nMicah Smith","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Contributors to this package at QuantEcon include","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Zac Cranko\nSpencer Lyon\nPablo Winant","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The gensys and csminwel routines DSGE.gensys and DSGE.csminwel are based on routines originally copyright Chris Sims. The files are released here with permission of Chris Sims under the BSD-3 License.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The kalman_filter routine is loosely based on a version of the Kalman filter algorithm originally copyright Federal Reserve Bank of Atlanta and written by Iskander Karibzhanov. The files are released here with permission of the Federal Reserve Bank of Atlanta under the BSD-3 License.","category":"page"},{"location":"means_bands/#means-bands-1","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"","category":"section"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"CurrentModule = DSGE","category":"page"},{"location":"means_bands/#Procedure-1","page":"Computing Means and Bands","title":"Procedure","text":"","category":"section"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"After running a full-distribution forecast, we are often interested in finding means and density bands of the various forecast outputs. This will allow us to plot our estimation of the full distribution of the forecast outputs.","category":"page"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"Main Steps:","category":"page"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"Load data: Load and transform data, population data, and population forecast (required for forecast output transformations)\nRead in forecast outputs: Read in the outputs saved by forecast_one, one variable (e.g. one observable) and one output_type at a time.\nTransform forecast outputs: If necessary, use reverse_transform to apply transformations specified in the Observable or PseudoObservable type to the given forecast output series.\nCompute means and bands: Compute the means and density bands of the forecast output.\nWrite to file: For each output_var, Write a MeansBands object (see The MeansBands Type below) to the file specified by get_meansbands_output_file.","category":"page"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"Computing means and bands is done by calling compute_meansbands. If desired, you can also write your computed means and bands as matrices by calling meansbands_matrix_all.","category":"page"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"For example, to compute means and bands for an unconditional, full-distribution forecast of states and observables:","category":"page"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"m = AnSchorfheide()\ncompute_meansbands(m, :mode, :none, [:forecaststates, forecastobs])","category":"page"},{"location":"means_bands/#Weighted-Averages-of-Full-Distribution-Forecasts-1","page":"Computing Means and Bands","title":"Weighted Averages of Full-Distribution Forecasts","text":"","category":"section"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"Sometimes a forecaster may want to combine several different \"scenarios\" to construct a forecast. For example, there may be uncertainty about the right model to use. Rather than pick just one model, a forecaster would instead want to somehow combine the forecasts from all the models. As another example, a forecaster may not be sure what policies will be implemented in the future, so it may be easier to forecast the future by constructing different plausible scenarios.","category":"page"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"We implement forecast combination as a weighted average of forecast paths drawn from different forecasts. A full-distribution forecast is just a matrix of different possible forecast paths, which approximate the true distribution of forecast paths. To construct a weighted average of forecasts from different scenarios, we just need to draw randomly from each scenario's distribution of forecast paths.","category":"page"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"For example, suppose m1, m2, m3 are three different models with unconditional forecasts identified by forecast_string1, forecast_string2, and forecast_string3. Then an equal weighted average of these forecasts identified by the tag combo_forecast_string can be calculated by running","category":"page"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"input_types = [:full, :full, :full]\ncond_types = [:none, :none, :none]\ncompute_meansbands([m1, m2, m3], input_types, cond_types, output_vars;\n                        weights = [1/3, 1/3, 1/3],\n                        forecast_strings = [forecast_string1, forecast_string2, forecast_string3],\n                        combo_forecast_string = combo_forecast_string)","category":"page"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"The results are saved using the file paths implied by the first model in the vector of models passed as the first input argument (m1). To get the resulting MeansBands, run","category":"page"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"mb = read_mb(m1, :full, :none, output_var; forecast_string = combo_forecast_string)","category":"page"},{"location":"means_bands/#Functions-for-Calculating-Means-and-Bands-1","page":"Computing Means and Bands","title":"Functions for Calculating Means and Bands","text":"","category":"section"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"compute_meansbands","category":"page"},{"location":"means_bands/#DSGE.compute_meansbands","page":"Computing Means and Bands","title":"DSGE.compute_meansbands","text":"compute_meansbands(m, input_type, cond_type, output_vars; forecast_string = \"\",\n    verbose = :low, kwargs...)\n\ncompute_meansbands(m, input_type, cond_type, output_var, df; forecast_string = \"\",\n    population_data = DataFrame(), population_forecast = DataFrame(),\n    verbose = :none, kwargs...)\n\ncompute_meansbands(m, input_type, cond_type, output_var, var_name, df;\n    forecast_string = \"\", population_data = DataFrame(),\n    population_forecast = DataFrame(), verbose = :low,\n    kwargs...)\n\nCompute means and bands for pseudo-observables, observables, and shocks, and write the results to a file. Other methods are for one output_var and one var_name respectively.\n\nKeyword Arguments\n\nforecast_string::String = \"\": forecast identifier string (the value \"fcid=value\" in the forecast output filename). Required when input_type == :subset\ndensity_bands::Vector{Float64} = [.5, .6, .7, .8 .9]: a vector of percent values (between 0 and 1) for which to compute density bands.\nminimize::Bool = false: if true, choose shortest interval, otherwise just chop off lowest and highest (percent/2)\nverbose::Symbol = :low: level of error messages to be printed to screen. One of :none, :low, :high\nbdd_fcast::Bool = true: if true, calculate bounded forecasts\nskipnan::Bool = false: if true, remove any NaNs found in the raw forecast output series\ndf::DataFrame = DataFrame(): if an empty DataFrame, then the function will attempt to   load the data using load_data.\ncheck_empty_columns::Bool = true: if true, throw an error if   calling load_data yields an empty column.\npseudo2data::AbstractDict{Symbol, Symbol} = Dict(): Maps the names of pseudo-observables   which require historical data during transformation to the name of the required historical series.\n\n\n\n\n\ncompute_meansbands(models, input_types, cond_types, output_vars; forecast_strings = [],\n    verbose = :low, kwargs...)\n\ncompute_meansbands(models, input_types, cond_types, output_vars, df; forecast_strings = [],\n    population_data = DataFrame(), population_forecast = DataFrame(),\n    verbose = :none, kwargs...)\n\ncompute_meansbands(models, input_types, cond_types, output_var, var_name, df;\n    forecast_strings = [], population_data = DataFrame(),\n    population_forecast = DataFrame(), verbose = :low,\n    kwargs...)\n\nCompute means and bands for pseudo-observables, observables, and shocks from multiple forecasts, and write the results to a file. Other methods are for one output_var and one var_name respectively.\n\nKeyword Arguments\n\nforecast_strings::Vector{String} = []: forecast identifier strings for each forecast (the value \"fcid=value\" in the forecast output filename for individual forecasts). Required when input_type == :subset\ndensity_bands::Vector{Float64} = [.5, .6, .7, .8 .9]: a vector of percent values (between 0 and 1) for which to compute density bands.\nminimize::Bool = false: if true, choose shortest interval, otherwise just chop off lowest and highest (percent/2)\nverbose::Symbol = :low: level of error messages to be printed to screen. One of :none, :low, :high\nbdd_fcast::Bool = true: if true, calculate bounded forecasts\nskipnan::Bool = false: if true, remove any NaNs found in the raw forecast output series\nndraws::Int = 20000: number of draws from the underlying scenarios\ndf::DataFrame = DataFrame(): if an empty DataFrame, then the function will attempt to   load the data using load_data.\ncheck_empty_columns::Bool = true: if true, throw an error if   calling load_data yields an empty column.\npseudo2data::AbstractDict{Symbol, Symbol} = Dict(): Maps the names of pseudo-observables   which require historical data during transformation to the name of the required historical series.\n\n\n\n\n\n","category":"function"},{"location":"means_bands/#The-MeansBands-type-1","page":"Computing Means and Bands","title":"The MeansBands type","text":"","category":"section"},{"location":"means_bands/#","page":"Computing Means and Bands","title":"Computing Means and Bands","text":"MeansBands","category":"page"},{"location":"means_bands/#DSGE.MeansBands","page":"Computing Means and Bands","title":"DSGE.MeansBands","text":"mutable struct MeansBands\n\nStores the means and bands of results for a particular set of outputs from the forecast step.\n\nSpecifically, forecasts can be made for any element in the Cartesian product of 4 sets:\n\ninput_type: some subset of the parameter draws from the estimation step. See forecast_one for all possible options.\ncond_type: conditional type. See forecast_one for all possible options.\nproduct: a particular result computed in the forecast. This could be one of the following:\n\n  - `hist`: smoothed histories\n  - `forecast`: forecasted values\n  - `shockdec`: shock decompositions\n  - `shockdecseq`: shock decompositions\n  - `irf`: impulse responses\n\nvariable class: the category in which a particular variable, like :y_t, falls. Options are:\n\n  - `state`: state (from `m.endogenous_states` or `m.endogenous_states_augmented`)\n  - `obs`: observable (from `m.observables`)\n  - `pseudo`: pseudoobservable (from `pseudo_measurement` equation)\n  - `shock`: shock (from `m.exogenous_shocks`)\n\nNote that the Cartesian product (product x class) is the set of options for output_vars in the forecast_one function signature.\n\nFields\n\nmetadata::Dict{Symbol,Any}: Contains metadata keeping track of the input_type, cond_type, product (history, forecast, shockdec, etc), and variable class (observable, pseudoobservable, state, etc) stored in this MeansBands structure.\nmeans::DataFrame: a DataFrame of the mean of the time series\nbands::Dict{Symbol,DataFrame}: a Dict mapping variable names to DataFrames containing confidence bands for each variable. See find_density_bands for more information.\n\n\n\n\n\n","category":"type"},{"location":"model_design/#Model-Design-1","page":"Model Design","title":"Model Design","text":"","category":"section"},{"location":"model_design/#","page":"Model Design","title":"Model Design","text":"DSGE.jl is an object-oriented approach to solving the New York Fed DSGE model that takes advantage of Julia's type system, multiple dispatch, package-handling mechanism, and other features. A single model object[1] centralizes  all information about the model's parameters, states, equilibrium conditions, and settings in a single data structure. The model object also keeps track of file locations for all I/O operations.","category":"page"},{"location":"model_design/#","page":"Model Design","title":"Model Design","text":"The following objects define a model:","category":"page"},{"location":"model_design/#","page":"Model Design","title":"Model Design","text":"Parameters: Have values, bounds, fixed-or-not status, priors. An instance of the AbstractParameter type houses all information about a given parameter in a single data structure. See  The AbstractParameter Type in the documentation for ModelConstructors.jl.\nModel Indices: Mappings of state, shock, observable, and pseudo-observable names to indices (e.g. y_t -> 1). See Defining Indices.\nObservables and PseudoObservables: Mapping of names to indices, as well as information necessary for transformations. See The Observable and PseudoObservable Types in the documentation for ModelConstructors.jl.\nEquilibrium Conditions: A function that takes parameters and model indices, then returns Î“0, Î“1, C, Î¨, and Î  (which fully describe the model in canonical form).\nMeasurement Equation: A function mapping states to observables.\nPseudo-Measurement Equation: A function mapping states to what we call \"pseudo-observables\", i.e. linear combinations of existing states which are not observed. (Note that this is not strictly required to implement a model, but we often use the pseudo-measurement equation instead of adding new states in order to achieve a more parsimonious model.)","category":"page"},{"location":"model_design/#","page":"Model Design","title":"Model Design","text":"These are enough to define the model structure. Everything else is essentially a function of these basics, and we can solve the model and forecast observables via the following chain:","category":"page"},{"location":"model_design/#","page":"Model Design","title":"Model Design","text":"Parameters + Model Indices + Equilibrium conditions -> Transition matrices in state-space form\nTransition matrices + Data -> Estimated parameter values\nEstimated parameters + Transition matrices + Data -> Forecast","category":"page"},{"location":"model_design/#","page":"Model Design","title":"Model Design","text":"[1]: As of v0.7.3, DSGE.jl no longer houses the code for creating a                   model object. We have created a separate package                   ModelConstructors.jl,                   which defines a bare-bones AbstractModel type                   for a generic model a user might want to estimate. In DSGE.jl,                   we now define a subtype AbstractDSGEModel that includes additional                   methods, defaults, etc. that a standard DSGE model would have.","category":"page"}]
}
